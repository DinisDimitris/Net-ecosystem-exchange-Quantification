{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1d20b1-fee7-478f-a15e-a3457668563e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as R2\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d201058-0694-4f84-a28a-473e0a45f026",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Knowledge guided machine learning implementation using gated recurrent units\n",
    "### Inspired from https://gmd.copernicus.org/articles/15/2839/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4ebd55-ff64-4041-ac30-48515bdc5406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KGML(nn.Module):\n",
    "    def __init__(self, ninp, nhid, nlayers, nout, dropout):\n",
    "        super(KGML, self).__init__()\n",
    "        if nlayers > 1:\n",
    "            self.gru = nn.GRU(ninp, nhid,nlayers,dropout=dropout)\n",
    "        else:\n",
    "            self.gru = nn.GRU(ninp, nhid,nlayers)\n",
    "        #self.densor1 = nn.ReLU() #can test other function\n",
    "        self.densor2 = nn.Linear(nhid, nout)\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        self.drop=nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1 #may change to a small value\n",
    "        self.densor2.bias.data.zero_()\n",
    "        self.densor2.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.gru(inputs, hidden)\n",
    "        #output = self.densor1(self.drop(output))\n",
    "        #output = torch.exp(self.densor2(self.drop(output))) # add exp\n",
    "        output = self.densor2(self.drop(output)) # add exp\n",
    "        return output, hidden\n",
    "\n",
    "#bsz should be batch size\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        weight = weight.float()\n",
    "        return weight.new_zeros(self.nlayers, bsz, self.nhid)\n",
    "    \n",
    "def get_ini(x,ind,nout):\n",
    "    initials=[]\n",
    "    for i in range(len(ind)):\n",
    "        initials.append(x[:,:,ind[i]].view(x.size(0),x.size(1),nout[i]))\n",
    "    return initials\n",
    "\n",
    "def myloss_mul_sum(output, target,loss_weights):\n",
    "    loss = 0.0\n",
    "    nout=output.size(2)\n",
    "    for i in range(nout):\n",
    "        loss = loss + loss_weights[i]*torch.mean((output[:,:,i] - target[:,:,i])**2)\n",
    "    return loss\n",
    "\n",
    "def Z_norm(X):\n",
    "    X_mean=X.mean()\n",
    "    X_std=np.std(np.array(X))\n",
    "    return (X-X_mean)/X_std, X_mean, X_std\n",
    "\n",
    "class R2Loss(nn.Module):\n",
    "    #calculate coefficient of determination\n",
    "    def forward(self, y_pred, y):\n",
    "        var_y = torch.var(y, unbiased=False)\n",
    "        return 1.0 - F.mse_loss(y_pred, y, reduction=\"mean\") / var_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece63282-72ea-44e7-91e6-90e512c228a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = 'NEE'\n",
    "\n",
    "model = ['rcef_RandomForestRegressor', 'rcef_RidgeCV', 'rcef_XGBRegressor', 'xgboost'] \n",
    "\n",
    "extracted_features = model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c4f8503-b91e-4f04-81b7-87c8918e924c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgbFeatImp = pd.read_csv('feature_analysis/xgboost/FeaturesImportance'  + target  + 'weather_soil_data' + '.csv')\n",
    "feat_cols = []\n",
    "for i in range(len(xgbFeatImp.values)):\n",
    "    feat_cols.append(xgbFeatImp.values[i][0])\n",
    "\n",
    "observed_df = pd.read_csv('datasets/TRAINextractedNEE_CUT_REF_NIGHTobsfeats.csv')\n",
    "\n",
    "observed_df['initial planting density (m-2)1'] = 8.2\n",
    "\n",
    "x_observed = observed_df[feat_cols]\n",
    "y_observed = observed_df['NEE']\n",
    "\n",
    "for entr in x_observed.columns:\n",
    "    x_observed[entr] = preprocessing.normalize([x_observed[entr]])[0]\n",
    "y_observed = pd.Series(preprocessing.normalize([y_observed])[0], name='NEE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea6c7b-5729-4a16-9020-04abc9ec772d",
   "metadata": {},
   "source": [
    "### If Cuda available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c520e-f8d4-41c9-a205-2f0bdcb4653e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_out=1\n",
    "#shuffled_b=torch.randperm(X.size()[1]) # be aware that random may be different every time\n",
    "\n",
    "##\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#print(device)\n",
    "##X=X[:,shuffled_b,:].to(device)   #test unshuffled site\n",
    "##Y=Y[:,shuffled_b,:].to(device)\n",
    "#X=df.to(device)  \n",
    "#Y=y.to(device)\n",
    "#print(X.size(),n_f)\n",
    "\n",
    "train_n=70\n",
    "val_n=10\n",
    "test_n=19\n",
    "\n",
    "\n",
    "X_train=X[:,0:train_n*fln,:].view(Tx*tyear,train_n*fln,n_f)\n",
    "X_val=X[:,train_n*fln:(train_n+val_n)*fln,:].view(Tx*tyear,val_n*fln,n_f)\n",
    "X_test=X[:,(train_n+val_n)*fln:(train_n+val_n+test_n)*fln,:].view(Tx*tyear,test_n*fln,n_f)\n",
    "Y_train=Y[:,0:train_n*fln,:].view(Tx*tyear,train_n*fln,n_out)\n",
    "Y_val=Y[:,train_n*fln:(train_n+val_n)*fln,:].view(Tx*tyear,val_n*fln,n_out)\n",
    "Y_test=Y[:,(train_n+val_n)*fln:(train_n+val_n+test_n)*fln,:].view(Tx*tyear,test_n*fln,n_out)\n",
    "\n",
    "#loss weights setup\n",
    "loss_weights=[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]   \n",
    "print(X_train.size(), Y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad589a15-91bd-4825-b6b1-c9f6803e5c9d",
   "metadata": {},
   "source": [
    "# 0.70 train , 0.25 val , years 2015 - 2020 left for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce0e4c6c-f223-47df-8bec-541d9940bc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "   x_observed, y_observed, test_size=0.25, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f85d9358-5c0e-4f4e-af4b-1df841fe9d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "KGML(\n",
      "  (gru): GRU(11, 64, num_layers=4, dropout=0.2)\n",
      "  (densor2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "18\n",
      "torch.Size([192, 64])\n"
     ]
    }
   ],
   "source": [
    "compute_r2=R2Loss()\n",
    "n_a=64 #hidden state number\n",
    "n_l=4 #layer of lstm\n",
    "nout1=1\n",
    "nout2=1\n",
    "dropout=0.2\n",
    "path_save = 'kgml-results'\n",
    "save_file = '/gru'\n",
    "mds_file = '/stats'\n",
    "os.makedirs(path_save, exist_ok=True)  \n",
    "model1=KGML(len(feat_cols),n_a,n_l,1,dropout)\n",
    "print(\"Model's state_dict:\")\n",
    "#model1.to(device)\n",
    "print(model1)\n",
    "params = list(model1.parameters())\n",
    "print(len(params))\n",
    "print(params[5].size())  # conv1's .weight\n",
    "model_save = path_save + save_file\n",
    "stats_save = path_save + mds_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "301a3614-bad2-4905-9584-f8014c17a2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:3560] \n",
    "Y_train = Y_train[:3560]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5addc4ac-25c1-45c5-a9af-d1075dd2e430",
   "metadata": {},
   "source": [
    "### Batch size needs to be changed to be a divisor of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc2f6712-273f-401c-8b2c-d5674c49d03f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training epoch 1\n",
      "train_loss:  0.0002531434648273164 train_R2 -1.1470786204534082\n",
      "finished training epoch 2\n",
      "train_loss:  0.0002362481023129076 train_R2 -1.416039758544895\n",
      "finished training epoch 3\n",
      "train_loss:  0.0003100833561161372 train_R2 -1.0814640857026854\n",
      "finished training epoch 4\n",
      "train_loss:  0.0002272566382742459 train_R2 -0.944942158431362\n",
      "finished training epoch 5\n",
      "train_loss:  0.00020219086719236546 train_R2 -0.7480184468406716\n",
      "finished training epoch 6\n",
      "train_loss:  0.00020608909092622517 train_R2 -1.6145119790710685\n",
      "finished training epoch 7\n",
      "train_loss:  0.000182300305735299 train_R2 -0.524839932476185\n",
      "finished training epoch 8\n",
      "train_loss:  0.00018037574954401852 train_R2 -0.6522990917487794\n",
      "finished training epoch 9\n",
      "train_loss:  0.00017765071729147693 train_R2 -0.6795585917170099\n",
      "finished training epoch 10\n",
      "train_loss:  0.0001776411766904435 train_R2 -0.8937809496609714\n",
      "finished training epoch 11\n",
      "train_loss:  0.00016916551931872923 train_R2 -0.85473453920005\n",
      "finished training epoch 12\n",
      "train_loss:  0.00016540456634920299 train_R2 -0.8305431036622981\n",
      "finished training epoch 13\n",
      "train_loss:  0.00016237494000769897 train_R2 -0.36475117142788926\n",
      "finished training epoch 14\n",
      "train_loss:  0.000158391042126409 train_R2 -0.10120422611808966\n",
      "finished training epoch 15\n",
      "train_loss:  0.00015394161847824425 train_R2 -1.5367512770710734\n",
      "finished training epoch 16\n",
      "train_loss:  0.00014936120406718552 train_R2 -0.6459213604388552\n",
      "finished training epoch 17\n",
      "train_loss:  0.00014952352768152617 train_R2 -0.2818456439910684\n",
      "finished training epoch 18\n",
      "train_loss:  0.00015318258500904945 train_R2 -0.321759841908116\n",
      "finished training epoch 19\n",
      "train_loss:  0.00015162521885760263 train_R2 -0.9899610726697414\n",
      "finished training epoch 20\n",
      "train_loss:  0.0001544145118439833 train_R2 -0.7375318475196264\n",
      "finished training epoch 21\n",
      "train_loss:  0.00014995104758054264 train_R2 -0.9455711821900079\n",
      "finished training epoch 22\n",
      "train_loss:  0.00015161519186251718 train_R2 -0.49002532671926\n",
      "finished training epoch 23\n",
      "train_loss:  0.00014060098992838612 train_R2 -0.47312958086408674\n",
      "finished training epoch 24\n",
      "train_loss:  0.00013804983182243274 train_R2 -0.15229052707554014\n",
      "finished training epoch 25\n",
      "train_loss:  0.00012943027512323744 train_R2 -0.09715074227091525\n",
      "finished training epoch 26\n",
      "train_loss:  0.00013279262211140475 train_R2 -0.19107722329086063\n",
      "finished training epoch 27\n",
      "train_loss:  0.00014247938658516198 train_R2 -0.5297380135780141\n",
      "finished training epoch 28\n",
      "train_loss:  0.00015628803846383065 train_R2 -0.36219277097971614\n",
      "finished training epoch 29\n",
      "train_loss:  0.00016729428029958046 train_R2 -0.5632804362543014\n",
      "finished training epoch 30\n",
      "train_loss:  0.00014536894078248582 train_R2 -0.3019540366676037\n",
      "finished training epoch 31\n",
      "train_loss:  0.00012917856588385649 train_R2 -0.564330660416146\n",
      "finished training epoch 32\n",
      "train_loss:  0.0001338119609106509 train_R2 -0.23030513956948506\n",
      "finished training epoch 33\n",
      "train_loss:  0.00013832512232195084 train_R2 -0.30578827111790563\n",
      "finished training epoch 34\n",
      "train_loss:  0.00013667813531692343 train_R2 -0.062712425177742\n",
      "finished training epoch 35\n",
      "train_loss:  0.00012528143876813156 train_R2 -0.6011580368587495\n",
      "finished training epoch 36\n",
      "train_loss:  0.00012029186273307167 train_R2 -0.48024690425847427\n",
      "finished training epoch 37\n",
      "train_loss:  0.0001232006073044435 train_R2 -0.254903884669359\n",
      "finished training epoch 38\n",
      "train_loss:  0.0001209415644034061 train_R2 -0.0689372100443133\n",
      "finished training epoch 39\n",
      "train_loss:  0.0001247251030305324 train_R2 -0.23655306991251446\n",
      "finished training epoch 40\n",
      "train_loss:  0.00011784204282357651 train_R2 -0.47114904565918847\n",
      "finished training epoch 41\n",
      "train_loss:  0.00011397818857633446 train_R2 -0.236662674018562\n",
      "finished training epoch 42\n",
      "train_loss:  0.00011331984988642353 train_R2 -0.12876389375774577\n",
      "finished training epoch 43\n",
      "train_loss:  0.00011617397299709922 train_R2 -0.4105408969683324\n",
      "finished training epoch 44\n",
      "train_loss:  0.00011979094454555707 train_R2 -0.22354399811009884\n",
      "finished training epoch 45\n",
      "train_loss:  0.00011600754243075708 train_R2 -0.285458037332486\n",
      "finished training epoch 46\n",
      "train_loss:  0.00011519869432658847 train_R2 -0.03275735457219975\n",
      "finished training epoch 47\n",
      "train_loss:  0.00011005395434796326 train_R2 -0.10295873939234279\n",
      "finished training epoch 48\n",
      "train_loss:  0.00011241403475905138 train_R2 -0.49238356338802625\n",
      "finished training epoch 49\n",
      "train_loss:  0.00011029442824005192 train_R2 0.13321799305883464\n",
      "finished training epoch 50\n",
      "train_loss:  0.00011391261323174546 train_R2 -0.2884445338759398\n",
      "finished training epoch 51\n",
      "train_loss:  0.00011959768026009225 train_R2 -0.22840212414450645\n",
      "finished training epoch 52\n",
      "train_loss:  0.00012230499772028004 train_R2 -0.3026125379985858\n",
      "finished training epoch 53\n",
      "train_loss:  0.0001270911316533693 train_R2 0.06862625121367438\n",
      "finished training epoch 54\n",
      "train_loss:  0.00011522200827304976 train_R2 -0.23573656992419223\n",
      "finished training epoch 55\n",
      "train_loss:  0.00011313241661121014 train_R2 -0.18330708718219557\n",
      "finished training epoch 56\n",
      "train_loss:  0.00010907162923761179 train_R2 -0.1344735777384296\n",
      "finished training epoch 57\n",
      "train_loss:  0.00011090883010915153 train_R2 -0.381681110231062\n",
      "finished training epoch 58\n",
      "train_loss:  0.00011283985381022358 train_R2 -0.24728835469577382\n",
      "finished training epoch 59\n",
      "train_loss:  0.00011325022542776585 train_R2 -0.3441534287659189\n",
      "finished training epoch 60\n",
      "train_loss:  0.0001164138073764705 train_R2 -0.029468169205073558\n",
      "finished training epoch 61\n",
      "train_loss:  0.00010970829926373086 train_R2 -0.17726410705024165\n",
      "finished training epoch 62\n",
      "train_loss:  0.00010775995325539942 train_R2 0.10905904775851993\n",
      "finished training epoch 63\n",
      "train_loss:  0.00010234142118087635 train_R2 -0.0049906712800933395\n",
      "finished training epoch 64\n",
      "train_loss:  0.00010074686647671721 train_R2 0.1712597533815663\n",
      "finished training epoch 65\n",
      "train_loss:  0.00010390858570731823 train_R2 0.21176699922722153\n",
      "finished training epoch 66\n",
      "train_loss:  0.00010336504905875368 train_R2 -0.008593737859931894\n",
      "finished training epoch 67\n",
      "train_loss:  0.00011293781431610487 train_R2 0.26976907036400943\n",
      "finished training epoch 68\n",
      "train_loss:  0.00011682514267528198 train_R2 -0.002527367295055649\n",
      "finished training epoch 69\n",
      "train_loss:  0.00012417104903393535 train_R2 -0.023227721130592682\n",
      "finished training epoch 70\n",
      "train_loss:  0.0001159735578714379 train_R2 -0.37197234354345254\n",
      "finished training epoch 71\n",
      "train_loss:  0.00010439897322106064 train_R2 -0.10190201996463033\n",
      "finished training epoch 72\n",
      "train_loss:  9.473907603876256e-05 train_R2 0.09847525917878885\n",
      "finished training epoch 73\n",
      "train_loss:  9.594736157032252e-05 train_R2 0.08567834438136768\n",
      "finished training epoch 74\n",
      "train_loss:  0.00010495447910518303 train_R2 -0.004625160827307129\n",
      "finished training epoch 75\n",
      "train_loss:  0.00011372791690856287 train_R2 -0.20598739320584092\n",
      "finished training epoch 76\n",
      "train_loss:  0.0001207033761811393 train_R2 0.11345212082561795\n",
      "finished training epoch 77\n",
      "train_loss:  0.00010459421984626699 train_R2 -0.27616221104819605\n",
      "finished training epoch 78\n",
      "train_loss:  8.967004903006248e-05 train_R2 0.11906408822909664\n",
      "finished training epoch 79\n",
      "train_loss:  8.250894631557374e-05 train_R2 0.12310750881124455\n",
      "finished training epoch 80\n",
      "train_loss:  8.586713960763814e-05 train_R2 -0.041432334394472026\n",
      "finished training epoch 81\n",
      "train_loss:  0.0001081831822401687 train_R2 0.0754266085231432\n",
      "finished training epoch 82\n",
      "train_loss:  0.00011974479521408262 train_R2 -0.3022401274042599\n",
      "finished training epoch 83\n",
      "train_loss:  0.00011261232191971893 train_R2 -0.13671523342104264\n",
      "finished training epoch 84\n",
      "train_loss:  8.079988565396486e-05 train_R2 0.30151942368912965\n",
      "finished training epoch 85\n",
      "train_loss:  7.08908690971209e-05 train_R2 0.4080545914649055\n",
      "finished training epoch 86\n",
      "train_loss:  7.819704447535037e-05 train_R2 0.5087848260943597\n",
      "finished training epoch 87\n",
      "train_loss:  8.513569440490751e-05 train_R2 0.15941240421824265\n",
      "finished training epoch 88\n",
      "train_loss:  8.836321067860327e-05 train_R2 0.17690942871442428\n",
      "finished training epoch 89\n",
      "train_loss:  7.445942870382672e-05 train_R2 0.1207457024922094\n",
      "finished training epoch 90\n",
      "train_loss:  6.071668256396499e-05 train_R2 0.37858720870246865\n",
      "finished training epoch 91\n",
      "train_loss:  5.3920562230892016e-05 train_R2 0.35008291284429716\n",
      "finished training epoch 92\n",
      "train_loss:  6.162811803995902e-05 train_R2 0.287589061025017\n",
      "finished training epoch 93\n",
      "train_loss:  8.087455486773962e-05 train_R2 0.4270737160119281\n",
      "finished training epoch 94\n",
      "train_loss:  0.00010565386122011909 train_R2 -0.14512282187736436\n",
      "finished training epoch 95\n",
      "train_loss:  0.0001083651980641369 train_R2 -0.0902549619448465\n",
      "finished training epoch 96\n",
      "train_loss:  7.068408094422656e-05 train_R2 0.12128192788537151\n",
      "finished training epoch 97\n",
      "train_loss:  5.6648877084051475e-05 train_R2 0.29890017986639117\n",
      "finished training epoch 98\n",
      "train_loss:  6.500047722351055e-05 train_R2 0.4029926147881556\n",
      "finished training epoch 99\n",
      "train_loss:  6.576164507065496e-05 train_R2 0.27786347619710994\n",
      "finished training epoch 100\n",
      "train_loss:  5.564499907407678e-05 train_R2 0.5130378423315072\n",
      "finished training epoch 101\n",
      "train_loss:  4.8095156826209225e-05 train_R2 0.681616106011401\n",
      "finished training epoch 102\n",
      "train_loss:  4.6962577087910263e-05 train_R2 0.351670565163523\n",
      "finished training epoch 103\n",
      "train_loss:  5.304213590163529e-05 train_R2 0.5835756954549396\n",
      "finished training epoch 104\n",
      "train_loss:  5.53546074213066e-05 train_R2 0.3366884354063878\n",
      "finished training epoch 105\n",
      "train_loss:  5.205975044352516e-05 train_R2 0.45012973314854243\n",
      "finished training epoch 106\n",
      "train_loss:  4.544008473697024e-05 train_R2 0.5721358609303488\n",
      "finished training epoch 107\n",
      "train_loss:  4.297590287840606e-05 train_R2 0.4522286335903458\n",
      "finished training epoch 108\n",
      "train_loss:  4.443687833141046e-05 train_R2 0.5485205534476194\n",
      "finished training epoch 109\n",
      "train_loss:  4.8776487789006604e-05 train_R2 0.3990224806492655\n",
      "finished training epoch 110\n",
      "train_loss:  5.5039065552331554e-05 train_R2 0.5726106481703834\n",
      "finished training epoch 111\n",
      "train_loss:  5.524059478766064e-05 train_R2 0.4225772945921046\n",
      "finished training epoch 112\n",
      "train_loss:  4.8958404847923036e-05 train_R2 0.5982912932878528\n",
      "finished training epoch 113\n",
      "train_loss:  4.2114275000710236e-05 train_R2 0.5653981600990218\n",
      "finished training epoch 114\n",
      "train_loss:  4.278824239723579e-05 train_R2 0.4790620126583903\n",
      "finished training epoch 115\n",
      "train_loss:  4.6857972669563615e-05 train_R2 0.4313862132219839\n",
      "finished training epoch 116\n",
      "train_loss:  4.878656291497968e-05 train_R2 0.3702264616051518\n",
      "finished training epoch 117\n",
      "train_loss:  4.9886374887708296e-05 train_R2 0.6185805287960027\n",
      "finished training epoch 118\n",
      "train_loss:  4.3620352316e-05 train_R2 0.4484534832319539\n",
      "finished training epoch 119\n",
      "train_loss:  4.1269063443693e-05 train_R2 0.5100011126050608\n",
      "finished training epoch 120\n",
      "train_loss:  4.034924314727158e-05 train_R2 0.5806220081256763\n",
      "finished training epoch 121\n",
      "train_loss:  4.3090710571567795e-05 train_R2 0.49512190157314107\n",
      "finished training epoch 122\n",
      "train_loss:  4.895315755365896e-05 train_R2 0.6809164185171962\n",
      "finished training epoch 123\n",
      "train_loss:  4.840891692503148e-05 train_R2 0.36156158225993984\n",
      "finished training epoch 124\n",
      "train_loss:  4.4729257197116765e-05 train_R2 0.5517456167378779\n",
      "finished training epoch 125\n",
      "train_loss:  4.072508773139153e-05 train_R2 0.5362693616863043\n",
      "finished training epoch 126\n",
      "train_loss:  3.927292593268015e-05 train_R2 0.5556207163949053\n",
      "finished training epoch 127\n",
      "train_loss:  4.063450620539599e-05 train_R2 0.7394067093507674\n",
      "finished training epoch 128\n",
      "train_loss:  4.2853145685301995e-05 train_R2 0.6836980633688516\n",
      "finished training epoch 129\n",
      "train_loss:  4.468005908405653e-05 train_R2 0.4163575721190592\n",
      "finished training epoch 130\n",
      "train_loss:  4.428564108950848e-05 train_R2 0.42173058135662445\n",
      "finished training epoch 131\n",
      "train_loss:  4.008566102825337e-05 train_R2 0.5406934111813275\n",
      "finished training epoch 132\n",
      "train_loss:  3.8670707656859924e-05 train_R2 0.6374831582001848\n",
      "finished training epoch 133\n",
      "train_loss:  3.788572505917949e-05 train_R2 0.5342253661280575\n",
      "finished training epoch 134\n",
      "train_loss:  4.0790556058354534e-05 train_R2 0.5591749741953473\n",
      "finished training epoch 135\n",
      "train_loss:  4.374378018914784e-05 train_R2 0.4690026918837381\n",
      "finished training epoch 136\n",
      "train_loss:  4.520630881685038e-05 train_R2 0.5581014643330596\n",
      "finished training epoch 137\n",
      "train_loss:  4.256666136560095e-05 train_R2 0.5695257979544055\n",
      "finished training epoch 138\n",
      "train_loss:  3.944101623342382e-05 train_R2 0.7042579908014539\n",
      "finished training epoch 139\n",
      "train_loss:  3.6426655942127823e-05 train_R2 0.7415990303982969\n",
      "finished training epoch 140\n",
      "train_loss:  3.765975570548099e-05 train_R2 0.7181066076808497\n",
      "finished training epoch 141\n",
      "train_loss:  3.9023635319064713e-05 train_R2 0.5595057750058436\n",
      "finished training epoch 142\n",
      "train_loss:  4.209900647018058e-05 train_R2 0.587846607132779\n",
      "finished training epoch 143\n",
      "train_loss:  4.401459825570627e-05 train_R2 0.6004501062525716\n",
      "finished training epoch 144\n",
      "train_loss:  4.235801218238548e-05 train_R2 0.5172709490771316\n",
      "finished training epoch 145\n",
      "train_loss:  3.9763673221725293e-05 train_R2 0.402272438012941\n",
      "finished training epoch 146\n",
      "train_loss:  3.6747917677770334e-05 train_R2 0.6143478623254605\n",
      "finished training epoch 147\n",
      "train_loss:  3.777979265418831e-05 train_R2 0.573953352351422\n",
      "finished training epoch 148\n",
      "train_loss:  3.945410728784231e-05 train_R2 0.7630764607011328\n",
      "finished training epoch 149\n",
      "train_loss:  4.3273874013843434e-05 train_R2 0.5611960273946117\n",
      "finished training epoch 150\n",
      "train_loss:  4.5322546376186506e-05 train_R2 0.6637486575338614\n",
      "finished training epoch 151\n",
      "train_loss:  4.3548902671438285e-05 train_R2 0.5337424282879207\n",
      "finished training epoch 152\n",
      "train_loss:  4.0391613807895306e-05 train_R2 0.43655990028502933\n",
      "finished training epoch 153\n",
      "train_loss:  3.543881673018805e-05 train_R2 0.6907454220683982\n",
      "finished training epoch 154\n",
      "train_loss:  3.682382605148152e-05 train_R2 0.5575668893195183\n",
      "finished training epoch 155\n",
      "train_loss:  3.889848393375016e-05 train_R2 0.644516187924253\n",
      "finished training epoch 156\n",
      "train_loss:  4.2731773785318854e-05 train_R2 0.6818386654547977\n",
      "finished training epoch 157\n",
      "train_loss:  4.33829647174442e-05 train_R2 0.6446008036640818\n",
      "finished training epoch 158\n",
      "train_loss:  4.0940232937388695e-05 train_R2 0.6522541003685722\n",
      "finished training epoch 159\n",
      "train_loss:  3.675316849201443e-05 train_R2 0.5790177602613094\n",
      "finished training epoch 160\n",
      "train_loss:  3.404235884854616e-05 train_R2 0.7261575277410915\n",
      "finished training epoch 161\n",
      "train_loss:  3.565181270834815e-05 train_R2 0.5030198971173934\n",
      "finished training epoch 162\n",
      "train_loss:  3.932271738683417e-05 train_R2 0.6569987296831181\n",
      "finished training epoch 163\n",
      "train_loss:  4.192594114755796e-05 train_R2 0.5293513235399459\n",
      "finished training epoch 164\n",
      "train_loss:  4.01967800279262e-05 train_R2 0.637109898951494\n",
      "finished training epoch 165\n",
      "train_loss:  3.6237478569631486e-05 train_R2 0.5771712180243064\n",
      "finished training epoch 166\n",
      "train_loss:  3.4217605528891644e-05 train_R2 0.6216482077127632\n",
      "finished training epoch 167\n",
      "train_loss:  3.444291657572232e-05 train_R2 0.6919888358133341\n",
      "finished training epoch 168\n",
      "train_loss:  3.7718704257501966e-05 train_R2 0.5349633613473888\n",
      "finished training epoch 169\n",
      "train_loss:  4.080331664152303e-05 train_R2 0.5797107172902445\n",
      "finished training epoch 170\n",
      "train_loss:  3.950414178378326e-05 train_R2 0.7124655263911384\n",
      "finished training epoch 171\n",
      "train_loss:  3.575793628996599e-05 train_R2 0.666689716532787\n",
      "finished training epoch 172\n",
      "train_loss:  3.4352154324865366e-05 train_R2 0.6080070177116594\n",
      "finished training epoch 173\n",
      "train_loss:  3.345264177890678e-05 train_R2 0.5596493202412748\n",
      "finished training epoch 174\n",
      "train_loss:  3.525243103269607e-05 train_R2 0.6192282831614258\n",
      "finished training epoch 175\n",
      "train_loss:  3.783934544177523e-05 train_R2 0.5048578615755182\n",
      "finished training epoch 176\n",
      "train_loss:  3.732485325571698e-05 train_R2 0.6733093668028147\n",
      "finished training epoch 177\n",
      "train_loss:  3.5308037452786364e-05 train_R2 0.5040316511992393\n",
      "finished training epoch 178\n",
      "train_loss:  3.405756715771892e-05 train_R2 0.6787676817303661\n",
      "finished training epoch 179\n",
      "train_loss:  3.3085306046902874e-05 train_R2 0.6981399146978422\n",
      "finished training epoch 180\n",
      "train_loss:  3.470374340563234e-05 train_R2 0.8007888080307923\n",
      "finished training epoch 181\n",
      "train_loss:  3.734421105086185e-05 train_R2 0.5320724323435579\n",
      "finished training epoch 182\n",
      "train_loss:  3.7953752417916526e-05 train_R2 0.7299954371014997\n",
      "finished training epoch 183\n",
      "train_loss:  3.755666571939319e-05 train_R2 0.47771674527747654\n",
      "finished training epoch 184\n",
      "train_loss:  3.3615873926455185e-05 train_R2 0.7107819888570559\n",
      "finished training epoch 185\n",
      "train_loss:  3.190320604691905e-05 train_R2 0.7170789369166859\n",
      "finished training epoch 186\n",
      "train_loss:  3.2618816156357705e-05 train_R2 0.6837415366099894\n",
      "finished training epoch 187\n",
      "train_loss:  3.4302279248294706e-05 train_R2 0.6380569036324993\n",
      "finished training epoch 188\n",
      "train_loss:  3.783223617050698e-05 train_R2 0.7286066785318308\n",
      "finished training epoch 189\n",
      "train_loss:  3.772146810100993e-05 train_R2 0.6203218039959105\n",
      "finished training epoch 190\n",
      "train_loss:  3.7023816688337035e-05 train_R2 0.5925698216837716\n",
      "finished training epoch 191\n",
      "train_loss:  3.324903015353069e-05 train_R2 0.5514186223899249\n",
      "finished training epoch 192\n",
      "train_loss:  3.1006018421389645e-05 train_R2 0.689653344667642\n",
      "finished training epoch 193\n",
      "train_loss:  3.194243039725401e-05 train_R2 0.690739982811496\n",
      "finished training epoch 194\n",
      "train_loss:  3.511546068267267e-05 train_R2 0.7845464327025773\n",
      "finished training epoch 195\n",
      "train_loss:  3.61931675483898e-05 train_R2 0.7071471774864053\n",
      "finished training epoch 196\n",
      "train_loss:  3.6214337233212054e-05 train_R2 0.6945485129977058\n",
      "finished training epoch 197\n",
      "train_loss:  3.3264803542094556e-05 train_R2 0.6462233485062392\n",
      "finished training epoch 198\n",
      "train_loss:  3.1045579139081484e-05 train_R2 0.5732008338081878\n",
      "finished training epoch 199\n",
      "train_loss:  2.9799203821511955e-05 train_R2 0.6873514248517154\n",
      "finished training epoch 200\n",
      "train_loss:  3.215819520270928e-05 train_R2 0.69967092129782\n",
      "finished training epoch 201\n",
      "train_loss:  3.388503864977991e-05 train_R2 0.6267360234235857\n",
      "finished training epoch 202\n",
      "train_loss:  3.465834071690221e-05 train_R2 0.6986122799120105\n",
      "finished training epoch 203\n",
      "train_loss:  3.399532434068893e-05 train_R2 0.5655345657779937\n",
      "finished training epoch 204\n",
      "train_loss:  3.225267968063658e-05 train_R2 0.7534765190852101\n",
      "finished training epoch 205\n",
      "train_loss:  2.99679041838073e-05 train_R2 0.771744090972214\n",
      "finished training epoch 206\n",
      "train_loss:  2.989644536828037e-05 train_R2 0.5619510222374189\n",
      "finished training epoch 207\n",
      "train_loss:  3.0768961067622147e-05 train_R2 0.5923622058286302\n",
      "finished training epoch 208\n",
      "train_loss:  3.261733672309805e-05 train_R2 0.6320600325216479\n",
      "finished training epoch 209\n",
      "train_loss:  3.3361014623740825e-05 train_R2 0.6493648966813039\n",
      "finished training epoch 210\n",
      "train_loss:  3.294513991595982e-05 train_R2 0.5642563220407699\n",
      "finished training epoch 211\n",
      "train_loss:  3.0429775416815524e-05 train_R2 0.7558907160598699\n",
      "finished training epoch 212\n",
      "train_loss:  2.9586212196456103e-05 train_R2 0.7305487512338065\n",
      "finished training epoch 213\n",
      "train_loss:  2.9059337273427293e-05 train_R2 0.7246414662253725\n",
      "finished training epoch 214\n",
      "train_loss:  3.0724209233509736e-05 train_R2 0.5559755984148198\n",
      "finished training epoch 215\n",
      "train_loss:  3.2032155361675674e-05 train_R2 0.6463044580391923\n",
      "finished training epoch 216\n",
      "train_loss:  3.186754316117886e-05 train_R2 0.7227750035210116\n",
      "finished training epoch 217\n",
      "train_loss:  3.211428162435445e-05 train_R2 0.6700706504675304\n",
      "finished training epoch 218\n",
      "train_loss:  3.0305148027744822e-05 train_R2 0.6843687014068709\n",
      "finished training epoch 219\n",
      "train_loss:  2.881992880483025e-05 train_R2 0.6874793046831527\n",
      "finished training epoch 220\n",
      "train_loss:  2.8495526663568e-05 train_R2 0.6538290457303901\n",
      "finished training epoch 221\n",
      "train_loss:  2.927979602731389e-05 train_R2 0.6545374488636713\n",
      "finished training epoch 222\n",
      "train_loss:  3.081954340325171e-05 train_R2 0.7073307564379419\n",
      "finished training epoch 223\n",
      "train_loss:  3.2298710918619934e-05 train_R2 0.6938050652643395\n",
      "finished training epoch 224\n",
      "train_loss:  3.0858795686792484e-05 train_R2 0.6849762950206254\n",
      "finished training epoch 225\n",
      "train_loss:  2.8861587309209038e-05 train_R2 0.7029504047465973\n",
      "finished training epoch 226\n",
      "train_loss:  2.785968948773897e-05 train_R2 0.7190938145444862\n",
      "finished training epoch 227\n",
      "train_loss:  2.812568292640435e-05 train_R2 0.7277386785868278\n",
      "finished training epoch 228\n",
      "train_loss:  2.969978595128577e-05 train_R2 0.7097004568685129\n",
      "finished training epoch 229\n",
      "train_loss:  3.0969078845792364e-05 train_R2 0.6864254453405176\n",
      "finished training epoch 230\n",
      "train_loss:  3.110859432821674e-05 train_R2 0.5762377713435296\n",
      "finished training epoch 231\n",
      "train_loss:  2.9653518718409577e-05 train_R2 0.7761629501985652\n",
      "finished training epoch 232\n",
      "train_loss:  2.8110260587074597e-05 train_R2 0.7018148360749892\n",
      "finished training epoch 233\n",
      "train_loss:  2.7076052933595674e-05 train_R2 0.809798328256201\n",
      "finished training epoch 234\n",
      "train_loss:  2.7766454821710918e-05 train_R2 0.780563836928866\n",
      "finished training epoch 235\n",
      "train_loss:  3.0122900817935884e-05 train_R2 0.7455620606759656\n",
      "finished training epoch 236\n",
      "train_loss:  3.1666546105030125e-05 train_R2 0.759993447088035\n",
      "finished training epoch 237\n",
      "train_loss:  3.1542783151758826e-05 train_R2 0.6226311606443569\n",
      "finished training epoch 238\n",
      "train_loss:  2.8846200627354392e-05 train_R2 0.5972196810373946\n",
      "finished training epoch 239\n",
      "train_loss:  2.680898357635031e-05 train_R2 0.6397388272103172\n",
      "finished training epoch 240\n",
      "train_loss:  2.5940488027914866e-05 train_R2 0.692656378599569\n",
      "finished training epoch 241\n",
      "train_loss:  2.7028047433518128e-05 train_R2 0.6818349180016225\n",
      "finished training epoch 242\n",
      "train_loss:  2.9120965333806312e-05 train_R2 0.811431238722196\n",
      "finished training epoch 243\n",
      "train_loss:  3.050800796121428e-05 train_R2 0.6028891853479181\n",
      "finished training epoch 244\n",
      "train_loss:  2.9787136404677075e-05 train_R2 0.6517816443730053\n",
      "finished training epoch 245\n",
      "train_loss:  2.6998546441144525e-05 train_R2 0.7744843311831047\n",
      "finished training epoch 246\n",
      "train_loss:  2.5781032391535664e-05 train_R2 0.728155286160183\n",
      "finished training epoch 247\n",
      "train_loss:  2.510735648669663e-05 train_R2 0.707852003359734\n",
      "finished training epoch 248\n",
      "train_loss:  2.6217171977713774e-05 train_R2 0.7410526015029291\n",
      "finished training epoch 249\n",
      "train_loss:  2.63445392940699e-05 train_R2 0.752824449341543\n",
      "finished training epoch 250\n",
      "train_loss:  2.6882455164001732e-05 train_R2 0.699062624699796\n",
      "finished training epoch 251\n",
      "train_loss:  2.619660090415573e-05 train_R2 0.810280901887378\n",
      "finished training epoch 252\n",
      "train_loss:  2.4291622353089133e-05 train_R2 0.7924550326619411\n",
      "finished training epoch 253\n",
      "train_loss:  2.48096062123158e-05 train_R2 0.7550833663270873\n",
      "finished training epoch 254\n",
      "train_loss:  2.4424949170429478e-05 train_R2 0.8012691225764685\n",
      "finished training epoch 255\n",
      "train_loss:  2.4421735458400346e-05 train_R2 0.7178489587187187\n",
      "finished training epoch 256\n",
      "train_loss:  2.5035069541071977e-05 train_R2 0.7548452171475456\n",
      "finished training epoch 257\n",
      "train_loss:  2.597133979097405e-05 train_R2 0.7416580623262476\n",
      "finished training epoch 258\n",
      "train_loss:  2.6931585861341696e-05 train_R2 0.6912797116654257\n",
      "finished training epoch 259\n",
      "train_loss:  2.689579267407043e-05 train_R2 0.7397151324202316\n",
      "finished training epoch 260\n",
      "train_loss:  2.560609289841868e-05 train_R2 0.7446484361186183\n",
      "finished training epoch 261\n",
      "train_loss:  2.435408527071096e-05 train_R2 0.803192937653585\n",
      "finished training epoch 262\n",
      "train_loss:  2.275584355176728e-05 train_R2 0.8113411922219143\n",
      "finished training epoch 263\n",
      "train_loss:  2.3340255259081288e-05 train_R2 0.7839583549107442\n",
      "finished training epoch 264\n",
      "train_loss:  2.4319693406794747e-05 train_R2 0.7975295965380007\n",
      "finished training epoch 265\n",
      "train_loss:  2.519085119107195e-05 train_R2 0.716012893098702\n",
      "finished training epoch 266\n",
      "train_loss:  2.78911082687244e-05 train_R2 0.6658078835606415\n",
      "finished training epoch 267\n",
      "train_loss:  2.81446732576762e-05 train_R2 0.8179658360820681\n",
      "finished training epoch 268\n",
      "train_loss:  2.7464031595292775e-05 train_R2 0.8491911691912862\n",
      "finished training epoch 269\n",
      "train_loss:  2.4759521393032195e-05 train_R2 0.7682278527661643\n",
      "finished training epoch 270\n",
      "train_loss:  2.2647315884538777e-05 train_R2 0.7838712569231241\n",
      "finished training epoch 271\n",
      "train_loss:  2.2298784004341146e-05 train_R2 0.8318331227335407\n",
      "finished training epoch 272\n",
      "train_loss:  2.369380429221418e-05 train_R2 0.7444053199867753\n",
      "finished training epoch 273\n",
      "train_loss:  2.5122974240130617e-05 train_R2 0.7634205047591279\n",
      "finished training epoch 274\n",
      "train_loss:  2.5458192926853335e-05 train_R2 0.7512124392626103\n",
      "finished training epoch 275\n",
      "train_loss:  2.5526750554810278e-05 train_R2 0.7731722212059525\n",
      "finished training epoch 276\n",
      "train_loss:  2.285427817012648e-05 train_R2 0.8088927694439132\n",
      "finished training epoch 277\n",
      "train_loss:  2.2247178762318068e-05 train_R2 0.8140912702922295\n",
      "finished training epoch 278\n",
      "train_loss:  2.161043868787125e-05 train_R2 0.8230593539166245\n",
      "finished training epoch 279\n",
      "train_loss:  2.4417544918086972e-05 train_R2 0.6664810945125434\n",
      "finished training epoch 280\n",
      "train_loss:  2.6708225017061796e-05 train_R2 0.7803534862782736\n",
      "finished training epoch 281\n",
      "train_loss:  2.635383085950787e-05 train_R2 0.6191020315939659\n",
      "finished training epoch 282\n",
      "train_loss:  2.4524793067183655e-05 train_R2 0.7653471494431088\n",
      "finished training epoch 283\n",
      "train_loss:  2.1520926174783785e-05 train_R2 0.7850303043428792\n",
      "finished training epoch 284\n",
      "train_loss:  2.05976816246388e-05 train_R2 0.8008351853632456\n",
      "finished training epoch 285\n",
      "train_loss:  2.144236395152651e-05 train_R2 0.8394014723468063\n",
      "finished training epoch 286\n",
      "train_loss:  2.351661114011533e-05 train_R2 0.5861880515576285\n",
      "finished training epoch 287\n",
      "train_loss:  2.6117097830651634e-05 train_R2 0.7890322817868759\n",
      "finished training epoch 288\n",
      "train_loss:  2.4385791704930897e-05 train_R2 0.8166818947183219\n",
      "finished training epoch 289\n",
      "train_loss:  2.3231291900848844e-05 train_R2 0.7627207626471266\n",
      "finished training epoch 290\n",
      "train_loss:  1.9945404966253368e-05 train_R2 0.8494059024400386\n",
      "finished training epoch 291\n",
      "train_loss:  2.0226521220701015e-05 train_R2 0.8408885136620786\n",
      "finished training epoch 292\n",
      "train_loss:  2.234635684688301e-05 train_R2 0.8076043861308738\n",
      "finished training epoch 293\n",
      "train_loss:  2.2279042206601374e-05 train_R2 0.7966954926601226\n",
      "finished training epoch 294\n",
      "train_loss:  2.2333553043872726e-05 train_R2 0.7297657288698511\n",
      "finished training epoch 295\n",
      "train_loss:  2.217352410305948e-05 train_R2 0.627777812560051\n",
      "finished training epoch 296\n",
      "train_loss:  2.140222375270567e-05 train_R2 0.8498110887226635\n",
      "finished training epoch 297\n",
      "train_loss:  1.999731054120322e-05 train_R2 0.744623865603416\n",
      "finished training epoch 298\n",
      "train_loss:  1.976386005638406e-05 train_R2 0.8769252581074118\n",
      "finished training epoch 299\n",
      "train_loss:  2.0305662727365014e-05 train_R2 0.8297124563878534\n",
      "finished training epoch 300\n",
      "train_loss:  2.2672472942907062e-05 train_R2 0.7604990126776707\n",
      "finished training epoch 301\n",
      "train_loss:  2.3180558827528165e-05 train_R2 0.8405710801463978\n",
      "finished training epoch 302\n",
      "train_loss:  2.1212841566459186e-05 train_R2 0.6105417621078456\n",
      "finished training epoch 303\n",
      "train_loss:  1.9855106139924302e-05 train_R2 0.8960093029328153\n",
      "finished training epoch 304\n",
      "train_loss:  1.970901027370578e-05 train_R2 0.5267754610196194\n",
      "finished training epoch 305\n",
      "train_loss:  1.9180813961252142e-05 train_R2 0.7889438235599547\n",
      "finished training epoch 306\n",
      "train_loss:  2.1254000484162772e-05 train_R2 0.8534282470622393\n",
      "finished training epoch 307\n",
      "train_loss:  2.2603623105651976e-05 train_R2 0.4942305581496863\n",
      "finished training epoch 308\n",
      "train_loss:  2.287850562019487e-05 train_R2 0.8361019533604193\n",
      "finished training epoch 309\n",
      "train_loss:  2.2216754273610542e-05 train_R2 0.5773834039532477\n",
      "finished training epoch 310\n",
      "train_loss:  1.980755170440195e-05 train_R2 0.8497891247856062\n",
      "finished training epoch 311\n",
      "train_loss:  1.863188945026744e-05 train_R2 0.8647520846869227\n",
      "finished training epoch 312\n",
      "train_loss:  1.989380757757167e-05 train_R2 0.8346855849119983\n",
      "finished training epoch 313\n",
      "train_loss:  2.2885843710830572e-05 train_R2 0.8099666943078082\n",
      "finished training epoch 314\n",
      "train_loss:  2.2955031799496653e-05 train_R2 0.46976433345575186\n",
      "finished training epoch 315\n",
      "train_loss:  2.3105991913317325e-05 train_R2 0.762113444092387\n",
      "finished training epoch 316\n",
      "train_loss:  2.013956372532489e-05 train_R2 0.7369130369794378\n",
      "finished training epoch 317\n",
      "train_loss:  1.8690691584576955e-05 train_R2 0.7114903077673608\n",
      "finished training epoch 318\n",
      "train_loss:  1.9108419097105663e-05 train_R2 0.8325105549810419\n",
      "finished training epoch 319\n",
      "train_loss:  2.06845688995701e-05 train_R2 0.706229181986012\n",
      "finished training epoch 320\n",
      "train_loss:  2.3877545601467402e-05 train_R2 0.8451146021311217\n",
      "finished training epoch 321\n",
      "train_loss:  2.2743879151127575e-05 train_R2 0.7723666827972419\n",
      "finished training epoch 322\n",
      "train_loss:  2.079815692985939e-05 train_R2 0.848276521483457\n",
      "finished training epoch 323\n",
      "train_loss:  1.8411657605117272e-05 train_R2 0.7346311686051996\n",
      "finished training epoch 324\n",
      "train_loss:  1.881499695732806e-05 train_R2 0.8199288900809032\n",
      "finished training epoch 325\n",
      "train_loss:  2.1691136786493705e-05 train_R2 0.8499102245346442\n",
      "finished training epoch 326\n",
      "train_loss:  2.0919627016857303e-05 train_R2 0.8463766749868876\n",
      "finished training epoch 327\n",
      "train_loss:  2.073075138894799e-05 train_R2 0.8278856888193175\n",
      "finished training epoch 328\n",
      "train_loss:  1.8326057464208133e-05 train_R2 0.7629267260268014\n",
      "finished training epoch 329\n",
      "train_loss:  1.785301647851258e-05 train_R2 0.8557994680770312\n",
      "finished training epoch 330\n",
      "train_loss:  1.8421742315078985e-05 train_R2 0.8329938988504118\n",
      "finished training epoch 331\n",
      "train_loss:  2.0026386620472976e-05 train_R2 0.6721591080261978\n",
      "finished training epoch 332\n",
      "train_loss:  2.1866985694284716e-05 train_R2 0.6964532220200421\n",
      "finished training epoch 333\n",
      "train_loss:  1.9982924833653232e-05 train_R2 0.73230362844194\n",
      "finished training epoch 334\n",
      "train_loss:  1.9071504791307113e-05 train_R2 0.7989792344618555\n",
      "finished training epoch 335\n",
      "train_loss:  1.7358170338054885e-05 train_R2 0.874277375596775\n",
      "finished training epoch 336\n",
      "train_loss:  1.7512467034857383e-05 train_R2 0.7089389324421345\n",
      "finished training epoch 337\n",
      "train_loss:  1.871923888482017e-05 train_R2 0.7577963381047905\n",
      "finished training epoch 338\n",
      "train_loss:  2.0179675038984902e-05 train_R2 0.7597574847634279\n",
      "finished training epoch 339\n",
      "train_loss:  2.0683657568670415e-05 train_R2 0.8443668253674872\n",
      "finished training epoch 340\n",
      "train_loss:  1.9407611608392948e-05 train_R2 0.8221956432280467\n",
      "finished training epoch 341\n",
      "train_loss:  1.7868997321177797e-05 train_R2 0.8443494142339195\n",
      "finished training epoch 342\n",
      "train_loss:  1.714498690429e-05 train_R2 0.8683248664466791\n",
      "finished training epoch 343\n",
      "train_loss:  1.763421660668975e-05 train_R2 0.7623831845482064\n",
      "finished training epoch 344\n",
      "train_loss:  1.847884671738133e-05 train_R2 0.7843895348377056\n",
      "finished training epoch 345\n",
      "train_loss:  1.9605920444991035e-05 train_R2 0.745841260096648\n",
      "finished training epoch 346\n",
      "train_loss:  1.918139206942503e-05 train_R2 0.8572744878014577\n",
      "finished training epoch 347\n",
      "train_loss:  1.8234915932656796e-05 train_R2 0.6538993125732937\n",
      "finished training epoch 348\n",
      "train_loss:  1.7446704729591952e-05 train_R2 0.8443121757367135\n",
      "finished training epoch 349\n",
      "train_loss:  1.8929168040177457e-05 train_R2 0.870019052672788\n",
      "finished training epoch 350\n",
      "train_loss:  1.89985766504581e-05 train_R2 0.7443988063365357\n",
      "finished training epoch 351\n",
      "train_loss:  2.1360624797792644e-05 train_R2 0.7775534283090024\n",
      "finished training epoch 352\n",
      "train_loss:  1.8889649482479308e-05 train_R2 0.7091419740399263\n",
      "finished training epoch 353\n",
      "train_loss:  1.7822886649107528e-05 train_R2 0.6165584423052954\n",
      "finished training epoch 354\n",
      "train_loss:  1.7406766647250775e-05 train_R2 0.6378372459268741\n",
      "finished training epoch 355\n",
      "train_loss:  1.743112685715448e-05 train_R2 0.8223147355248455\n",
      "finished training epoch 356\n",
      "train_loss:  1.8423962930017535e-05 train_R2 0.7974638247074766\n",
      "finished training epoch 357\n",
      "train_loss:  1.9018495307080005e-05 train_R2 0.7885336789206177\n",
      "finished training epoch 358\n",
      "train_loss:  1.875301085297055e-05 train_R2 0.8855423469576421\n",
      "finished training epoch 359\n",
      "train_loss:  1.8756536206918864e-05 train_R2 0.8686556836193461\n",
      "finished training epoch 360\n",
      "train_loss:  1.7666248592233926e-05 train_R2 0.8176906460698818\n",
      "finished training epoch 361\n",
      "train_loss:  1.662118880540064e-05 train_R2 0.7311928035756025\n",
      "finished training epoch 362\n",
      "train_loss:  1.69825005255464e-05 train_R2 0.8160344595278564\n",
      "finished training epoch 363\n",
      "train_loss:  1.8489871224836237e-05 train_R2 0.8230663730348472\n",
      "finished training epoch 364\n",
      "train_loss:  2.028718615351831e-05 train_R2 0.8126073992261836\n",
      "finished training epoch 365\n",
      "train_loss:  2.1435345169334217e-05 train_R2 0.8208461708295152\n",
      "finished training epoch 366\n",
      "train_loss:  1.883575110881389e-05 train_R2 0.7775767468963771\n",
      "finished training epoch 367\n",
      "train_loss:  1.7433191920705393e-05 train_R2 0.8498201446594338\n",
      "finished training epoch 368\n",
      "train_loss:  1.669909688240221e-05 train_R2 0.7068469222383209\n",
      "finished training epoch 369\n",
      "train_loss:  1.6995821939756534e-05 train_R2 0.8175596074707905\n",
      "finished training epoch 370\n",
      "train_loss:  1.7573501166056327e-05 train_R2 0.851859073461407\n",
      "finished training epoch 371\n",
      "train_loss:  1.8368005288810776e-05 train_R2 0.5924968112359255\n",
      "finished training epoch 372\n",
      "train_loss:  1.9500698260780163e-05 train_R2 0.8421802839328818\n",
      "finished training epoch 373\n",
      "train_loss:  1.811776072972342e-05 train_R2 0.6193432446422871\n",
      "finished training epoch 374\n",
      "train_loss:  1.738584765554705e-05 train_R2 0.8019332349119885\n",
      "finished training epoch 375\n",
      "train_loss:  1.651639166162572e-05 train_R2 0.787342322372433\n",
      "finished training epoch 376\n",
      "train_loss:  1.6634234974961784e-05 train_R2 0.8574340331568495\n",
      "finished training epoch 377\n",
      "train_loss:  2.0035372854012517e-05 train_R2 0.9031092221802817\n",
      "finished training epoch 378\n",
      "train_loss:  1.887507365005689e-05 train_R2 0.7727094788314262\n",
      "finished training epoch 379\n",
      "train_loss:  2.107404661220265e-05 train_R2 0.8239933477921433\n",
      "finished training epoch 380\n",
      "train_loss:  1.941820379244442e-05 train_R2 0.8007279091259807\n",
      "finished training epoch 381\n",
      "train_loss:  1.730685044428137e-05 train_R2 0.7886506544549259\n",
      "finished training epoch 382\n",
      "train_loss:  1.618539066749511e-05 train_R2 0.9134265940659949\n",
      "finished training epoch 383\n",
      "train_loss:  1.72171859666656e-05 train_R2 0.7895303915982939\n",
      "finished training epoch 384\n",
      "train_loss:  1.9498598819026902e-05 train_R2 0.7880468948932995\n",
      "finished training epoch 385\n",
      "train_loss:  1.9796529160517828e-05 train_R2 0.3714299643135712\n",
      "finished training epoch 386\n",
      "train_loss:  2.0849145397532488e-05 train_R2 0.8327828694746913\n",
      "finished training epoch 387\n",
      "train_loss:  1.8339501338693265e-05 train_R2 0.8351153283895423\n",
      "finished training epoch 388\n",
      "train_loss:  1.6985756921514163e-05 train_R2 0.8985206790177335\n",
      "finished training epoch 389\n",
      "train_loss:  1.6673472742001152e-05 train_R2 0.7315100004343502\n",
      "finished training epoch 390\n",
      "train_loss:  1.8446344294338945e-05 train_R2 0.7966874572748761\n",
      "finished training epoch 391\n",
      "train_loss:  2.1656444875228718e-05 train_R2 0.785594992279787\n",
      "finished training epoch 392\n",
      "train_loss:  2.00165949234163e-05 train_R2 0.5781039777549326\n",
      "finished training epoch 393\n",
      "train_loss:  1.8429590243331254e-05 train_R2 0.9141667478551465\n",
      "finished training epoch 394\n",
      "train_loss:  1.672843082565713e-05 train_R2 0.8132743093765511\n",
      "finished training epoch 395\n",
      "train_loss:  1.7201227081507766e-05 train_R2 0.8852798526975582\n",
      "finished training epoch 396\n",
      "train_loss:  1.990990075612041e-05 train_R2 0.7770837174244442\n",
      "finished training epoch 397\n",
      "train_loss:  1.9034252209596314e-05 train_R2 0.6571814590457576\n",
      "finished training epoch 398\n",
      "train_loss:  1.959843533492519e-05 train_R2 0.8656349315400658\n",
      "finished training epoch 399\n",
      "train_loss:  1.8823921027706372e-05 train_R2 0.7587093928701191\n",
      "finished training epoch 400\n",
      "train_loss:  1.707611421580985e-05 train_R2 0.88833833169966\n",
      "finished training epoch 401\n",
      "train_loss:  1.7051036670015626e-05 train_R2 0.86201761381031\n",
      "finished training epoch 402\n",
      "train_loss:  1.7543367356270293e-05 train_R2 0.7656230904430446\n",
      "finished training epoch 403\n",
      "train_loss:  1.8679596815020078e-05 train_R2 0.8110384371433865\n",
      "finished training epoch 404\n",
      "train_loss:  1.9252621022202993e-05 train_R2 0.7420535963323336\n",
      "finished training epoch 405\n",
      "train_loss:  1.872409656704372e-05 train_R2 0.8699295588969713\n",
      "finished training epoch 406\n",
      "train_loss:  1.7467028880399907e-05 train_R2 0.8348960767276119\n",
      "finished training epoch 407\n",
      "train_loss:  1.6850525261666484e-05 train_R2 0.8403415502693035\n",
      "finished training epoch 408\n",
      "train_loss:  1.6698674715347878e-05 train_R2 0.5997246021804663\n",
      "finished training epoch 409\n",
      "train_loss:  1.7639106620451256e-05 train_R2 0.8386377557652618\n",
      "finished training epoch 410\n",
      "train_loss:  1.99015053397247e-05 train_R2 0.8351053012765596\n",
      "finished training epoch 411\n",
      "train_loss:  1.9583938416437024e-05 train_R2 0.7189854887743772\n",
      "finished training epoch 412\n",
      "train_loss:  1.8864075082777013e-05 train_R2 0.8450730451464772\n",
      "finished training epoch 413\n",
      "train_loss:  1.73064961090683e-05 train_R2 0.8141332885517765\n",
      "finished training epoch 414\n",
      "train_loss:  1.6042728192737605e-05 train_R2 0.8881384362634401\n",
      "finished training epoch 415\n",
      "train_loss:  1.699209039921342e-05 train_R2 0.8584601848703557\n",
      "finished training epoch 416\n",
      "train_loss:  1.829119574842208e-05 train_R2 0.6644434298601738\n",
      "finished training epoch 417\n",
      "train_loss:  2.0577282620056735e-05 train_R2 0.7633715596116742\n",
      "finished training epoch 418\n",
      "train_loss:  1.828668157432103e-05 train_R2 0.6555528093550878\n",
      "finished training epoch 419\n",
      "train_loss:  1.6672842968382244e-05 train_R2 0.8159155858142451\n",
      "finished training epoch 420\n",
      "train_loss:  1.577339439497213e-05 train_R2 0.8726830812341568\n",
      "finished training epoch 421\n",
      "train_loss:  1.6947143497102414e-05 train_R2 0.8089628669361657\n",
      "finished training epoch 422\n",
      "train_loss:  1.80683595409777e-05 train_R2 0.8279194326116356\n",
      "finished training epoch 423\n",
      "train_loss:  1.8015790764943573e-05 train_R2 0.6976078415687654\n",
      "finished training epoch 424\n",
      "train_loss:  1.856520723692817e-05 train_R2 0.8266829876454342\n",
      "finished training epoch 425\n",
      "train_loss:  1.733425983199216e-05 train_R2 0.56241064051564\n",
      "finished training epoch 426\n",
      "train_loss:  1.6560814607119187e-05 train_R2 0.7867767809114629\n",
      "finished training epoch 427\n",
      "train_loss:  1.639332122190831e-05 train_R2 0.804471219568045\n",
      "finished training epoch 428\n",
      "train_loss:  1.6884359390457257e-05 train_R2 0.745014063828763\n",
      "finished training epoch 429\n",
      "train_loss:  1.8313832695236073e-05 train_R2 0.8375794279351506\n",
      "finished training epoch 430\n",
      "train_loss:  1.8025563437469608e-05 train_R2 0.7263802567881803\n",
      "finished training epoch 431\n",
      "train_loss:  1.8264894781052176e-05 train_R2 0.6567893650494131\n",
      "finished training epoch 432\n",
      "train_loss:  1.660847401157641e-05 train_R2 0.9054383096720726\n",
      "finished training epoch 433\n",
      "train_loss:  1.645419790840927e-05 train_R2 0.5357991526412456\n",
      "finished training epoch 434\n",
      "train_loss:  1.761800085758023e-05 train_R2 0.7874677449231124\n",
      "finished training epoch 435\n",
      "train_loss:  1.7011385003471876e-05 train_R2 0.769682432509272\n",
      "finished training epoch 436\n",
      "train_loss:  1.794483791009689e-05 train_R2 0.8644648227703037\n",
      "finished training epoch 437\n",
      "train_loss:  1.83813579475275e-05 train_R2 0.8138842255257409\n",
      "finished training epoch 438\n",
      "train_loss:  1.7293254960555474e-05 train_R2 0.8266625714654342\n",
      "finished training epoch 439\n",
      "train_loss:  1.663383400981419e-05 train_R2 0.8679352288518752\n",
      "finished training epoch 440\n",
      "train_loss:  1.560906239304127e-05 train_R2 0.7551548983282195\n",
      "finished training epoch 441\n",
      "train_loss:  1.5094104160613707e-05 train_R2 0.8946085271573647\n",
      "finished training epoch 442\n",
      "train_loss:  1.6083838246373767e-05 train_R2 0.7975639483601246\n",
      "finished training epoch 443\n",
      "train_loss:  1.7123406592111052e-05 train_R2 0.8524895300224946\n",
      "finished training epoch 444\n",
      "train_loss:  1.855442948390457e-05 train_R2 0.4659852358479335\n",
      "finished training epoch 445\n",
      "train_loss:  1.9322912347922754e-05 train_R2 0.8428352190427779\n",
      "finished training epoch 446\n",
      "train_loss:  1.7004250577890992e-05 train_R2 0.7532247063070058\n",
      "finished training epoch 447\n",
      "train_loss:  1.6527583861734374e-05 train_R2 0.7634559310948393\n",
      "finished training epoch 448\n",
      "train_loss:  1.58511033482862e-05 train_R2 0.8112884913326412\n",
      "finished training epoch 449\n",
      "train_loss:  1.703266697690322e-05 train_R2 0.7380798496675747\n",
      "finished training epoch 450\n",
      "train_loss:  1.9875416629372947e-05 train_R2 0.7970073153702163\n",
      "finished training epoch 451\n",
      "train_loss:  1.930457504600575e-05 train_R2 0.6980467296284635\n",
      "finished training epoch 452\n",
      "train_loss:  2.0765525136288514e-05 train_R2 0.8110554187926775\n",
      "finished training epoch 453\n",
      "train_loss:  1.688622591336503e-05 train_R2 0.744718493023956\n",
      "finished training epoch 454\n",
      "train_loss:  1.5618269017360785e-05 train_R2 0.785392181225463\n",
      "finished training epoch 455\n",
      "train_loss:  1.7150194269392318e-05 train_R2 0.7394489852890473\n",
      "finished training epoch 456\n",
      "train_loss:  1.908526244564578e-05 train_R2 0.7203688256931391\n",
      "finished training epoch 457\n",
      "train_loss:  2.3758633608194237e-05 train_R2 0.8448517088159215\n",
      "finished training epoch 458\n",
      "train_loss:  1.8337353927337962e-05 train_R2 0.7332251040672835\n",
      "finished training epoch 459\n",
      "train_loss:  1.737247326866341e-05 train_R2 0.8418397761827457\n",
      "finished training epoch 460\n",
      "train_loss:  1.9893835617713534e-05 train_R2 0.8651459825564329\n",
      "finished training epoch 461\n",
      "train_loss:  1.8439019847241578e-05 train_R2 0.8847088427252296\n",
      "finished training epoch 462\n",
      "train_loss:  1.7488175379310676e-05 train_R2 0.8017332054547542\n",
      "finished training epoch 463\n",
      "train_loss:  1.5808845217757673e-05 train_R2 0.7811077673686839\n",
      "finished training epoch 464\n",
      "train_loss:  1.5438768792268674e-05 train_R2 0.7425602815351633\n",
      "finished training epoch 465\n",
      "train_loss:  1.671539126082324e-05 train_R2 0.9126552894055489\n",
      "finished training epoch 466\n",
      "train_loss:  1.5733948607172647e-05 train_R2 0.62175572147614\n",
      "finished training epoch 467\n",
      "train_loss:  1.4993577817661025e-05 train_R2 0.9332711358858644\n",
      "finished training epoch 468\n",
      "train_loss:  1.5353252068614097e-05 train_R2 0.8421848644804169\n",
      "finished training epoch 469\n",
      "train_loss:  1.6130876370076117e-05 train_R2 0.713221181704645\n",
      "finished training epoch 470\n",
      "train_loss:  1.5732029825053693e-05 train_R2 0.7646119443535654\n",
      "finished training epoch 471\n",
      "train_loss:  1.5627866741247104e-05 train_R2 0.806306270769353\n",
      "finished training epoch 472\n",
      "train_loss:  1.5511008999318896e-05 train_R2 0.7736060867155479\n",
      "finished training epoch 473\n",
      "train_loss:  1.5387429375235474e-05 train_R2 0.6635737686426021\n",
      "finished training epoch 474\n",
      "train_loss:  1.5177236506099383e-05 train_R2 0.8917508773479104\n",
      "finished training epoch 475\n",
      "train_loss:  1.5155213244148007e-05 train_R2 0.7515549079158744\n",
      "finished training epoch 476\n",
      "train_loss:  1.4703114237586887e-05 train_R2 0.7940411216692127\n",
      "finished training epoch 477\n",
      "train_loss:  1.54795278183797e-05 train_R2 0.8978598742221873\n",
      "finished training epoch 478\n",
      "train_loss:  1.6101866414573855e-05 train_R2 0.8287982672533887\n",
      "finished training epoch 479\n",
      "train_loss:  1.668677792563801e-05 train_R2 0.6956433332845631\n",
      "finished training epoch 480\n",
      "train_loss:  1.9162178252521722e-05 train_R2 0.8425640045669056\n",
      "finished training epoch 481\n",
      "train_loss:  2.0180837648351093e-05 train_R2 0.6947133204882201\n",
      "finished training epoch 482\n",
      "train_loss:  2.0710020242544237e-05 train_R2 0.8529792249983614\n",
      "finished training epoch 483\n",
      "train_loss:  2.009471294434353e-05 train_R2 0.6665627928594678\n",
      "finished training epoch 484\n",
      "train_loss:  1.770294750752783e-05 train_R2 0.8084837069405979\n",
      "finished training epoch 485\n",
      "train_loss:  1.6458931708079277e-05 train_R2 0.876159672228446\n",
      "finished training epoch 486\n",
      "train_loss:  1.665451416106056e-05 train_R2 0.6640590112834109\n",
      "finished training epoch 487\n",
      "train_loss:  1.6645312287491725e-05 train_R2 0.8150191418880945\n",
      "finished training epoch 488\n",
      "train_loss:  1.6441653107977697e-05 train_R2 0.932504607178225\n",
      "finished training epoch 489\n",
      "train_loss:  1.79858534776096e-05 train_R2 0.9060799254456481\n",
      "finished training epoch 490\n",
      "train_loss:  1.8342848562228877e-05 train_R2 0.7922997857082716\n",
      "finished training epoch 491\n",
      "train_loss:  1.7094770138199286e-05 train_R2 0.8636796810059784\n",
      "finished training epoch 492\n",
      "train_loss:  1.580003225053955e-05 train_R2 0.62263607965822\n",
      "finished training epoch 493\n",
      "train_loss:  1.5257649289449242e-05 train_R2 0.7184489603923713\n",
      "finished training epoch 494\n",
      "train_loss:  1.5477403643151544e-05 train_R2 0.8926925460002754\n",
      "finished training epoch 495\n",
      "train_loss:  1.627192801969634e-05 train_R2 0.7330713256769601\n",
      "finished training epoch 496\n",
      "train_loss:  1.8230786452933796e-05 train_R2 0.809327364194002\n",
      "finished training epoch 497\n",
      "train_loss:  1.8658291082744307e-05 train_R2 0.6843838167219619\n",
      "finished training epoch 498\n",
      "train_loss:  2.045239493943251e-05 train_R2 0.8531946163690234\n",
      "finished training epoch 499\n",
      "train_loss:  1.7239197281841815e-05 train_R2 0.6785822367616221\n",
      "finished training epoch 500\n",
      "train_loss:  1.5323302127142937e-05 train_R2 0.894179205320072\n",
      "finished training epoch 501\n",
      "train_loss:  1.5953787317069346e-05 train_R2 0.8571679951401653\n",
      "finished training epoch 502\n",
      "train_loss:  1.7538984161589796e-05 train_R2 0.03283978421363354\n",
      "finished training epoch 503\n",
      "train_loss:  2.087245684603754e-05 train_R2 0.8050911312685924\n",
      "finished training epoch 504\n",
      "train_loss:  1.9088202885265612e-05 train_R2 0.5824636686105706\n",
      "finished training epoch 505\n",
      "train_loss:  1.770012355183596e-05 train_R2 0.8889573226537021\n",
      "finished training epoch 506\n",
      "train_loss:  1.5918746039738584e-05 train_R2 0.8696741796352441\n",
      "finished training epoch 507\n",
      "train_loss:  1.7072125707617108e-05 train_R2 0.6640371857788667\n",
      "finished training epoch 508\n",
      "train_loss:  2.0834912420688534e-05 train_R2 0.8402128967181108\n",
      "finished training epoch 509\n",
      "train_loss:  1.908884044687435e-05 train_R2 0.6503305545593534\n",
      "finished training epoch 510\n",
      "train_loss:  1.8316031667166894e-05 train_R2 0.8064768033636498\n",
      "finished training epoch 511\n",
      "train_loss:  1.7641391690573174e-05 train_R2 0.7681134524120975\n",
      "finished training epoch 512\n",
      "train_loss:  1.6620180983172246e-05 train_R2 0.8272642860689068\n",
      "finished training epoch 513\n",
      "train_loss:  1.65866948002913e-05 train_R2 0.8840902427898423\n",
      "finished training epoch 514\n",
      "train_loss:  1.7197406534187483e-05 train_R2 0.5611663444896728\n",
      "finished training epoch 515\n",
      "train_loss:  1.806057988905882e-05 train_R2 0.8204713196577997\n",
      "finished training epoch 516\n",
      "train_loss:  1.8254479893050986e-05 train_R2 0.832228766568869\n",
      "finished training epoch 517\n",
      "train_loss:  1.6710268760695883e-05 train_R2 0.8194727072915144\n",
      "finished training epoch 518\n",
      "train_loss:  1.5139828846317738e-05 train_R2 0.9146692752033325\n",
      "finished training epoch 519\n",
      "train_loss:  1.4879100549292805e-05 train_R2 0.8815672147567589\n",
      "finished training epoch 520\n",
      "train_loss:  1.574083808492782e-05 train_R2 0.8520207534657707\n",
      "finished training epoch 521\n",
      "train_loss:  1.6563172015815444e-05 train_R2 0.8095652234647653\n",
      "finished training epoch 522\n",
      "train_loss:  1.7477420570451365e-05 train_R2 0.7868155659986759\n",
      "finished training epoch 523\n",
      "train_loss:  1.5751370831839894e-05 train_R2 0.5649390044231104\n",
      "finished training epoch 524\n",
      "train_loss:  1.4969309931131156e-05 train_R2 0.8080900613311524\n",
      "finished training epoch 525\n",
      "train_loss:  1.4878477090831384e-05 train_R2 0.8496706366661964\n",
      "finished training epoch 526\n",
      "train_loss:  1.5156086668550671e-05 train_R2 0.8123006341488864\n",
      "finished training epoch 527\n",
      "train_loss:  1.542238175307599e-05 train_R2 0.8239553138640326\n",
      "finished training epoch 528\n",
      "train_loss:  1.60222374128707e-05 train_R2 0.8115247059842158\n",
      "finished training epoch 529\n",
      "train_loss:  1.6370727340357597e-05 train_R2 0.821168611191001\n",
      "finished training epoch 530\n",
      "train_loss:  1.6322153801995808e-05 train_R2 0.5839443432976251\n",
      "finished training epoch 531\n",
      "train_loss:  1.576612675590191e-05 train_R2 0.8939694298786658\n",
      "finished training epoch 532\n",
      "train_loss:  1.5230095922416248e-05 train_R2 0.6390731416160756\n",
      "finished training epoch 533\n",
      "train_loss:  1.488114908682311e-05 train_R2 0.9061485681016033\n",
      "finished training epoch 534\n",
      "train_loss:  1.4953112764008106e-05 train_R2 0.8743118659536453\n",
      "finished training epoch 535\n",
      "train_loss:  1.5071737181972721e-05 train_R2 0.7069931068793631\n",
      "finished training epoch 536\n",
      "train_loss:  1.5427067947429736e-05 train_R2 0.8904867867485824\n",
      "finished training epoch 537\n",
      "train_loss:  1.5669133368701515e-05 train_R2 0.8437327564519057\n",
      "finished training epoch 538\n",
      "train_loss:  1.5873382107588794e-05 train_R2 0.8786014059052685\n",
      "finished training epoch 539\n",
      "train_loss:  1.4963676121232693e-05 train_R2 0.7717388510665099\n",
      "finished training epoch 540\n",
      "train_loss:  1.4674641742924474e-05 train_R2 0.927635894328232\n",
      "finished training epoch 541\n",
      "train_loss:  1.488330463612445e-05 train_R2 0.7899652820782419\n",
      "finished training epoch 542\n",
      "train_loss:  1.5169471552352375e-05 train_R2 0.6099783009204304\n",
      "finished training epoch 543\n",
      "train_loss:  1.616313894010935e-05 train_R2 0.9124007250029901\n",
      "finished training epoch 544\n",
      "train_loss:  1.6692405230723928e-05 train_R2 0.764554058524026\n",
      "finished training epoch 545\n",
      "train_loss:  1.940623534310919e-05 train_R2 0.8546897580536288\n",
      "finished training epoch 546\n",
      "train_loss:  1.8083602514574965e-05 train_R2 0.6740093373181061\n",
      "finished training epoch 547\n",
      "train_loss:  1.7830674356841327e-05 train_R2 0.8181111867715942\n",
      "finished training epoch 548\n",
      "train_loss:  1.7453988221223376e-05 train_R2 0.7449914722852956\n",
      "finished training epoch 549\n",
      "train_loss:  1.6540824161584384e-05 train_R2 0.883408517672792\n",
      "finished training epoch 550\n",
      "train_loss:  1.6615093721625166e-05 train_R2 0.893595126243077\n",
      "finished training epoch 551\n",
      "train_loss:  1.7239163209879177e-05 train_R2 0.23027366185608333\n",
      "finished training epoch 552\n",
      "train_loss:  1.904358973884411e-05 train_R2 0.887963512704955\n",
      "finished training epoch 553\n",
      "train_loss:  1.7303967579208528e-05 train_R2 0.7946378524775305\n",
      "finished training epoch 554\n",
      "train_loss:  1.7456865944235138e-05 train_R2 0.8525761381479044\n",
      "finished training epoch 555\n",
      "train_loss:  1.672378967097421e-05 train_R2 0.5538838422573769\n",
      "finished training epoch 556\n",
      "train_loss:  1.632715990957103e-05 train_R2 0.8612198769146636\n",
      "finished training epoch 557\n",
      "train_loss:  1.495745957173247e-05 train_R2 0.8307989241403005\n",
      "finished training epoch 558\n",
      "train_loss:  1.608817700616134e-05 train_R2 0.7828653944208109\n",
      "finished training epoch 559\n",
      "train_loss:  1.7763544064483836e-05 train_R2 0.8728757025614039\n",
      "finished training epoch 560\n",
      "train_loss:  1.9104101402511474e-05 train_R2 0.7511888781868055\n",
      "finished training epoch 561\n",
      "train_loss:  1.9039579090772803e-05 train_R2 0.8765081878335422\n",
      "finished training epoch 562\n",
      "train_loss:  1.6766001473723895e-05 train_R2 0.7745378082467289\n",
      "finished training epoch 563\n",
      "train_loss:  1.5867392494024514e-05 train_R2 0.9047673648941224\n",
      "finished training epoch 564\n",
      "train_loss:  1.4960722335038233e-05 train_R2 0.8932820008029458\n",
      "finished training epoch 565\n",
      "train_loss:  1.652590044434294e-05 train_R2 0.8580262650824605\n",
      "finished training epoch 566\n",
      "train_loss:  1.963187983743802e-05 train_R2 0.8366140378530382\n",
      "finished training epoch 567\n",
      "train_loss:  1.894683792022016e-05 train_R2 0.7743639634225064\n",
      "finished training epoch 568\n",
      "train_loss:  1.918250534669643e-05 train_R2 0.8473644646979378\n",
      "finished training epoch 569\n",
      "train_loss:  1.651441183313124e-05 train_R2 0.6870244096702603\n",
      "finished training epoch 570\n",
      "train_loss:  1.5257223171548844e-05 train_R2 0.8330171086098268\n",
      "finished training epoch 571\n",
      "train_loss:  1.535383645642422e-05 train_R2 0.8795833964307257\n",
      "finished training epoch 572\n",
      "train_loss:  1.678949970073591e-05 train_R2 0.7871897745099775\n",
      "finished training epoch 573\n",
      "train_loss:  1.961357298483529e-05 train_R2 0.8555027036957635\n",
      "finished training epoch 574\n",
      "train_loss:  1.7316700585575398e-05 train_R2 0.7541216360571489\n",
      "finished training epoch 575\n",
      "train_loss:  1.5843066108602727e-05 train_R2 0.8600507487580237\n",
      "finished training epoch 576\n",
      "train_loss:  1.5140366297941571e-05 train_R2 0.8535344056445713\n",
      "finished training epoch 577\n",
      "train_loss:  1.6927057712087515e-05 train_R2 0.7404958217978823\n",
      "finished training epoch 578\n",
      "train_loss:  2.0677832045856515e-05 train_R2 0.8495427351296903\n",
      "finished training epoch 579\n",
      "train_loss:  1.6950033126221132e-05 train_R2 0.8932777444212914\n",
      "finished training epoch 580\n",
      "train_loss:  1.5263690717871292e-05 train_R2 0.8267194704864734\n",
      "finished training epoch 581\n",
      "train_loss:  1.620484208916334e-05 train_R2 0.883912858513724\n",
      "finished training epoch 582\n",
      "train_loss:  1.6227052279172137e-05 train_R2 0.7091871532860291\n",
      "finished training epoch 583\n",
      "train_loss:  1.6737520140747394e-05 train_R2 0.8138344631727015\n",
      "finished training epoch 584\n",
      "train_loss:  1.5327026069205745e-05 train_R2 0.763347241493179\n",
      "finished training epoch 585\n",
      "train_loss:  1.5406060051131414e-05 train_R2 0.8807279342987206\n",
      "finished training epoch 586\n",
      "train_loss:  1.5405377242587763e-05 train_R2 0.8637913370951324\n",
      "finished training epoch 587\n",
      "train_loss:  1.5279326955373332e-05 train_R2 0.8117115591686989\n",
      "finished training epoch 588\n",
      "train_loss:  1.4143612317320405e-05 train_R2 0.858011624308407\n",
      "finished training epoch 589\n",
      "train_loss:  1.5169944129922293e-05 train_R2 0.7718873737264265\n",
      "finished training epoch 590\n",
      "train_loss:  1.555807694079292e-05 train_R2 0.8522853557615302\n",
      "finished training epoch 591\n",
      "train_loss:  1.621888345911342e-05 train_R2 0.8337033595539654\n",
      "finished training epoch 592\n",
      "train_loss:  1.603324559475995e-05 train_R2 0.8140835137408275\n",
      "finished training epoch 593\n",
      "train_loss:  1.5374620812339313e-05 train_R2 0.8914374781592564\n",
      "finished training epoch 594\n",
      "train_loss:  1.4660901504403646e-05 train_R2 0.874972651908971\n",
      "finished training epoch 595\n",
      "train_loss:  1.4147951225050906e-05 train_R2 0.8611432801857065\n",
      "finished training epoch 596\n",
      "train_loss:  1.4232038985013495e-05 train_R2 0.8891352530823636\n",
      "finished training epoch 597\n",
      "train_loss:  1.4498214705843286e-05 train_R2 0.7140696664809449\n",
      "finished training epoch 598\n",
      "train_loss:  1.5161309802819834e-05 train_R2 0.8690216655458871\n",
      "finished training epoch 599\n",
      "train_loss:  1.574346016070213e-05 train_R2 0.8689151864330806\n",
      "finished training epoch 600\n",
      "train_loss:  1.6199188880559565e-05 train_R2 0.7030446678374965\n",
      "finished training epoch 601\n",
      "train_loss:  1.580294650721115e-05 train_R2 0.8218772373008056\n",
      "finished training epoch 602\n",
      "train_loss:  1.4791188869585025e-05 train_R2 0.7279392660523737\n",
      "finished training epoch 603\n",
      "train_loss:  1.4621823827985742e-05 train_R2 0.801138725660809\n",
      "finished training epoch 604\n",
      "train_loss:  1.4518245372513033e-05 train_R2 0.8567013463529778\n",
      "finished training epoch 605\n",
      "train_loss:  1.4412223307485676e-05 train_R2 0.7867731614827105\n",
      "finished training epoch 606\n",
      "train_loss:  1.4522994971427877e-05 train_R2 0.8250737587669131\n",
      "finished training epoch 607\n",
      "train_loss:  1.437234686923747e-05 train_R2 0.8766128038684657\n",
      "finished training epoch 608\n",
      "train_loss:  1.4497665181483244e-05 train_R2 0.8586057431370027\n",
      "finished training epoch 609\n",
      "train_loss:  1.4049055268756969e-05 train_R2 0.8907463144904049\n",
      "finished training epoch 610\n",
      "train_loss:  1.3839504441885413e-05 train_R2 0.8643868202710158\n",
      "finished training epoch 611\n",
      "train_loss:  1.390581507130472e-05 train_R2 0.8694830508490465\n",
      "finished training epoch 612\n",
      "train_loss:  1.4101617089947032e-05 train_R2 0.903782955764801\n",
      "finished training epoch 613\n",
      "train_loss:  1.3796831724995738e-05 train_R2 0.7748254395890386\n",
      "finished training epoch 614\n",
      "train_loss:  1.4393514643766997e-05 train_R2 0.8346266082713669\n",
      "finished training epoch 615\n",
      "train_loss:  1.4355782206255961e-05 train_R2 0.8854229316474327\n",
      "finished training epoch 616\n",
      "train_loss:  1.4161897143519407e-05 train_R2 0.6272830649338687\n",
      "finished training epoch 617\n",
      "train_loss:  1.429995558278582e-05 train_R2 0.7519852757070551\n",
      "finished training epoch 618\n",
      "train_loss:  1.3688750290534552e-05 train_R2 0.8747340508146764\n",
      "finished training epoch 619\n",
      "train_loss:  1.4031480842304587e-05 train_R2 0.8048448678473943\n",
      "finished training epoch 620\n",
      "train_loss:  1.406018417501776e-05 train_R2 0.8245988054143768\n",
      "finished training epoch 621\n",
      "train_loss:  1.4040282599070617e-05 train_R2 0.8000152978671842\n",
      "finished training epoch 622\n",
      "train_loss:  1.4188471507688112e-05 train_R2 0.8664894851872118\n",
      "finished training epoch 623\n",
      "train_loss:  1.4112494850489327e-05 train_R2 0.7076256647301726\n",
      "finished training epoch 624\n",
      "train_loss:  1.3945221325453834e-05 train_R2 0.7237213899412522\n",
      "finished training epoch 625\n",
      "train_loss:  1.3769142266554938e-05 train_R2 0.8689484669866341\n",
      "finished training epoch 626\n",
      "train_loss:  1.4206700370002386e-05 train_R2 0.838615126417332\n",
      "finished training epoch 627\n",
      "train_loss:  1.3981363050414429e-05 train_R2 0.90696286637324\n",
      "finished training epoch 628\n",
      "train_loss:  1.4244999277186257e-05 train_R2 0.785236733829117\n",
      "finished training epoch 629\n",
      "train_loss:  1.381100628057451e-05 train_R2 0.7311293032414801\n",
      "finished training epoch 630\n",
      "train_loss:  1.4142116824922897e-05 train_R2 0.6725550206835629\n",
      "finished training epoch 631\n",
      "train_loss:  1.3924902203280452e-05 train_R2 0.861460725072459\n",
      "finished training epoch 632\n",
      "train_loss:  1.3885931476385416e-05 train_R2 0.7564551324517301\n",
      "finished training epoch 633\n",
      "train_loss:  1.4040941452371166e-05 train_R2 0.849443390474213\n",
      "finished training epoch 634\n",
      "train_loss:  1.4173412348884585e-05 train_R2 0.8204791994789578\n",
      "finished training epoch 635\n",
      "train_loss:  1.4202063010409504e-05 train_R2 0.7950427184733396\n",
      "finished training epoch 636\n",
      "train_loss:  1.4247527779599864e-05 train_R2 0.8586666388215222\n",
      "finished training epoch 637\n",
      "train_loss:  1.4065675998142901e-05 train_R2 0.8614365555342243\n",
      "finished training epoch 638\n",
      "train_loss:  1.4253316540541053e-05 train_R2 0.8662985584395295\n",
      "finished training epoch 639\n",
      "train_loss:  1.375267896246411e-05 train_R2 0.7666335801569033\n",
      "finished training epoch 640\n",
      "train_loss:  1.4335036218079695e-05 train_R2 0.919554066574455\n",
      "finished training epoch 641\n",
      "train_loss:  1.379758818857905e-05 train_R2 0.8415853694150478\n",
      "finished training epoch 642\n",
      "train_loss:  1.4048262320170218e-05 train_R2 0.8631392609053576\n",
      "finished training epoch 643\n",
      "train_loss:  1.4013405848410481e-05 train_R2 0.8559998004131916\n",
      "finished training epoch 644\n",
      "train_loss:  1.3973814418685533e-05 train_R2 0.8424903120443306\n",
      "finished training epoch 645\n",
      "train_loss:  1.4214597691489705e-05 train_R2 0.780723782031947\n",
      "finished training epoch 646\n",
      "train_loss:  1.4052120743578812e-05 train_R2 0.8575532322874109\n",
      "finished training epoch 647\n",
      "train_loss:  1.3848186119492988e-05 train_R2 0.8365964139636817\n",
      "finished training epoch 648\n",
      "train_loss:  1.3954387370661368e-05 train_R2 0.8272653839525717\n",
      "finished training epoch 649\n",
      "train_loss:  1.3968238880062435e-05 train_R2 0.8599843514292616\n",
      "finished training epoch 650\n",
      "train_loss:  1.3898654453242047e-05 train_R2 0.7872212623323731\n",
      "finished training epoch 651\n",
      "train_loss:  1.4001228464501395e-05 train_R2 0.8913156677692355\n",
      "finished training epoch 652\n",
      "train_loss:  1.4160759334270087e-05 train_R2 0.7530579165362248\n",
      "finished training epoch 653\n",
      "train_loss:  1.4078058014791879e-05 train_R2 0.7730257990810667\n",
      "finished training epoch 654\n",
      "train_loss:  1.3813716333467462e-05 train_R2 0.8272269825124269\n",
      "finished training epoch 655\n",
      "train_loss:  1.386321750860315e-05 train_R2 0.857094765697985\n",
      "finished training epoch 656\n",
      "train_loss:  1.3962437116198695e-05 train_R2 0.7679007605201549\n",
      "finished training epoch 657\n",
      "train_loss:  1.3731932407909113e-05 train_R2 0.8486459921589062\n",
      "finished training epoch 658\n",
      "train_loss:  1.3964433166806874e-05 train_R2 0.7619658922201975\n",
      "finished training epoch 659\n",
      "train_loss:  1.3906226632767195e-05 train_R2 0.8706659267023288\n",
      "finished training epoch 660\n",
      "train_loss:  1.3753312980855432e-05 train_R2 0.7764624658398143\n",
      "finished training epoch 661\n",
      "train_loss:  1.3681243545938537e-05 train_R2 0.89828454072332\n",
      "finished training epoch 662\n",
      "train_loss:  1.4342693344462989e-05 train_R2 0.7962476934916631\n",
      "finished training epoch 663\n",
      "train_loss:  1.3957643032897299e-05 train_R2 0.8701442714032113\n",
      "finished training epoch 664\n",
      "train_loss:  1.3557501750315559e-05 train_R2 0.8683716835880251\n",
      "finished training epoch 665\n",
      "train_loss:  1.4404856304502293e-05 train_R2 0.9097588363406289\n",
      "finished training epoch 666\n",
      "train_loss:  1.4945473158696468e-05 train_R2 0.8443215136276502\n",
      "finished training epoch 667\n",
      "train_loss:  1.5148577126528946e-05 train_R2 0.744179595412231\n",
      "finished training epoch 668\n",
      "train_loss:  1.4870643865726025e-05 train_R2 0.9019641553542822\n",
      "finished training epoch 669\n",
      "train_loss:  1.3961126845977323e-05 train_R2 0.8619312079802852\n",
      "finished training epoch 670\n",
      "train_loss:  1.418051728950551e-05 train_R2 0.8753274769982555\n",
      "finished training epoch 671\n",
      "train_loss:  1.405889718808972e-05 train_R2 0.8767449356255612\n",
      "finished training epoch 672\n",
      "train_loss:  1.4688853050406239e-05 train_R2 0.730653183296743\n",
      "finished training epoch 673\n",
      "train_loss:  1.4522861704533736e-05 train_R2 0.8308740816838931\n",
      "finished training epoch 674\n",
      "train_loss:  1.4703852298596406e-05 train_R2 0.8984245624448627\n",
      "finished training epoch 675\n",
      "train_loss:  1.4701629226013707e-05 train_R2 0.8096446389386514\n",
      "finished training epoch 676\n",
      "train_loss:  1.463735748509851e-05 train_R2 0.8560931296466425\n",
      "finished training epoch 677\n",
      "train_loss:  1.4069545722441285e-05 train_R2 0.7948382712340584\n",
      "finished training epoch 678\n",
      "train_loss:  1.385573666549309e-05 train_R2 0.8058415181140491\n",
      "finished training epoch 679\n",
      "train_loss:  1.4036163307291168e-05 train_R2 0.8919637965603109\n",
      "finished training epoch 680\n",
      "train_loss:  1.4160970619437512e-05 train_R2 0.8766662122716289\n",
      "finished training epoch 681\n",
      "train_loss:  1.4996805941952127e-05 train_R2 0.7154218094388713\n",
      "finished training epoch 682\n",
      "train_loss:  1.5670305675907083e-05 train_R2 0.8390700853573202\n",
      "finished training epoch 683\n",
      "train_loss:  1.5142176371095607e-05 train_R2 0.8038720629390007\n",
      "finished training epoch 684\n",
      "train_loss:  1.4935474540846825e-05 train_R2 0.8241596739434289\n",
      "finished training epoch 685\n",
      "train_loss:  1.4409331086883255e-05 train_R2 0.8144171639603099\n",
      "finished training epoch 686\n",
      "train_loss:  1.4202157867243106e-05 train_R2 0.7358792267698768\n",
      "finished training epoch 687\n",
      "train_loss:  1.421225760024846e-05 train_R2 0.6634712795785871\n",
      "finished training epoch 688\n",
      "train_loss:  1.538962879380296e-05 train_R2 0.6996955243896561\n",
      "finished training epoch 689\n",
      "train_loss:  1.6810156103479644e-05 train_R2 0.8161061104914313\n",
      "finished training epoch 690\n",
      "train_loss:  1.5618953695263026e-05 train_R2 0.6404593194852557\n",
      "finished training epoch 691\n",
      "train_loss:  1.4573147467398294e-05 train_R2 0.8931155807120096\n",
      "finished training epoch 692\n",
      "train_loss:  1.403987961984662e-05 train_R2 0.8698512644246905\n",
      "finished training epoch 693\n",
      "train_loss:  1.4552010230705584e-05 train_R2 0.7658966656156317\n",
      "finished training epoch 694\n",
      "train_loss:  1.544121129260409e-05 train_R2 0.8676941942237418\n",
      "finished training epoch 695\n",
      "train_loss:  1.5413363031375472e-05 train_R2 0.7500842253843425\n",
      "finished training epoch 696\n",
      "train_loss:  1.4543556762868464e-05 train_R2 0.9133027291295156\n",
      "finished training epoch 697\n",
      "train_loss:  1.3904562730566698e-05 train_R2 0.8147519929984679\n",
      "finished training epoch 698\n",
      "train_loss:  1.384626488958679e-05 train_R2 0.8327809281759772\n",
      "finished training epoch 699\n",
      "train_loss:  1.4621950354072767e-05 train_R2 0.7894225525699996\n",
      "finished training epoch 700\n",
      "train_loss:  1.401594191661624e-05 train_R2 0.7848394561169305\n",
      "finished training epoch 701\n",
      "train_loss:  1.4327207989114498e-05 train_R2 0.8908110195156866\n",
      "finished training epoch 702\n",
      "train_loss:  1.3888385808277622e-05 train_R2 0.8106285626617908\n",
      "finished training epoch 703\n",
      "train_loss:  1.390431891947641e-05 train_R2 0.9183243546239348\n",
      "finished training epoch 704\n",
      "train_loss:  1.4470407053862519e-05 train_R2 0.8506730959112987\n",
      "finished training epoch 705\n",
      "train_loss:  1.4368120517491137e-05 train_R2 0.8335724166048033\n",
      "finished training epoch 706\n",
      "train_loss:  1.3931001678666857e-05 train_R2 0.887810807950221\n",
      "finished training epoch 707\n",
      "train_loss:  1.398839818292666e-05 train_R2 0.7074850143375265\n",
      "finished training epoch 708\n",
      "train_loss:  1.3715288307476783e-05 train_R2 0.8825709361766934\n",
      "finished training epoch 709\n",
      "train_loss:  1.3777127944071874e-05 train_R2 0.901927865937661\n",
      "finished training epoch 710\n",
      "train_loss:  1.4054660001954132e-05 train_R2 0.8191874277185757\n",
      "finished training epoch 711\n",
      "train_loss:  1.4284902354854182e-05 train_R2 0.7867062370167732\n",
      "finished training epoch 712\n",
      "train_loss:  1.3709987715466374e-05 train_R2 0.862169870499544\n",
      "finished training epoch 713\n",
      "train_loss:  1.3764850019878946e-05 train_R2 0.8296183434316167\n",
      "finished training epoch 714\n",
      "train_loss:  1.3574667470688455e-05 train_R2 0.889198353754944\n",
      "finished training epoch 715\n",
      "train_loss:  1.4047142262777989e-05 train_R2 0.844931110137432\n",
      "finished training epoch 716\n",
      "train_loss:  1.457538960123536e-05 train_R2 0.8728544962143617\n",
      "finished training epoch 717\n",
      "train_loss:  1.4059728832933071e-05 train_R2 0.8528665728123815\n",
      "finished training epoch 718\n",
      "train_loss:  1.4414949554980653e-05 train_R2 0.7986821660709048\n",
      "finished training epoch 719\n",
      "train_loss:  1.3794779145363152e-05 train_R2 0.7228209495221427\n",
      "finished training epoch 720\n",
      "train_loss:  1.4180397414976985e-05 train_R2 0.8123510438008568\n",
      "finished training epoch 721\n",
      "train_loss:  1.4363668450744155e-05 train_R2 0.8885393681720574\n",
      "finished training epoch 722\n",
      "train_loss:  1.4272188707948314e-05 train_R2 0.8422850429905068\n",
      "finished training epoch 723\n",
      "train_loss:  1.4192739346001995e-05 train_R2 0.8520728279117419\n",
      "finished training epoch 724\n",
      "train_loss:  1.343120928008105e-05 train_R2 0.9001338968282218\n",
      "finished training epoch 725\n",
      "train_loss:  1.4066864672588044e-05 train_R2 0.810102143113866\n",
      "finished training epoch 726\n",
      "train_loss:  1.4056047766184817e-05 train_R2 0.9185225228977383\n",
      "finished training epoch 727\n",
      "train_loss:  1.4324361482201989e-05 train_R2 0.8769175564616278\n",
      "finished training epoch 728\n",
      "train_loss:  1.435095544328576e-05 train_R2 0.8781506350226561\n",
      "finished training epoch 729\n",
      "train_loss:  1.4117416650926966e-05 train_R2 0.8144014382500713\n",
      "finished training epoch 730\n",
      "train_loss:  1.4219826486210934e-05 train_R2 0.8672850844648019\n",
      "finished training epoch 731\n",
      "train_loss:  1.3861208279249297e-05 train_R2 0.8669429811320599\n",
      "finished training epoch 732\n",
      "train_loss:  1.4088908749345925e-05 train_R2 0.8582445125980962\n",
      "finished training epoch 733\n",
      "train_loss:  1.3803801294741774e-05 train_R2 0.8320297938804371\n",
      "finished training epoch 734\n",
      "train_loss:  1.4127797328426284e-05 train_R2 0.7368615612360172\n",
      "finished training epoch 735\n",
      "train_loss:  1.390432157229639e-05 train_R2 0.8891952761343489\n",
      "finished training epoch 736\n",
      "train_loss:  1.3953246234767443e-05 train_R2 0.8354413451067777\n",
      "finished training epoch 737\n",
      "train_loss:  1.4216592606606111e-05 train_R2 0.8807404731527839\n",
      "finished training epoch 738\n",
      "train_loss:  1.4284331029879443e-05 train_R2 0.8218941806835124\n",
      "finished training epoch 739\n",
      "train_loss:  1.4079722679874866e-05 train_R2 0.8883923170481183\n",
      "finished training epoch 740\n",
      "train_loss:  1.3730759155507159e-05 train_R2 0.7710546177720609\n",
      "finished training epoch 741\n",
      "train_loss:  1.4121457575590298e-05 train_R2 0.9039609428606408\n",
      "finished training epoch 742\n",
      "train_loss:  1.3480586439983347e-05 train_R2 0.7404295313776423\n",
      "finished training epoch 743\n",
      "train_loss:  1.3519570332350041e-05 train_R2 0.8885530590544856\n",
      "finished training epoch 744\n",
      "train_loss:  1.3547011390652435e-05 train_R2 0.8278928463071727\n",
      "finished training epoch 745\n",
      "train_loss:  1.3887061446516015e-05 train_R2 0.8333575112480036\n",
      "finished training epoch 746\n",
      "train_loss:  1.4257623169583311e-05 train_R2 0.8515785042120276\n",
      "finished training epoch 747\n",
      "train_loss:  1.4605303120258857e-05 train_R2 0.8034599372964086\n",
      "finished training epoch 748\n",
      "train_loss:  1.5253638351008644e-05 train_R2 0.8377781700690468\n",
      "finished training epoch 749\n",
      "train_loss:  1.508169304072987e-05 train_R2 0.7476180892352533\n",
      "finished training epoch 750\n",
      "train_loss:  1.466791206828314e-05 train_R2 0.862041863288562\n",
      "finished training epoch 751\n",
      "train_loss:  1.402256402198927e-05 train_R2 0.878356822401123\n",
      "finished training epoch 752\n",
      "train_loss:  1.3464175770299642e-05 train_R2 0.856908717825181\n",
      "finished training epoch 753\n",
      "train_loss:  1.3813710976777106e-05 train_R2 0.9082789178361417\n",
      "finished training epoch 754\n",
      "train_loss:  1.4471933851399136e-05 train_R2 0.8864815399015012\n",
      "finished training epoch 755\n",
      "train_loss:  1.4815559770379314e-05 train_R2 0.8790137926307748\n",
      "finished training epoch 756\n",
      "train_loss:  1.476418563964848e-05 train_R2 0.804898505294891\n",
      "finished training epoch 757\n",
      "train_loss:  1.4196845043940975e-05 train_R2 0.8871429209267099\n",
      "finished training epoch 758\n",
      "train_loss:  1.371998462946648e-05 train_R2 0.8647684642372127\n",
      "finished training epoch 759\n",
      "train_loss:  1.3853232909144852e-05 train_R2 0.872351501229571\n",
      "finished training epoch 760\n",
      "train_loss:  1.4808785485095828e-05 train_R2 0.8149761470029526\n",
      "finished training epoch 761\n",
      "train_loss:  1.5076676800061665e-05 train_R2 0.8246991309220522\n",
      "finished training epoch 762\n",
      "train_loss:  1.5748378726984055e-05 train_R2 0.8725324679467347\n",
      "finished training epoch 763\n",
      "train_loss:  1.4246058833382768e-05 train_R2 0.801884648273353\n",
      "finished training epoch 764\n",
      "train_loss:  1.358732956293787e-05 train_R2 0.8925908130149043\n",
      "finished training epoch 765\n",
      "train_loss:  1.4039544923817917e-05 train_R2 0.8922724644648763\n",
      "finished training epoch 766\n",
      "train_loss:  1.4125976982111503e-05 train_R2 0.8442196401822403\n",
      "finished training epoch 767\n",
      "train_loss:  1.4093405847750135e-05 train_R2 0.8509333819727757\n",
      "finished training epoch 768\n",
      "train_loss:  1.404943583479881e-05 train_R2 0.7355654216866176\n",
      "finished training epoch 769\n",
      "train_loss:  1.3235000053764294e-05 train_R2 0.9079483709594304\n",
      "finished training epoch 770\n",
      "train_loss:  1.3375234220335094e-05 train_R2 0.8926117128357806\n",
      "finished training epoch 771\n",
      "train_loss:  1.3871614354693969e-05 train_R2 0.8146099088294145\n",
      "finished training epoch 772\n",
      "train_loss:  1.3890029969863902e-05 train_R2 0.873546211758722\n",
      "finished training epoch 773\n",
      "train_loss:  1.316412380364711e-05 train_R2 0.8829270126862385\n",
      "finished training epoch 774\n",
      "train_loss:  1.3551647531302832e-05 train_R2 0.865668259139085\n",
      "finished training epoch 775\n",
      "train_loss:  1.3595097578917478e-05 train_R2 0.7377265212719111\n",
      "finished training epoch 776\n",
      "train_loss:  1.3565078953472142e-05 train_R2 0.8156395754132306\n",
      "finished training epoch 777\n",
      "train_loss:  1.3556187097236636e-05 train_R2 0.8092139543220257\n",
      "finished training epoch 778\n",
      "train_loss:  1.3564854333673714e-05 train_R2 0.9009054584732374\n",
      "finished training epoch 779\n",
      "train_loss:  1.3663946696990163e-05 train_R2 0.8768774850814448\n",
      "finished training epoch 780\n",
      "train_loss:  1.3777687383546654e-05 train_R2 0.7126723502978547\n",
      "finished training epoch 781\n",
      "train_loss:  1.3452705425625304e-05 train_R2 0.9032602351736557\n",
      "finished training epoch 782\n",
      "train_loss:  1.3460138415558666e-05 train_R2 0.8499688597233186\n",
      "finished training epoch 783\n",
      "train_loss:  1.369329330094791e-05 train_R2 0.8561030778322158\n",
      "finished training epoch 784\n",
      "train_loss:  1.3906731240845064e-05 train_R2 0.8798813923275473\n",
      "finished training epoch 785\n",
      "train_loss:  1.4003551224675996e-05 train_R2 0.9020788153017465\n",
      "finished training epoch 786\n",
      "train_loss:  1.371393994506777e-05 train_R2 0.9158347431485804\n",
      "finished training epoch 787\n",
      "train_loss:  1.3190630717328038e-05 train_R2 0.8947761870276528\n",
      "finished training epoch 788\n",
      "train_loss:  1.3291849980778782e-05 train_R2 0.8243114986457818\n",
      "finished training epoch 789\n",
      "train_loss:  1.344724411252211e-05 train_R2 0.86325507022464\n",
      "finished training epoch 790\n",
      "train_loss:  1.3498835936364226e-05 train_R2 0.8135460652678469\n",
      "finished training epoch 791\n",
      "train_loss:  1.403665917961473e-05 train_R2 0.755972545181205\n",
      "finished training epoch 792\n",
      "train_loss:  1.564111827344594e-05 train_R2 0.9162467601231612\n",
      "finished training epoch 793\n",
      "train_loss:  1.5487263483696944e-05 train_R2 0.801478678833333\n",
      "finished training epoch 794\n",
      "train_loss:  1.6400739075183644e-05 train_R2 0.8667667483215873\n",
      "finished training epoch 795\n",
      "train_loss:  1.5332191151924067e-05 train_R2 0.7282705015870308\n",
      "finished training epoch 796\n",
      "train_loss:  1.4709962275775658e-05 train_R2 0.8803910642364093\n",
      "finished training epoch 797\n",
      "train_loss:  1.4463955188211537e-05 train_R2 0.8786482462424806\n",
      "finished training epoch 798\n",
      "train_loss:  1.4545650346794986e-05 train_R2 0.8507932779569172\n",
      "finished training epoch 799\n",
      "train_loss:  1.3744548195799389e-05 train_R2 0.8917547210026602\n",
      "finished training epoch 800\n",
      "train_loss:  1.4256213961762435e-05 train_R2 0.730532361850126\n",
      "finished training epoch 801\n",
      "train_loss:  1.4356947699102851e-05 train_R2 0.7593345785939982\n",
      "finished training epoch 802\n",
      "train_loss:  1.417688449933321e-05 train_R2 0.8839158159179608\n",
      "finished training epoch 803\n",
      "train_loss:  1.4052278977918475e-05 train_R2 0.8818804577820514\n",
      "finished training epoch 804\n",
      "train_loss:  1.3310341296345036e-05 train_R2 0.8020568324123647\n",
      "finished training epoch 805\n",
      "train_loss:  1.3228685446916197e-05 train_R2 0.793729186565903\n",
      "finished training epoch 806\n",
      "train_loss:  1.3796491680589441e-05 train_R2 0.825438986439321\n",
      "finished training epoch 807\n",
      "train_loss:  1.3702269569865076e-05 train_R2 0.7898018030474031\n",
      "finished training epoch 808\n",
      "train_loss:  1.3968531045674859e-05 train_R2 0.9054417286368808\n",
      "finished training epoch 809\n",
      "train_loss:  1.3308289644316536e-05 train_R2 0.8661994524347058\n",
      "finished training epoch 810\n",
      "train_loss:  1.3730623203609131e-05 train_R2 0.8995307746948549\n",
      "finished training epoch 811\n",
      "train_loss:  1.3722603350909099e-05 train_R2 0.7604994142683297\n",
      "finished training epoch 812\n",
      "train_loss:  1.3442094120939171e-05 train_R2 0.89469210158623\n",
      "finished training epoch 813\n",
      "train_loss:  1.3577077118528911e-05 train_R2 0.9141692758756566\n",
      "finished training epoch 814\n",
      "train_loss:  1.3940832454644777e-05 train_R2 0.8468656933489951\n",
      "finished training epoch 815\n",
      "train_loss:  1.4318190732883344e-05 train_R2 0.8359054463244056\n",
      "finished training epoch 816\n",
      "train_loss:  1.3903624051647227e-05 train_R2 0.9022105467791166\n",
      "finished training epoch 817\n",
      "train_loss:  1.3894088568723061e-05 train_R2 0.88579050350427\n",
      "finished training epoch 818\n",
      "train_loss:  1.3471412455143055e-05 train_R2 0.8407282241272126\n",
      "finished training epoch 819\n",
      "train_loss:  1.361358131426805e-05 train_R2 0.8852258494638987\n",
      "finished training epoch 820\n",
      "train_loss:  1.3442992706597012e-05 train_R2 0.8469549742475901\n",
      "finished training epoch 821\n",
      "train_loss:  1.3259428057721804e-05 train_R2 0.8249520974112936\n",
      "finished training epoch 822\n",
      "train_loss:  1.3805604385579396e-05 train_R2 0.879938230265149\n",
      "finished training epoch 823\n",
      "train_loss:  1.3926205889511122e-05 train_R2 0.7264805011702138\n",
      "finished training epoch 824\n",
      "train_loss:  1.4405144019545393e-05 train_R2 0.8833319164022925\n",
      "finished training epoch 825\n",
      "train_loss:  1.4351295358769169e-05 train_R2 0.7629331459401351\n",
      "finished training epoch 826\n",
      "train_loss:  1.4382874988607938e-05 train_R2 0.8693659901682474\n",
      "finished training epoch 827\n",
      "train_loss:  1.3962584399455392e-05 train_R2 0.8074925406770627\n",
      "finished training epoch 828\n",
      "train_loss:  1.3535695946160511e-05 train_R2 0.8762021347511644\n",
      "finished training epoch 829\n",
      "train_loss:  1.369872983291707e-05 train_R2 0.8913035661285931\n",
      "finished training epoch 830\n",
      "train_loss:  1.3781809508879575e-05 train_R2 0.8633166974724771\n",
      "finished training epoch 831\n",
      "train_loss:  1.4086070322034285e-05 train_R2 0.8490106749003202\n",
      "finished training epoch 832\n",
      "train_loss:  1.3497568787910644e-05 train_R2 0.9109445106977333\n",
      "finished training epoch 833\n",
      "train_loss:  1.4438086451753094e-05 train_R2 0.8941636237438142\n",
      "finished training epoch 834\n",
      "train_loss:  1.3828991389862565e-05 train_R2 0.8445320292286649\n",
      "finished training epoch 835\n",
      "train_loss:  1.3748681471149431e-05 train_R2 0.8513497112305265\n",
      "finished training epoch 836\n",
      "train_loss:  1.3302080185685315e-05 train_R2 0.8584956244931711\n",
      "finished training epoch 837\n",
      "train_loss:  1.3288942185063213e-05 train_R2 0.9182606263288762\n",
      "finished training epoch 838\n",
      "train_loss:  1.3829202145466298e-05 train_R2 0.8319400221287171\n",
      "finished training epoch 839\n",
      "train_loss:  1.4051794998332325e-05 train_R2 0.8760390260698618\n",
      "finished training epoch 840\n",
      "train_loss:  1.4128964085856992e-05 train_R2 0.9107604416460885\n",
      "finished training epoch 841\n",
      "train_loss:  1.4112516239804917e-05 train_R2 0.8193792834839142\n",
      "finished training epoch 842\n",
      "train_loss:  1.3809200441840568e-05 train_R2 0.9172944938505074\n",
      "finished training epoch 843\n",
      "train_loss:  1.312371792220517e-05 train_R2 0.8885974444820705\n",
      "finished training epoch 844\n",
      "train_loss:  1.3623530719408468e-05 train_R2 0.8565322395087043\n",
      "finished training epoch 845\n",
      "train_loss:  1.4099086697239887e-05 train_R2 0.9053928503549354\n",
      "finished training epoch 846\n",
      "train_loss:  1.4584363924721047e-05 train_R2 0.673546766156047\n",
      "finished training epoch 847\n",
      "train_loss:  1.496965446283812e-05 train_R2 0.8833249043218196\n",
      "finished training epoch 848\n",
      "train_loss:  1.4025806729562292e-05 train_R2 0.8829551415186655\n",
      "finished training epoch 849\n",
      "train_loss:  1.3250601031975623e-05 train_R2 0.8847924290332744\n",
      "finished training epoch 850\n",
      "train_loss:  1.3418158568181236e-05 train_R2 0.9058824623993186\n",
      "finished training epoch 851\n",
      "train_loss:  1.3694258644409206e-05 train_R2 0.8680968988316546\n",
      "finished training epoch 852\n",
      "train_loss:  1.4209685352083035e-05 train_R2 0.8228368793388239\n",
      "finished training epoch 853\n",
      "train_loss:  1.4354942924414037e-05 train_R2 0.8780309423224263\n",
      "finished training epoch 854\n",
      "train_loss:  1.441115849863112e-05 train_R2 0.8869048150904826\n",
      "finished training epoch 855\n",
      "train_loss:  1.3939007333705893e-05 train_R2 0.8255352212591581\n",
      "finished training epoch 856\n",
      "train_loss:  1.3749633440028705e-05 train_R2 0.8714485054182176\n",
      "finished training epoch 857\n",
      "train_loss:  1.3485174599948832e-05 train_R2 0.862086039473697\n",
      "finished training epoch 858\n",
      "train_loss:  1.4259973418984388e-05 train_R2 0.8171141685871626\n",
      "finished training epoch 859\n",
      "train_loss:  1.5058336058049607e-05 train_R2 0.9003346400575316\n",
      "finished training epoch 860\n",
      "train_loss:  1.4811441062277073e-05 train_R2 0.8175615920201115\n",
      "finished training epoch 861\n",
      "train_loss:  1.4180268171867265e-05 train_R2 0.8790973854430415\n",
      "finished training epoch 862\n",
      "train_loss:  1.3352508702038405e-05 train_R2 0.8317378445974745\n",
      "finished training epoch 863\n",
      "train_loss:  1.367834515024017e-05 train_R2 0.8175215957275892\n",
      "finished training epoch 864\n",
      "train_loss:  1.4508883413388417e-05 train_R2 0.8779231198521645\n",
      "finished training epoch 865\n",
      "train_loss:  1.4928386681726107e-05 train_R2 0.8092942082106153\n",
      "finished training epoch 866\n",
      "train_loss:  1.4471293629235917e-05 train_R2 0.8355432965733636\n",
      "finished training epoch 867\n",
      "train_loss:  1.372338331028427e-05 train_R2 0.8932628018545057\n",
      "finished training epoch 868\n",
      "train_loss:  1.3177524675736901e-05 train_R2 0.8746865020096264\n",
      "finished training epoch 869\n",
      "train_loss:  1.3790994239277915e-05 train_R2 0.9048601466204492\n",
      "finished training epoch 870\n",
      "train_loss:  1.4018154834771988e-05 train_R2 0.8758818312510691\n",
      "finished training epoch 871\n",
      "train_loss:  1.394427466393718e-05 train_R2 0.8827017164774223\n",
      "finished training epoch 872\n",
      "train_loss:  1.3592669399017262e-05 train_R2 0.8520909356042955\n",
      "finished training epoch 873\n",
      "train_loss:  1.3541882021689689e-05 train_R2 0.8106315325610436\n",
      "finished training epoch 874\n",
      "train_loss:  1.3870424310278502e-05 train_R2 0.7947988408206674\n",
      "finished training epoch 875\n",
      "train_loss:  1.4272469664525673e-05 train_R2 0.7701545522237531\n",
      "finished training epoch 876\n",
      "train_loss:  1.3870036456055349e-05 train_R2 0.8910703289028936\n",
      "finished training epoch 877\n",
      "train_loss:  1.3340244790372078e-05 train_R2 0.9095395339588943\n",
      "finished training epoch 878\n",
      "train_loss:  1.3367193536712981e-05 train_R2 0.8804613918757075\n",
      "finished training epoch 879\n",
      "train_loss:  1.3231938321994147e-05 train_R2 0.8937669893264326\n",
      "finished training epoch 880\n",
      "train_loss:  1.3568358496215006e-05 train_R2 0.8862933606600258\n",
      "finished training epoch 881\n",
      "train_loss:  1.4081031195669201e-05 train_R2 0.9070965433998704\n",
      "finished training epoch 882\n",
      "train_loss:  1.3760435971874228e-05 train_R2 0.6877165206815866\n",
      "finished training epoch 883\n",
      "train_loss:  1.3195556524883928e-05 train_R2 0.9029185749231431\n",
      "finished training epoch 884\n",
      "train_loss:  1.3311734746506182e-05 train_R2 0.880791530329433\n",
      "finished training epoch 885\n",
      "train_loss:  1.363806777226575e-05 train_R2 0.7459198153878265\n",
      "finished training epoch 886\n",
      "train_loss:  1.4444705621395799e-05 train_R2 0.9174297949988209\n",
      "finished training epoch 887\n",
      "train_loss:  1.4002852956337682e-05 train_R2 0.761652095673446\n",
      "finished training epoch 888\n",
      "train_loss:  1.3641190125271362e-05 train_R2 0.8659180406810995\n",
      "finished training epoch 889\n",
      "train_loss:  1.3435584143732445e-05 train_R2 0.8434236418343642\n",
      "finished training epoch 890\n",
      "train_loss:  1.3165867806811085e-05 train_R2 0.8621078365737413\n",
      "finished training epoch 891\n",
      "train_loss:  1.3663673734820738e-05 train_R2 0.8584170404802909\n",
      "finished training epoch 892\n",
      "train_loss:  1.3373590119368695e-05 train_R2 0.7667839319293396\n",
      "finished training epoch 893\n",
      "train_loss:  1.3284735685037573e-05 train_R2 0.879900343394673\n",
      "finished training epoch 894\n",
      "train_loss:  1.3155494075245367e-05 train_R2 0.8964064648120766\n",
      "finished training epoch 895\n",
      "train_loss:  1.310904190990539e-05 train_R2 0.9040005544177908\n",
      "finished training epoch 896\n",
      "train_loss:  1.303536244006337e-05 train_R2 0.8793236680621106\n",
      "finished training epoch 897\n",
      "train_loss:  1.3265160614798817e-05 train_R2 0.9083979804757378\n",
      "finished training epoch 898\n",
      "train_loss:  1.3636195581752484e-05 train_R2 0.8467532651639366\n",
      "finished training epoch 899\n",
      "train_loss:  1.2898886017847792e-05 train_R2 0.8582171778637169\n",
      "finished training epoch 900\n",
      "train_loss:  1.2978967815377546e-05 train_R2 0.8475887867815282\n",
      "finished training epoch 901\n",
      "train_loss:  1.3226955471650186e-05 train_R2 0.8395991168507942\n",
      "finished training epoch 902\n",
      "train_loss:  1.3499309739871507e-05 train_R2 0.835400685512123\n",
      "finished training epoch 903\n",
      "train_loss:  1.3040461181724878e-05 train_R2 0.9023896395791016\n",
      "finished training epoch 904\n",
      "train_loss:  1.3373708140443022e-05 train_R2 0.7887078299546628\n",
      "finished training epoch 905\n",
      "train_loss:  1.3350819820423022e-05 train_R2 0.8972528327754885\n",
      "finished training epoch 906\n",
      "train_loss:  1.4065043473500297e-05 train_R2 0.8762990374119964\n",
      "finished training epoch 907\n",
      "train_loss:  1.494306429961405e-05 train_R2 0.8902270335361094\n",
      "finished training epoch 908\n",
      "train_loss:  1.5407292508509876e-05 train_R2 0.8689906226462554\n",
      "finished training epoch 909\n",
      "train_loss:  1.4781697893334017e-05 train_R2 0.9069204749836048\n",
      "finished training epoch 910\n",
      "train_loss:  1.379471731775811e-05 train_R2 0.8186950264796689\n",
      "finished training epoch 911\n",
      "train_loss:  1.3495918892769684e-05 train_R2 0.809522592043876\n",
      "finished training epoch 912\n",
      "train_loss:  1.3396712227061643e-05 train_R2 0.8201945057006315\n",
      "finished training epoch 913\n",
      "train_loss:  1.3329127303433776e-05 train_R2 0.9056600064274312\n",
      "finished training epoch 914\n",
      "train_loss:  1.3601670595847992e-05 train_R2 0.8362045186233004\n",
      "finished training epoch 915\n",
      "train_loss:  1.408338428927412e-05 train_R2 0.8535900721699454\n",
      "finished training epoch 916\n",
      "train_loss:  1.4361655242034932e-05 train_R2 0.7676093272388984\n",
      "finished training epoch 917\n",
      "train_loss:  1.4004572220788404e-05 train_R2 0.7714422230836683\n",
      "finished training epoch 918\n",
      "train_loss:  1.3463036829270055e-05 train_R2 0.8868969973376178\n",
      "finished training epoch 919\n",
      "train_loss:  1.3304807127908295e-05 train_R2 0.8648315294326434\n",
      "finished training epoch 920\n",
      "train_loss:  1.3110108385266145e-05 train_R2 0.8940675662899772\n",
      "finished training epoch 921\n",
      "train_loss:  1.3293202609828276e-05 train_R2 0.8470442659502043\n",
      "finished training epoch 922\n",
      "train_loss:  1.375984133526808e-05 train_R2 0.7840343377590142\n",
      "finished training epoch 923\n",
      "train_loss:  1.4101428878554782e-05 train_R2 0.8370248563775011\n",
      "finished training epoch 924\n",
      "train_loss:  1.365802881131246e-05 train_R2 0.7287732909172868\n",
      "finished training epoch 925\n",
      "train_loss:  1.3193090866584036e-05 train_R2 0.9081046626849696\n",
      "finished training epoch 926\n",
      "train_loss:  1.3368229193031378e-05 train_R2 0.7741042621181533\n",
      "finished training epoch 927\n",
      "train_loss:  1.2895893043186533e-05 train_R2 0.8308801684507493\n",
      "finished training epoch 928\n",
      "train_loss:  1.3429380814641305e-05 train_R2 0.8689475789571051\n",
      "finished training epoch 929\n",
      "train_loss:  1.3213225482460544e-05 train_R2 0.8592918178893586\n",
      "finished training epoch 930\n",
      "train_loss:  1.3143390679421772e-05 train_R2 0.9220707369886575\n",
      "finished training epoch 931\n",
      "train_loss:  1.3793697520916834e-05 train_R2 0.8189633558294849\n",
      "finished training epoch 932\n",
      "train_loss:  1.3457329803634862e-05 train_R2 0.803366918009158\n",
      "finished training epoch 933\n",
      "train_loss:  1.3184497062723204e-05 train_R2 0.8614764631496622\n",
      "finished training epoch 934\n",
      "train_loss:  1.3000935968329982e-05 train_R2 0.871711524264815\n",
      "finished training epoch 935\n",
      "train_loss:  1.3189914609401812e-05 train_R2 0.8980759221038018\n",
      "finished training epoch 936\n",
      "train_loss:  1.29281918578129e-05 train_R2 0.7926781021357622\n",
      "finished training epoch 937\n",
      "train_loss:  1.3041041072318367e-05 train_R2 0.846858154241578\n",
      "finished training epoch 938\n",
      "train_loss:  1.3240583561128638e-05 train_R2 0.8801781985432924\n",
      "finished training epoch 939\n",
      "train_loss:  1.2928448469307682e-05 train_R2 0.7975781868963983\n",
      "finished training epoch 940\n",
      "train_loss:  1.3098294995896335e-05 train_R2 0.9309996642215357\n",
      "finished training epoch 941\n",
      "train_loss:  1.334466823405074e-05 train_R2 0.8880911171808398\n",
      "finished training epoch 942\n",
      "train_loss:  1.3356536265780484e-05 train_R2 0.887488836037642\n",
      "finished training epoch 943\n",
      "train_loss:  1.4092589185606843e-05 train_R2 0.8959967217628991\n",
      "finished training epoch 944\n",
      "train_loss:  1.4119506586645101e-05 train_R2 0.7518199335967417\n",
      "finished training epoch 945\n",
      "train_loss:  1.507771919009076e-05 train_R2 0.8411293811551601\n",
      "finished training epoch 946\n",
      "train_loss:  1.4145978094242957e-05 train_R2 0.8389740033481039\n",
      "finished training epoch 947\n",
      "train_loss:  1.3965720976791223e-05 train_R2 0.8619940843998435\n",
      "finished training epoch 948\n",
      "train_loss:  1.3216343193164107e-05 train_R2 0.8439845390390407\n",
      "finished training epoch 949\n",
      "train_loss:  1.3507106334090617e-05 train_R2 0.7860984560918002\n",
      "finished training epoch 950\n",
      "train_loss:  1.4497823276257761e-05 train_R2 0.9134069798298721\n",
      "finished training epoch 951\n",
      "train_loss:  1.4947289623936532e-05 train_R2 0.6808071248575313\n",
      "finished training epoch 952\n",
      "train_loss:  1.58976461889485e-05 train_R2 0.8220250544715129\n",
      "finished training epoch 953\n",
      "train_loss:  1.4267441584530046e-05 train_R2 0.8391283081886947\n",
      "finished training epoch 954\n",
      "train_loss:  1.313853792220986e-05 train_R2 0.8901969699928213\n",
      "finished training epoch 955\n",
      "train_loss:  1.3766900790727896e-05 train_R2 0.8475644767545104\n",
      "finished training epoch 956\n",
      "train_loss:  1.4218701772326396e-05 train_R2 0.8284502867827797\n",
      "finished training epoch 957\n",
      "train_loss:  1.5357398968417577e-05 train_R2 0.8658274385996726\n",
      "finished training epoch 958\n",
      "train_loss:  1.3830749767226465e-05 train_R2 0.8599661102963715\n",
      "finished training epoch 959\n",
      "train_loss:  1.3375851943224043e-05 train_R2 0.8543318392962838\n",
      "finished training epoch 960\n",
      "train_loss:  1.3401158065491598e-05 train_R2 0.8490389328367914\n",
      "finished training epoch 961\n",
      "train_loss:  1.3978788081879097e-05 train_R2 0.8592191610049332\n",
      "finished training epoch 962\n",
      "train_loss:  1.4372368712058858e-05 train_R2 0.8767951956463038\n",
      "finished training epoch 963\n",
      "train_loss:  1.3688430299648062e-05 train_R2 0.7619900335584824\n",
      "finished training epoch 964\n",
      "train_loss:  1.3354736488410888e-05 train_R2 0.929277592114754\n",
      "finished training epoch 965\n",
      "train_loss:  1.3285778210517453e-05 train_R2 0.8856259918420256\n",
      "finished training epoch 966\n",
      "train_loss:  1.3906812421502998e-05 train_R2 0.8576711059765844\n",
      "finished training epoch 967\n",
      "train_loss:  1.4283924457859898e-05 train_R2 0.8365449935196717\n",
      "finished training epoch 968\n",
      "train_loss:  1.3646458042882275e-05 train_R2 0.829206921818094\n",
      "finished training epoch 969\n",
      "train_loss:  1.2977139226899128e-05 train_R2 0.8251089244929372\n",
      "finished training epoch 970\n",
      "train_loss:  1.3210434206739527e-05 train_R2 0.9164643439832824\n",
      "finished training epoch 971\n",
      "train_loss:  1.3462901736455743e-05 train_R2 0.8364326345405928\n",
      "finished training epoch 972\n",
      "train_loss:  1.3475117403640965e-05 train_R2 0.8397767901776051\n",
      "finished training epoch 973\n",
      "train_loss:  1.315239934481956e-05 train_R2 0.8142446670915386\n",
      "finished training epoch 974\n",
      "train_loss:  1.3135765203628043e-05 train_R2 0.9196955094835829\n",
      "finished training epoch 975\n",
      "train_loss:  1.3301022072487975e-05 train_R2 0.923025110470398\n",
      "finished training epoch 976\n",
      "train_loss:  1.3589337425378477e-05 train_R2 0.8149479079717791\n",
      "finished training epoch 977\n",
      "train_loss:  1.347428701000828e-05 train_R2 0.9106455918833926\n",
      "finished training epoch 978\n",
      "train_loss:  1.3402509696421377e-05 train_R2 0.852427693438158\n",
      "finished training epoch 979\n",
      "train_loss:  1.3048721860445868e-05 train_R2 0.8668708471670723\n",
      "finished training epoch 980\n",
      "train_loss:  1.2890411311275543e-05 train_R2 0.8990203223001041\n",
      "finished training epoch 981\n",
      "train_loss:  1.2785147089273909e-05 train_R2 0.8851024773035888\n",
      "finished training epoch 982\n",
      "train_loss:  1.305865242534318e-05 train_R2 0.904557864623095\n",
      "finished training epoch 983\n",
      "train_loss:  1.3286309068485754e-05 train_R2 0.8019162338141056\n",
      "finished training epoch 984\n",
      "train_loss:  1.3402294030494044e-05 train_R2 0.9039228098455308\n",
      "finished training epoch 985\n",
      "train_loss:  1.318845972433612e-05 train_R2 0.8575452413749262\n",
      "finished training epoch 986\n",
      "train_loss:  1.2872374021596946e-05 train_R2 0.8514593781142805\n",
      "finished training epoch 987\n",
      "train_loss:  1.3007288262384422e-05 train_R2 0.8351594313444485\n",
      "finished training epoch 988\n",
      "train_loss:  1.2819578575183315e-05 train_R2 0.9003264949985309\n",
      "finished training epoch 989\n",
      "train_loss:  1.3158686991026785e-05 train_R2 0.8928180064773777\n",
      "finished training epoch 990\n",
      "train_loss:  1.3285131639657888e-05 train_R2 0.7327384866805444\n",
      "finished training epoch 991\n",
      "train_loss:  1.3369368764633811e-05 train_R2 0.8960918747152826\n",
      "finished training epoch 992\n",
      "train_loss:  1.3328035156641131e-05 train_R2 0.8689487185590523\n",
      "finished training epoch 993\n",
      "train_loss:  1.3000068099259864e-05 train_R2 0.8758539724370874\n",
      "finished training epoch 994\n",
      "train_loss:  1.2998577511784456e-05 train_R2 0.8524373172780615\n",
      "finished training epoch 995\n",
      "train_loss:  1.3614654212772275e-05 train_R2 0.7446774841896433\n",
      "finished training epoch 996\n",
      "train_loss:  1.3890697895537217e-05 train_R2 0.8781140482995825\n",
      "finished training epoch 997\n",
      "train_loss:  1.3995242353082915e-05 train_R2 0.7706069306798534\n",
      "finished training epoch 998\n",
      "train_loss:  1.3419269066066375e-05 train_R2 0.851508517884829\n",
      "finished training epoch 999\n",
      "train_loss:  1.3058069775113536e-05 train_R2 0.9300849420133696\n",
      "finished training epoch 1000\n",
      "train_loss:  1.3010637043060983e-05 train_R2 0.8613931850330738\n",
      "finished training epoch 1001\n",
      "train_loss:  1.3606613568399506e-05 train_R2 0.8649905386914843\n",
      "finished training epoch 1002\n",
      "train_loss:  1.3633536777012163e-05 train_R2 0.8067115876058748\n",
      "finished training epoch 1003\n",
      "train_loss:  1.3920687738965934e-05 train_R2 0.8970825442009789\n",
      "finished training epoch 1004\n",
      "train_loss:  1.353974657077854e-05 train_R2 0.8597789100943145\n",
      "finished training epoch 1005\n",
      "train_loss:  1.3525839357619365e-05 train_R2 0.8754543664288712\n",
      "finished training epoch 1006\n",
      "train_loss:  1.3619091177362762e-05 train_R2 0.8843967516308293\n",
      "finished training epoch 1007\n",
      "train_loss:  1.3388760029230443e-05 train_R2 0.7869268426142421\n",
      "finished training epoch 1008\n",
      "train_loss:  1.3307331524384198e-05 train_R2 0.8562303900678316\n",
      "finished training epoch 1009\n",
      "train_loss:  1.3429498655488244e-05 train_R2 0.7338331661177036\n",
      "finished training epoch 1010\n",
      "train_loss:  1.396905152198265e-05 train_R2 0.8958441285386843\n",
      "finished training epoch 1011\n",
      "train_loss:  1.42818408840711e-05 train_R2 0.7912012845609265\n",
      "finished training epoch 1012\n",
      "train_loss:  1.4028273591832219e-05 train_R2 0.7910193723708946\n",
      "finished training epoch 1013\n",
      "train_loss:  1.3325489680681875e-05 train_R2 0.8608270023584366\n",
      "finished training epoch 1014\n",
      "train_loss:  1.3104777606967395e-05 train_R2 0.8088204014902188\n",
      "finished training epoch 1015\n",
      "train_loss:  1.3042067871317634e-05 train_R2 0.8183855987798483\n",
      "finished training epoch 1016\n",
      "train_loss:  1.3230620453115008e-05 train_R2 0.9292491295189459\n",
      "finished training epoch 1017\n",
      "train_loss:  1.3262306261473873e-05 train_R2 0.7786476783561675\n",
      "finished training epoch 1018\n",
      "train_loss:  1.3058861732244622e-05 train_R2 0.861612158954845\n",
      "finished training epoch 1019\n",
      "train_loss:  1.3243809822995289e-05 train_R2 0.8884573121880562\n",
      "finished training epoch 1020\n",
      "train_loss:  1.3166749089953348e-05 train_R2 0.882796161790926\n",
      "finished training epoch 1021\n",
      "train_loss:  1.3054066008640196e-05 train_R2 0.8829661918867644\n",
      "finished training epoch 1022\n",
      "train_loss:  1.2936665649620908e-05 train_R2 0.8301393761182557\n",
      "finished training epoch 1023\n",
      "train_loss:  1.2461573283441387e-05 train_R2 0.8784381962310414\n",
      "finished training epoch 1024\n",
      "train_loss:  1.271823759958037e-05 train_R2 0.8971135747232792\n",
      "finished training epoch 1025\n",
      "train_loss:  1.2580725254417128e-05 train_R2 0.8775761603409968\n",
      "finished training epoch 1026\n",
      "train_loss:  1.2678837182211687e-05 train_R2 0.871352735544693\n",
      "finished training epoch 1027\n",
      "train_loss:  1.2994970657909282e-05 train_R2 0.845439249959222\n",
      "finished training epoch 1028\n",
      "train_loss:  1.2980736147500465e-05 train_R2 0.8391630197009926\n",
      "finished training epoch 1029\n",
      "train_loss:  1.2842055950504678e-05 train_R2 0.9033195866424847\n",
      "finished training epoch 1030\n",
      "train_loss:  1.318017292592599e-05 train_R2 0.8800894286687069\n",
      "finished training epoch 1031\n",
      "train_loss:  1.297075444181821e-05 train_R2 0.8371471343005331\n",
      "finished training epoch 1032\n",
      "train_loss:  1.2951163950452129e-05 train_R2 0.8356396208811544\n",
      "finished training epoch 1033\n",
      "train_loss:  1.304089752411822e-05 train_R2 0.8846375451208166\n",
      "finished training epoch 1034\n",
      "train_loss:  1.3016906887726606e-05 train_R2 0.9055255332736805\n",
      "finished training epoch 1035\n",
      "train_loss:  1.3149298392763842e-05 train_R2 0.7542590444189039\n",
      "finished training epoch 1036\n",
      "train_loss:  1.2634437310044403e-05 train_R2 0.8825507104625491\n",
      "finished training epoch 1037\n",
      "train_loss:  1.2920839487069725e-05 train_R2 0.8611557315310259\n",
      "finished training epoch 1038\n",
      "train_loss:  1.2677423858885848e-05 train_R2 0.9070564203998682\n",
      "finished training epoch 1039\n",
      "train_loss:  1.2835108092981057e-05 train_R2 0.8599898262724005\n",
      "finished training epoch 1040\n",
      "train_loss:  1.3362603994275393e-05 train_R2 0.920234335885505\n",
      "finished training epoch 1041\n",
      "train_loss:  1.3591111470751877e-05 train_R2 0.8743356351415974\n",
      "finished training epoch 1042\n",
      "train_loss:  1.4721382443455035e-05 train_R2 0.8096652708716471\n",
      "finished training epoch 1043\n",
      "train_loss:  1.593266929385938e-05 train_R2 0.8580441227585852\n",
      "finished training epoch 1044\n",
      "train_loss:  1.5308215677202646e-05 train_R2 0.7988833082285949\n",
      "finished training epoch 1045\n",
      "train_loss:  1.5231075938937532e-05 train_R2 0.8912195124789113\n",
      "finished training epoch 1046\n",
      "train_loss:  1.3581307449577557e-05 train_R2 0.8777879876623584\n",
      "finished training epoch 1047\n",
      "train_loss:  1.353047424756886e-05 train_R2 0.8676390763098232\n",
      "finished training epoch 1048\n",
      "train_loss:  1.4337667308911216e-05 train_R2 0.9095318162946094\n",
      "finished training epoch 1049\n",
      "train_loss:  1.480802827988273e-05 train_R2 0.8124997716900164\n",
      "finished training epoch 1050\n",
      "train_loss:  1.5596717045583484e-05 train_R2 0.8885468586091783\n",
      "finished training epoch 1051\n",
      "train_loss:  1.3765106420815583e-05 train_R2 0.825366636310103\n",
      "finished training epoch 1052\n",
      "train_loss:  1.3636277028543144e-05 train_R2 0.9113552628775803\n",
      "finished training epoch 1053\n",
      "train_loss:  1.4289134435632e-05 train_R2 0.8614226915588665\n",
      "finished training epoch 1054\n",
      "train_loss:  1.4588991941674016e-05 train_R2 0.822005976453804\n",
      "finished training epoch 1055\n",
      "train_loss:  1.4614429327794916e-05 train_R2 0.9072069164430392\n",
      "finished training epoch 1056\n",
      "train_loss:  1.3101736303384312e-05 train_R2 0.8202422033651109\n",
      "finished training epoch 1057\n",
      "train_loss:  1.3092833719283761e-05 train_R2 0.8933309409948448\n",
      "finished training epoch 1058\n",
      "train_loss:  1.3803551060655854e-05 train_R2 0.8652107963381206\n",
      "finished training epoch 1059\n",
      "train_loss:  1.3808433200037578e-05 train_R2 0.8593696723590889\n",
      "finished training epoch 1060\n",
      "train_loss:  1.3498558327975182e-05 train_R2 0.8819028743622781\n",
      "finished training epoch 1061\n",
      "train_loss:  1.3120592931361534e-05 train_R2 0.8865770320567673\n",
      "finished training epoch 1062\n",
      "train_loss:  1.2967817748980804e-05 train_R2 0.8853059688945358\n",
      "finished training epoch 1063\n",
      "train_loss:  1.3366027144728118e-05 train_R2 0.9268732158698928\n",
      "finished training epoch 1064\n",
      "train_loss:  1.3184222548999816e-05 train_R2 0.9044335052032665\n",
      "finished training epoch 1065\n",
      "train_loss:  1.3025916354482293e-05 train_R2 0.880543873313293\n",
      "finished training epoch 1066\n",
      "train_loss:  1.265653558319212e-05 train_R2 0.8578615415412922\n",
      "finished training epoch 1067\n",
      "train_loss:  1.292039362774028e-05 train_R2 0.8707939795437873\n",
      "finished training epoch 1068\n",
      "train_loss:  1.290134351087004e-05 train_R2 0.8693573189589292\n",
      "finished training epoch 1069\n",
      "train_loss:  1.2888269524630571e-05 train_R2 0.8817729553036997\n",
      "finished training epoch 1070\n",
      "train_loss:  1.2595197758784995e-05 train_R2 0.849151167254711\n",
      "finished training epoch 1071\n",
      "train_loss:  1.2832153424296981e-05 train_R2 0.8811202591696767\n",
      "finished training epoch 1072\n",
      "train_loss:  1.2677177605992319e-05 train_R2 0.8577385915068236\n",
      "finished training epoch 1073\n",
      "train_loss:  1.2941673993250273e-05 train_R2 0.8688394842391748\n",
      "finished training epoch 1074\n",
      "train_loss:  1.32695304017038e-05 train_R2 0.8645012810883679\n",
      "finished training epoch 1075\n",
      "train_loss:  1.3418970354618452e-05 train_R2 0.8852034686669982\n",
      "finished training epoch 1076\n",
      "train_loss:  1.3376035754226923e-05 train_R2 0.9048035380286457\n",
      "finished training epoch 1077\n",
      "train_loss:  1.2721268292178898e-05 train_R2 0.8609486053507155\n",
      "finished training epoch 1078\n",
      "train_loss:  1.320776210361902e-05 train_R2 0.845565552189105\n",
      "finished training epoch 1079\n",
      "train_loss:  1.276161033414812e-05 train_R2 0.8851940125737086\n",
      "finished training epoch 1080\n",
      "train_loss:  1.268894831453338e-05 train_R2 0.8964070337871337\n",
      "finished training epoch 1081\n",
      "train_loss:  1.2538636924865664e-05 train_R2 0.8799204490350118\n",
      "finished training epoch 1082\n",
      "train_loss:  1.2807656923398284e-05 train_R2 0.8997231225304163\n",
      "finished training epoch 1083\n",
      "train_loss:  1.3352028112851126e-05 train_R2 0.8495620370486813\n",
      "finished training epoch 1084\n",
      "train_loss:  1.3093311610461172e-05 train_R2 0.8916178647867539\n",
      "finished training epoch 1085\n",
      "train_loss:  1.2939681310157274e-05 train_R2 0.7979918982117772\n",
      "finished training epoch 1086\n",
      "train_loss:  1.2739467501804112e-05 train_R2 0.8568310133137518\n",
      "finished training epoch 1087\n",
      "train_loss:  1.2770896835627522e-05 train_R2 0.9147651801257642\n",
      "finished training epoch 1088\n",
      "train_loss:  1.2708231146376598e-05 train_R2 0.8219536178731739\n",
      "finished training epoch 1089\n",
      "train_loss:  1.2784102561321225e-05 train_R2 0.8318080773105057\n",
      "finished training epoch 1090\n",
      "train_loss:  1.2709012443111183e-05 train_R2 0.8361402405847473\n",
      "finished training epoch 1091\n",
      "train_loss:  1.2348969301881863e-05 train_R2 0.858629227538732\n",
      "finished training epoch 1092\n",
      "train_loss:  1.3097972145401885e-05 train_R2 0.812751987397381\n",
      "finished training epoch 1093\n",
      "train_loss:  1.2852201048765265e-05 train_R2 0.9188923587126754\n",
      "finished training epoch 1094\n",
      "train_loss:  1.2960325600390655e-05 train_R2 0.7909874597062967\n",
      "finished training epoch 1095\n",
      "train_loss:  1.3247244300146932e-05 train_R2 0.8815471540138571\n",
      "finished training epoch 1096\n",
      "train_loss:  1.3741256889639075e-05 train_R2 0.8649464535306138\n",
      "finished training epoch 1097\n",
      "train_loss:  1.3741738631642633e-05 train_R2 0.9042086648001753\n",
      "finished training epoch 1098\n",
      "train_loss:  1.3782956603649581e-05 train_R2 0.8871041924390946\n",
      "finished training epoch 1099\n",
      "train_loss:  1.3524742789328097e-05 train_R2 0.8666373969527295\n",
      "finished training epoch 1100\n",
      "train_loss:  1.308009672270461e-05 train_R2 0.8223306955327673\n",
      "finished training epoch 1101\n",
      "train_loss:  1.2951029262832692e-05 train_R2 0.8964088570711009\n",
      "finished training epoch 1102\n",
      "train_loss:  1.3076808680230247e-05 train_R2 0.9125728966396414\n",
      "finished training epoch 1103\n",
      "train_loss:  1.351416827421967e-05 train_R2 0.8533694583047671\n",
      "finished training epoch 1104\n",
      "train_loss:  1.4274422507001302e-05 train_R2 0.9069144037797472\n",
      "finished training epoch 1105\n",
      "train_loss:  1.4097093423609114e-05 train_R2 0.859866893819352\n",
      "finished training epoch 1106\n",
      "train_loss:  1.4003807479238433e-05 train_R2 0.8731391858988705\n",
      "finished training epoch 1107\n",
      "train_loss:  1.3116756513881127e-05 train_R2 0.9035520065146939\n",
      "finished training epoch 1108\n",
      "train_loss:  1.3130427293721959e-05 train_R2 0.891905014359455\n",
      "finished training epoch 1109\n",
      "train_loss:  1.3781697375211922e-05 train_R2 0.9044007534838865\n",
      "finished training epoch 1110\n",
      "train_loss:  1.3900903608849653e-05 train_R2 0.8189394761841424\n",
      "finished training epoch 1111\n",
      "train_loss:  1.4557747831785627e-05 train_R2 0.883894821054766\n",
      "finished training epoch 1112\n",
      "train_loss:  1.3598022790634146e-05 train_R2 0.8875800311147062\n",
      "finished training epoch 1113\n",
      "train_loss:  1.3278899516608284e-05 train_R2 0.8916845951261463\n",
      "finished training epoch 1114\n",
      "train_loss:  1.3683268146707442e-05 train_R2 0.8251941722023939\n",
      "finished training epoch 1115\n",
      "train_loss:  1.4168093088271597e-05 train_R2 0.8742676041219253\n",
      "finished training epoch 1116\n",
      "train_loss:  1.4059869801028065e-05 train_R2 0.8617031202361519\n",
      "finished training epoch 1117\n",
      "train_loss:  1.3546026121982578e-05 train_R2 0.8589630493533932\n",
      "finished training epoch 1118\n",
      "train_loss:  1.2844641748263111e-05 train_R2 0.9035282777569148\n",
      "finished training epoch 1119\n",
      "train_loss:  1.2854931942525872e-05 train_R2 0.8609514009284825\n",
      "finished training epoch 1120\n",
      "train_loss:  1.3724258224118201e-05 train_R2 0.9001131707805516\n",
      "finished training epoch 1121\n",
      "train_loss:  1.3737310218252078e-05 train_R2 0.8580536431694807\n",
      "finished training epoch 1122\n",
      "train_loss:  1.262378698859126e-05 train_R2 0.9052094482197789\n",
      "finished training epoch 1123\n",
      "train_loss:  1.2752057189241057e-05 train_R2 0.8843858416726774\n",
      "finished training epoch 1124\n",
      "train_loss:  1.312615344663706e-05 train_R2 0.8701874223182868\n",
      "finished training epoch 1125\n",
      "train_loss:  1.3152650808232808e-05 train_R2 0.8243950315587553\n",
      "finished training epoch 1126\n",
      "train_loss:  1.3536104780247549e-05 train_R2 0.8896486563261642\n",
      "finished training epoch 1127\n",
      "train_loss:  1.2711239035262569e-05 train_R2 0.8069494299313279\n",
      "finished training epoch 1128\n",
      "train_loss:  1.28610060625744e-05 train_R2 0.8602382838817404\n",
      "finished training epoch 1129\n",
      "train_loss:  1.2866488177873495e-05 train_R2 0.8609767375948354\n",
      "finished training epoch 1130\n",
      "train_loss:  1.2834870500163902e-05 train_R2 0.8516672814646676\n",
      "finished training epoch 1131\n",
      "train_loss:  1.319611780654005e-05 train_R2 0.8903782803563254\n",
      "finished training epoch 1132\n",
      "train_loss:  1.3106238093260334e-05 train_R2 0.8828821057168317\n",
      "finished training epoch 1133\n",
      "train_loss:  1.2875761572954706e-05 train_R2 0.8961883332918039\n",
      "finished training epoch 1134\n",
      "train_loss:  1.3033571673418543e-05 train_R2 0.8486756464270483\n",
      "finished training epoch 1135\n",
      "train_loss:  1.3157961707157225e-05 train_R2 0.9322180424889529\n",
      "finished training epoch 1136\n",
      "train_loss:  1.3021804509348676e-05 train_R2 0.9001293557216586\n",
      "finished training epoch 1137\n",
      "train_loss:  1.2877659241060125e-05 train_R2 0.8787057566063755\n",
      "finished training epoch 1138\n",
      "train_loss:  1.2875831474546022e-05 train_R2 0.8713443134161091\n",
      "finished training epoch 1139\n",
      "train_loss:  1.2932944754679806e-05 train_R2 0.9095398576494368\n",
      "finished training epoch 1140\n",
      "train_loss:  1.3252983263081962e-05 train_R2 0.9036402788558702\n",
      "finished training epoch 1141\n",
      "train_loss:  1.3074202314229885e-05 train_R2 0.8656471108238893\n",
      "finished training epoch 1142\n",
      "train_loss:  1.2914547211904037e-05 train_R2 0.9119951587551457\n",
      "finished training epoch 1143\n",
      "train_loss:  1.2780116527951464e-05 train_R2 0.8789534326356365\n",
      "finished training epoch 1144\n",
      "train_loss:  1.272723718384072e-05 train_R2 0.8723787603009521\n",
      "finished training epoch 1145\n",
      "train_loss:  1.24942562576411e-05 train_R2 0.8480898664334874\n",
      "finished training epoch 1146\n",
      "train_loss:  1.2834929269849078e-05 train_R2 0.8898159953662602\n",
      "finished training epoch 1147\n",
      "train_loss:  1.2858681440050554e-05 train_R2 0.8679986232315338\n",
      "finished training epoch 1148\n",
      "train_loss:  1.2392873654779317e-05 train_R2 0.9061500844803597\n",
      "finished training epoch 1149\n",
      "train_loss:  1.2714124184745653e-05 train_R2 0.8946421173799697\n",
      "finished training epoch 1150\n",
      "train_loss:  1.2471393933175806e-05 train_R2 0.8221175241155672\n",
      "finished training epoch 1151\n",
      "train_loss:  1.2760798985583073e-05 train_R2 0.8808471858688693\n",
      "finished training epoch 1152\n",
      "train_loss:  1.297200705649535e-05 train_R2 0.9138343655452443\n",
      "finished training epoch 1153\n",
      "train_loss:  1.3419771381089739e-05 train_R2 0.8419737040318727\n",
      "finished training epoch 1154\n",
      "train_loss:  1.3100894085584794e-05 train_R2 0.9091703790476077\n",
      "finished training epoch 1155\n",
      "train_loss:  1.3196620254209065e-05 train_R2 0.917466366778614\n",
      "finished training epoch 1156\n",
      "train_loss:  1.3144109814443942e-05 train_R2 0.9030483428767708\n",
      "finished training epoch 1157\n",
      "train_loss:  1.2904349800883845e-05 train_R2 0.9063625903066583\n",
      "finished training epoch 1158\n",
      "train_loss:  1.2757369370588318e-05 train_R2 0.9178511115084236\n",
      "finished training epoch 1159\n",
      "train_loss:  1.2469779786336158e-05 train_R2 0.8889931069232037\n",
      "finished training epoch 1160\n",
      "train_loss:  1.288510341174662e-05 train_R2 0.7885931704280423\n",
      "finished training epoch 1161\n",
      "train_loss:  1.312165104807083e-05 train_R2 0.9037637415611208\n",
      "finished training epoch 1162\n",
      "train_loss:  1.3126241687100437e-05 train_R2 0.8846492288733491\n",
      "finished training epoch 1163\n",
      "train_loss:  1.346003133484703e-05 train_R2 0.918257768002005\n",
      "finished training epoch 1164\n",
      "train_loss:  1.350288885428485e-05 train_R2 0.8967927347926574\n",
      "finished training epoch 1165\n",
      "train_loss:  1.294079424780188e-05 train_R2 0.9051211842094207\n",
      "finished training epoch 1166\n",
      "train_loss:  1.2723924818229969e-05 train_R2 0.8385700091722472\n",
      "finished training epoch 1167\n",
      "train_loss:  1.244922199701207e-05 train_R2 0.8601199042982258\n",
      "finished training epoch 1168\n",
      "train_loss:  1.2504838542164236e-05 train_R2 0.8902501940543524\n",
      "finished training epoch 1169\n",
      "train_loss:  1.3638687243066489e-05 train_R2 0.8789789576282248\n",
      "finished training epoch 1170\n",
      "train_loss:  1.4866897243966583e-05 train_R2 0.8789999992392871\n",
      "finished training epoch 1171\n",
      "train_loss:  1.4549222317187792e-05 train_R2 0.8505833746247986\n",
      "finished training epoch 1172\n",
      "train_loss:  1.4161624805351678e-05 train_R2 0.8984789318864221\n",
      "finished training epoch 1173\n",
      "train_loss:  1.3077806900226642e-05 train_R2 0.8878908777299861\n",
      "finished training epoch 1174\n",
      "train_loss:  1.2848985532916976e-05 train_R2 0.8955373646380951\n",
      "finished training epoch 1175\n",
      "train_loss:  1.335580925689392e-05 train_R2 0.8457114315726687\n",
      "finished training epoch 1176\n",
      "train_loss:  1.4426490814181407e-05 train_R2 0.7852324979784328\n",
      "finished training epoch 1177\n",
      "train_loss:  1.5084548987096902e-05 train_R2 0.8785377109261515\n",
      "finished training epoch 1178\n",
      "train_loss:  1.3622326893351886e-05 train_R2 0.873478551176214\n",
      "finished training epoch 1179\n",
      "train_loss:  1.300333820614957e-05 train_R2 0.8761258157909609\n",
      "finished training epoch 1180\n",
      "train_loss:  1.3208167384713994e-05 train_R2 0.8621379221147513\n",
      "finished training epoch 1181\n",
      "train_loss:  1.3864230040697033e-05 train_R2 0.8276663045875043\n",
      "finished training epoch 1182\n",
      "train_loss:  1.4053945633951907e-05 train_R2 0.8961940290807661\n",
      "finished training epoch 1183\n",
      "train_loss:  1.2809947264728175e-05 train_R2 0.8930597812804236\n",
      "finished training epoch 1184\n",
      "train_loss:  1.2682874459214434e-05 train_R2 0.8422742399985914\n",
      "finished training epoch 1185\n",
      "train_loss:  1.2871604637880365e-05 train_R2 0.8771012219157144\n",
      "finished training epoch 1186\n",
      "train_loss:  1.3340594522665808e-05 train_R2 0.8517224468545679\n",
      "finished training epoch 1187\n",
      "train_loss:  1.3312723974765162e-05 train_R2 0.9160641143442512\n",
      "finished training epoch 1188\n",
      "train_loss:  1.2809000154596295e-05 train_R2 0.9050793296590077\n",
      "finished training epoch 1189\n",
      "train_loss:  1.2719737952831378e-05 train_R2 0.9006640692651844\n",
      "finished training epoch 1190\n",
      "train_loss:  1.2689884030985481e-05 train_R2 0.878603493610348\n",
      "finished training epoch 1191\n",
      "train_loss:  1.2848579424994157e-05 train_R2 0.8413045496516074\n",
      "finished training epoch 1192\n",
      "train_loss:  1.289546060680213e-05 train_R2 0.8581976030027065\n",
      "finished training epoch 1193\n",
      "train_loss:  1.2477943557316377e-05 train_R2 0.8441217582612301\n",
      "finished training epoch 1194\n",
      "train_loss:  1.2497439719111065e-05 train_R2 0.9275190635950111\n",
      "finished training epoch 1195\n",
      "train_loss:  1.253779288375843e-05 train_R2 0.8759716472665291\n",
      "finished training epoch 1196\n",
      "train_loss:  1.259297143162571e-05 train_R2 0.8272463518715649\n",
      "finished training epoch 1197\n",
      "train_loss:  1.270427651548386e-05 train_R2 0.933813662939802\n",
      "finished training epoch 1198\n",
      "train_loss:  1.241904836831149e-05 train_R2 0.8173213697228535\n",
      "finished training epoch 1199\n",
      "train_loss:  1.2360632599325694e-05 train_R2 0.9022620242169442\n",
      "finished training epoch 1200\n",
      "train_loss:  1.266915433135746e-05 train_R2 0.7700016215935126\n",
      "finished training epoch 1201\n",
      "train_loss:  1.2764563297276078e-05 train_R2 0.8767581754942202\n",
      "finished training epoch 1202\n",
      "train_loss:  1.2415812460278539e-05 train_R2 0.9280671794686498\n",
      "finished training epoch 1203\n",
      "train_loss:  1.2592403036665005e-05 train_R2 0.8848750265272909\n",
      "finished training epoch 1204\n",
      "train_loss:  1.2377039153365209e-05 train_R2 0.8805305197222031\n",
      "finished training epoch 1205\n",
      "train_loss:  1.2397631018658279e-05 train_R2 0.8526671042362408\n",
      "finished training epoch 1206\n",
      "train_loss:  1.2228867204933483e-05 train_R2 0.813292948324103\n",
      "finished training epoch 1207\n",
      "train_loss:  1.249622940589826e-05 train_R2 0.8985224127441384\n",
      "finished training epoch 1208\n",
      "train_loss:  1.2715950393769754e-05 train_R2 0.9033638060808256\n",
      "finished training epoch 1209\n",
      "train_loss:  1.237094391359071e-05 train_R2 0.922030540149566\n",
      "finished training epoch 1210\n",
      "train_loss:  1.2610035750642096e-05 train_R2 0.8624304323482304\n",
      "finished training epoch 1211\n",
      "train_loss:  1.2485578999084693e-05 train_R2 0.88177811896388\n",
      "finished training epoch 1212\n",
      "train_loss:  1.244205188441805e-05 train_R2 0.8368963371999558\n",
      "finished training epoch 1213\n",
      "train_loss:  1.279940984112862e-05 train_R2 0.8130060638759014\n",
      "finished training epoch 1214\n",
      "train_loss:  1.2264772556879448e-05 train_R2 0.907650021365122\n",
      "finished training epoch 1215\n",
      "train_loss:  1.2407322046800189e-05 train_R2 0.8955101148811901\n",
      "finished training epoch 1216\n",
      "train_loss:  1.2107913477882902e-05 train_R2 0.8615548652693323\n",
      "finished training epoch 1217\n",
      "train_loss:  1.2358263639461676e-05 train_R2 0.880238856865029\n",
      "finished training epoch 1218\n",
      "train_loss:  1.2439257916051117e-05 train_R2 0.8335242740901159\n",
      "finished training epoch 1219\n",
      "train_loss:  1.2446111180885969e-05 train_R2 0.8587405385280994\n",
      "finished training epoch 1220\n",
      "train_loss:  1.2388232714824008e-05 train_R2 0.9053275469572624\n",
      "finished training epoch 1221\n",
      "train_loss:  1.2435141273596718e-05 train_R2 0.8635930809266529\n",
      "finished training epoch 1222\n",
      "train_loss:  1.2347454667004503e-05 train_R2 0.8808030955794358\n",
      "finished training epoch 1223\n",
      "train_loss:  1.2285927859089361e-05 train_R2 0.8892298420093838\n",
      "finished training epoch 1224\n",
      "train_loss:  1.2252088222920276e-05 train_R2 0.9085268722448593\n",
      "finished training epoch 1225\n",
      "train_loss:  1.2206379136555055e-05 train_R2 0.874212696513489\n",
      "finished training epoch 1226\n",
      "train_loss:  1.2280965653786486e-05 train_R2 0.8622193486383094\n",
      "finished training epoch 1227\n",
      "train_loss:  1.2264265796299592e-05 train_R2 0.8837375784079032\n",
      "finished training epoch 1228\n",
      "train_loss:  1.2427975125107617e-05 train_R2 0.8683256804955687\n",
      "finished training epoch 1229\n",
      "train_loss:  1.2552400544064063e-05 train_R2 0.8794614310516933\n",
      "finished training epoch 1230\n",
      "train_loss:  1.2447858198953e-05 train_R2 0.8691485239225523\n",
      "finished training epoch 1231\n",
      "train_loss:  1.2340944022665078e-05 train_R2 0.8629366337086457\n",
      "finished training epoch 1232\n",
      "train_loss:  1.2427611121194492e-05 train_R2 0.8763378921761917\n",
      "finished training epoch 1233\n",
      "train_loss:  1.2622709115084312e-05 train_R2 0.840077972006579\n",
      "finished training epoch 1234\n",
      "train_loss:  1.1757659969770446e-05 train_R2 0.9032701349593306\n",
      "finished training epoch 1235\n",
      "train_loss:  1.219211950273518e-05 train_R2 0.8563279437475634\n",
      "finished training epoch 1236\n",
      "train_loss:  1.2553665906806977e-05 train_R2 0.8952488652824818\n",
      "finished training epoch 1237\n",
      "train_loss:  1.2148016029531567e-05 train_R2 0.8479070553600975\n",
      "finished training epoch 1238\n",
      "train_loss:  1.2408454477327085e-05 train_R2 0.8193970653824346\n",
      "finished training epoch 1239\n",
      "train_loss:  1.254947120996169e-05 train_R2 0.9079157449636118\n",
      "finished training epoch 1240\n",
      "train_loss:  1.24031367435676e-05 train_R2 0.9166705080124748\n",
      "finished training epoch 1241\n",
      "train_loss:  1.2424581337704043e-05 train_R2 0.9019196009295329\n",
      "finished training epoch 1242\n",
      "train_loss:  1.2208059089827919e-05 train_R2 0.904361262743599\n",
      "finished training epoch 1243\n",
      "train_loss:  1.217873652137846e-05 train_R2 0.905799447504297\n",
      "finished training epoch 1244\n",
      "train_loss:  1.238909816205713e-05 train_R2 0.8716911744865097\n",
      "finished training epoch 1245\n",
      "train_loss:  1.2400008354257051e-05 train_R2 0.9327321281781993\n",
      "finished training epoch 1246\n",
      "train_loss:  1.2223715794813068e-05 train_R2 0.8486540581984978\n",
      "finished training epoch 1247\n",
      "train_loss:  1.2347270154627258e-05 train_R2 0.9094110180463235\n",
      "finished training epoch 1248\n",
      "train_loss:  1.2461802905027266e-05 train_R2 0.8738001162567308\n",
      "finished training epoch 1249\n",
      "train_loss:  1.2335353101883351e-05 train_R2 0.8851198114551906\n",
      "finished training epoch 1250\n",
      "train_loss:  1.2312875930351001e-05 train_R2 0.9233132222655798\n",
      "finished training epoch 1251\n",
      "train_loss:  1.2184597514741885e-05 train_R2 0.794888582492507\n",
      "finished training epoch 1252\n",
      "train_loss:  1.2228970459197478e-05 train_R2 0.8657003153348518\n",
      "finished training epoch 1253\n",
      "train_loss:  1.2324575179459665e-05 train_R2 0.9181854810143903\n",
      "finished training epoch 1254\n",
      "train_loss:  1.23451332209062e-05 train_R2 0.9067203907883198\n",
      "finished training epoch 1255\n",
      "train_loss:  1.2336638774195483e-05 train_R2 0.8961463310285662\n",
      "finished training epoch 1256\n",
      "train_loss:  1.2192971147829654e-05 train_R2 0.8679595974222243\n",
      "finished training epoch 1257\n",
      "train_loss:  1.232557587706461e-05 train_R2 0.8169779582009038\n",
      "finished training epoch 1258\n",
      "train_loss:  1.2134039960377253e-05 train_R2 0.8772562877672366\n",
      "finished training epoch 1259\n",
      "train_loss:  1.2376115578991637e-05 train_R2 0.8625104979614721\n",
      "finished training epoch 1260\n",
      "train_loss:  1.2484595165923279e-05 train_R2 0.8917973352442573\n",
      "finished training epoch 1261\n",
      "train_loss:  1.243383274120576e-05 train_R2 0.8313831218431179\n",
      "finished training epoch 1262\n",
      "train_loss:  1.2320855046387967e-05 train_R2 0.8774656484583595\n",
      "finished training epoch 1263\n",
      "train_loss:  1.254607573272279e-05 train_R2 0.847680903963319\n",
      "finished training epoch 1264\n",
      "train_loss:  1.2276824531335089e-05 train_R2 0.8261101634227496\n",
      "finished training epoch 1265\n",
      "train_loss:  1.204586825501989e-05 train_R2 0.8870945766892688\n",
      "finished training epoch 1266\n",
      "train_loss:  1.2310572152889634e-05 train_R2 0.9077141577459622\n",
      "finished training epoch 1267\n",
      "train_loss:  1.2336944703443735e-05 train_R2 0.9132381625265042\n",
      "finished training epoch 1268\n",
      "train_loss:  1.2299807151965738e-05 train_R2 0.8696082028037795\n",
      "finished training epoch 1269\n",
      "train_loss:  1.2232097666260781e-05 train_R2 0.8405644731716706\n",
      "finished training epoch 1270\n",
      "train_loss:  1.2373670127835176e-05 train_R2 0.8489500715267381\n",
      "finished training epoch 1271\n",
      "train_loss:  1.2266589343601033e-05 train_R2 0.8849993250132316\n",
      "finished training epoch 1272\n",
      "train_loss:  1.2418475914891848e-05 train_R2 0.7830276873614228\n",
      "finished training epoch 1273\n",
      "train_loss:  1.2276432018212547e-05 train_R2 0.9062679558647216\n",
      "finished training epoch 1274\n",
      "train_loss:  1.2618330976982099e-05 train_R2 0.887060943000746\n",
      "finished training epoch 1275\n",
      "train_loss:  1.2330726978161157e-05 train_R2 0.8724807305895127\n",
      "finished training epoch 1276\n",
      "train_loss:  1.2137187831728741e-05 train_R2 0.9159170577051766\n",
      "finished training epoch 1277\n",
      "train_loss:  1.224191975263569e-05 train_R2 0.8991071140501108\n",
      "finished training epoch 1278\n",
      "train_loss:  1.2388837251592116e-05 train_R2 0.8947982922380497\n",
      "finished training epoch 1279\n",
      "train_loss:  1.2329437569343201e-05 train_R2 0.8150215774305085\n",
      "finished training epoch 1280\n",
      "train_loss:  1.2321733124127496e-05 train_R2 0.8413679803667689\n",
      "finished training epoch 1281\n",
      "train_loss:  1.2362794337262529e-05 train_R2 0.8898131030490747\n",
      "finished training epoch 1282\n",
      "train_loss:  1.2585674752965753e-05 train_R2 0.8914704702030035\n",
      "finished training epoch 1283\n",
      "train_loss:  1.229819161036638e-05 train_R2 0.8925143108723181\n",
      "finished training epoch 1284\n",
      "train_loss:  1.2447722212153269e-05 train_R2 0.9244677101517662\n",
      "finished training epoch 1285\n",
      "train_loss:  1.2434991789614665e-05 train_R2 0.8609465371716132\n",
      "finished training epoch 1286\n",
      "train_loss:  1.2196616933170887e-05 train_R2 0.8586889931047743\n",
      "finished training epoch 1287\n",
      "train_loss:  1.2345785813669262e-05 train_R2 0.8497192300259231\n",
      "finished training epoch 1288\n",
      "train_loss:  1.226799151626451e-05 train_R2 0.8198959574037767\n",
      "finished training epoch 1289\n",
      "train_loss:  1.2374412336345713e-05 train_R2 0.886200213603564\n",
      "finished training epoch 1290\n",
      "train_loss:  1.2896259335013603e-05 train_R2 0.9219083933075113\n",
      "finished training epoch 1291\n",
      "train_loss:  1.2529787418238096e-05 train_R2 0.8948635634801683\n",
      "finished training epoch 1292\n",
      "train_loss:  1.2460090461309934e-05 train_R2 0.8633248721687199\n",
      "finished training epoch 1293\n",
      "train_loss:  1.2279269638548142e-05 train_R2 0.8091670840179125\n",
      "finished training epoch 1294\n",
      "train_loss:  1.2137949064561883e-05 train_R2 0.8937136536190671\n",
      "finished training epoch 1295\n",
      "train_loss:  1.2181691428536703e-05 train_R2 0.8727676919028504\n",
      "finished training epoch 1296\n",
      "train_loss:  1.253858395744384e-05 train_R2 0.857301974097298\n",
      "finished training epoch 1297\n",
      "train_loss:  1.2354955579739593e-05 train_R2 0.8884078308956708\n",
      "finished training epoch 1298\n",
      "train_loss:  1.270526985079941e-05 train_R2 0.7799357199889673\n",
      "finished training epoch 1299\n",
      "train_loss:  1.2153658281654327e-05 train_R2 0.9191479998333939\n",
      "finished training epoch 1300\n",
      "train_loss:  1.202779054457342e-05 train_R2 0.9025628854094978\n",
      "finished training epoch 1301\n",
      "train_loss:  1.2160198462171908e-05 train_R2 0.8901254585322496\n",
      "finished training epoch 1302\n",
      "train_loss:  1.246695278977972e-05 train_R2 0.9420157214522267\n",
      "finished training epoch 1303\n",
      "train_loss:  1.2415782515336061e-05 train_R2 0.9111909805399123\n",
      "finished training epoch 1304\n",
      "train_loss:  1.2866070745836032e-05 train_R2 0.911976614324633\n",
      "finished training epoch 1305\n",
      "train_loss:  1.2462247270581947e-05 train_R2 0.8786624872561103\n",
      "finished training epoch 1306\n",
      "train_loss:  1.2258713560175452e-05 train_R2 0.8808572438594975\n",
      "finished training epoch 1307\n",
      "train_loss:  1.2216901437742467e-05 train_R2 0.8923027374124275\n",
      "finished training epoch 1308\n",
      "train_loss:  1.2611489310646512e-05 train_R2 0.8447291084931656\n",
      "finished training epoch 1309\n",
      "train_loss:  1.2526529600652902e-05 train_R2 0.8609924242119598\n",
      "finished training epoch 1310\n",
      "train_loss:  1.2628161427327846e-05 train_R2 0.8888921592864585\n",
      "finished training epoch 1311\n",
      "train_loss:  1.2725384251752657e-05 train_R2 0.9048233879635345\n",
      "finished training epoch 1312\n",
      "train_loss:  1.2381040678523355e-05 train_R2 0.9187851457225109\n",
      "finished training epoch 1313\n",
      "train_loss:  1.228609732691441e-05 train_R2 0.9054980165599069\n",
      "finished training epoch 1314\n",
      "train_loss:  1.229659434438773e-05 train_R2 0.9043432802956228\n",
      "finished training epoch 1315\n",
      "train_loss:  1.2572998266743263e-05 train_R2 0.906519075795541\n",
      "finished training epoch 1316\n",
      "train_loss:  1.2406691554773085e-05 train_R2 0.9025751195966305\n",
      "finished training epoch 1317\n",
      "train_loss:  1.2258830573974672e-05 train_R2 0.9005495932339229\n",
      "finished training epoch 1318\n",
      "train_loss:  1.2210326185156125e-05 train_R2 0.8845977431900182\n",
      "finished training epoch 1319\n",
      "train_loss:  1.2132427432751164e-05 train_R2 0.9056424431911998\n",
      "finished training epoch 1320\n",
      "train_loss:  1.2394358525341716e-05 train_R2 0.8581459322775455\n",
      "finished training epoch 1321\n",
      "train_loss:  1.2357753088515033e-05 train_R2 0.9105280169024276\n",
      "finished training epoch 1322\n",
      "train_loss:  1.2184110969544027e-05 train_R2 0.851668258817344\n",
      "finished training epoch 1323\n",
      "train_loss:  1.2188475826968257e-05 train_R2 0.9010427953774545\n",
      "finished training epoch 1324\n",
      "train_loss:  1.223376839937018e-05 train_R2 0.9212343143626224\n",
      "finished training epoch 1325\n",
      "train_loss:  1.2200460522213246e-05 train_R2 0.8038922043960309\n",
      "finished training epoch 1326\n",
      "train_loss:  1.2589714534032661e-05 train_R2 0.853067567256285\n",
      "finished training epoch 1327\n",
      "train_loss:  1.2401602625370233e-05 train_R2 0.8536096757862641\n",
      "finished training epoch 1328\n",
      "train_loss:  1.2392537122654936e-05 train_R2 0.8732971762980599\n",
      "finished training epoch 1329\n",
      "train_loss:  1.226508092888433e-05 train_R2 0.8759256278815921\n",
      "finished training epoch 1330\n",
      "train_loss:  1.2309369648598349e-05 train_R2 0.8815775930792302\n",
      "finished training epoch 1331\n",
      "train_loss:  1.2099178079680189e-05 train_R2 0.8539949570022267\n",
      "finished training epoch 1332\n",
      "train_loss:  1.228135117916143e-05 train_R2 0.8518879384998553\n",
      "finished training epoch 1333\n",
      "train_loss:  1.2348808793299304e-05 train_R2 0.8153516999168923\n",
      "finished training epoch 1334\n",
      "train_loss:  1.233208222560879e-05 train_R2 0.8988409506398796\n",
      "finished training epoch 1335\n",
      "train_loss:  1.232089418773126e-05 train_R2 0.9058496584028031\n",
      "finished training epoch 1336\n",
      "train_loss:  1.221098234452822e-05 train_R2 0.8483158574018015\n",
      "finished training epoch 1337\n",
      "train_loss:  1.2482686913256051e-05 train_R2 0.9007510208972983\n",
      "finished training epoch 1338\n",
      "train_loss:  1.2501462478133248e-05 train_R2 0.8302463212270996\n",
      "finished training epoch 1339\n",
      "train_loss:  1.2353135496214956e-05 train_R2 0.8918763919982784\n",
      "finished training epoch 1340\n",
      "train_loss:  1.2229936577152907e-05 train_R2 0.8861697483251864\n",
      "finished training epoch 1341\n",
      "train_loss:  1.2241675340546611e-05 train_R2 0.9092942171883277\n",
      "finished training epoch 1342\n",
      "train_loss:  1.2273914764733354e-05 train_R2 0.9247040698623953\n",
      "finished training epoch 1343\n",
      "train_loss:  1.227907052136405e-05 train_R2 0.8978875973441984\n",
      "finished training epoch 1344\n",
      "train_loss:  1.2211474441942949e-05 train_R2 0.8121730257864688\n",
      "finished training epoch 1345\n",
      "train_loss:  1.2123496903854766e-05 train_R2 0.9075647242833332\n",
      "finished training epoch 1346\n",
      "train_loss:  1.204815994149325e-05 train_R2 0.8530174734007571\n",
      "finished training epoch 1347\n",
      "train_loss:  1.2016171592530642e-05 train_R2 0.842565468095281\n",
      "finished training epoch 1348\n",
      "train_loss:  1.2189218725139174e-05 train_R2 0.895887096655529\n",
      "finished training epoch 1349\n",
      "train_loss:  1.2602222387759663e-05 train_R2 0.8674381740098522\n",
      "finished training epoch 1350\n",
      "train_loss:  1.2910127524733549e-05 train_R2 0.8944346983085417\n",
      "finished training epoch 1351\n",
      "train_loss:  1.2765767568132677e-05 train_R2 0.8746224963459526\n",
      "finished training epoch 1352\n",
      "train_loss:  1.264806319381435e-05 train_R2 0.9123409851781475\n",
      "finished training epoch 1353\n",
      "train_loss:  1.2298554609750306e-05 train_R2 0.8303181391872354\n",
      "finished training epoch 1354\n",
      "train_loss:  1.2458847529689162e-05 train_R2 0.8772627605864339\n",
      "finished training epoch 1355\n",
      "train_loss:  1.2907785474446922e-05 train_R2 0.9289017211352988\n",
      "finished training epoch 1356\n",
      "train_loss:  1.2729471485269205e-05 train_R2 0.8844346555213298\n",
      "finished training epoch 1357\n",
      "train_loss:  1.25338069776964e-05 train_R2 0.904051070427714\n",
      "finished training epoch 1358\n",
      "train_loss:  1.2022487894434244e-05 train_R2 0.9027735699898873\n",
      "finished training epoch 1359\n",
      "train_loss:  1.2342884109637554e-05 train_R2 0.8709910062197926\n",
      "finished training epoch 1360\n",
      "train_loss:  1.279345986497335e-05 train_R2 0.8586105846955597\n",
      "finished training epoch 1361\n",
      "train_loss:  1.2644259184951999e-05 train_R2 0.8891149950016681\n",
      "finished training epoch 1362\n",
      "train_loss:  1.2301639749635613e-05 train_R2 0.9097091941471058\n",
      "finished training epoch 1363\n",
      "train_loss:  1.2007325466545257e-05 train_R2 0.8898458508347806\n",
      "finished training epoch 1364\n",
      "train_loss:  1.2423186806694614e-05 train_R2 0.9186809452985711\n",
      "finished training epoch 1365\n",
      "train_loss:  1.2374125131034126e-05 train_R2 0.8797050830831794\n",
      "finished training epoch 1366\n",
      "train_loss:  1.2372151311387735e-05 train_R2 0.8705108807886763\n",
      "finished training epoch 1367\n",
      "train_loss:  1.2392723249546872e-05 train_R2 0.8929174482437692\n",
      "finished training epoch 1368\n",
      "train_loss:  1.2253677269738665e-05 train_R2 0.9076284244214687\n",
      "finished training epoch 1369\n",
      "train_loss:  1.2021318634620546e-05 train_R2 0.8571849382217499\n",
      "finished training epoch 1370\n",
      "train_loss:  1.2276769298555091e-05 train_R2 0.8535217361734954\n",
      "finished training epoch 1371\n",
      "train_loss:  1.2427099578786414e-05 train_R2 0.8599632279587892\n",
      "finished training epoch 1372\n",
      "train_loss:  1.2337511838427008e-05 train_R2 0.8561566620234364\n",
      "finished training epoch 1373\n",
      "train_loss:  1.228951973040442e-05 train_R2 0.8758903146101747\n",
      "finished training epoch 1374\n",
      "train_loss:  1.2148346237046208e-05 train_R2 0.88896340559536\n",
      "finished training epoch 1375\n",
      "train_loss:  1.1826234840444783e-05 train_R2 0.8907244434139828\n",
      "finished training epoch 1376\n",
      "train_loss:  1.2252588759750108e-05 train_R2 0.8872895616229756\n",
      "finished training epoch 1377\n",
      "train_loss:  1.2165453143506433e-05 train_R2 0.8853926212421133\n",
      "finished training epoch 1378\n",
      "train_loss:  1.19829029538737e-05 train_R2 0.903163815698244\n",
      "finished training epoch 1379\n",
      "train_loss:  1.203782407415843e-05 train_R2 0.913049061127026\n",
      "finished training epoch 1380\n",
      "train_loss:  1.2295270821367636e-05 train_R2 0.8954546893314616\n",
      "finished training epoch 1381\n",
      "train_loss:  1.2256479265760117e-05 train_R2 0.9198148012506439\n",
      "finished training epoch 1382\n",
      "train_loss:  1.2476953507497716e-05 train_R2 0.867273347060848\n",
      "finished training epoch 1383\n",
      "train_loss:  1.2138199895689372e-05 train_R2 0.8494813510667136\n",
      "finished training epoch 1384\n",
      "train_loss:  1.233957683273971e-05 train_R2 0.9105621756394606\n",
      "finished training epoch 1385\n",
      "train_loss:  1.211940012617493e-05 train_R2 0.898096435091433\n",
      "finished training epoch 1386\n",
      "train_loss:  1.2321860805345621e-05 train_R2 0.898578371962288\n",
      "finished training epoch 1387\n",
      "train_loss:  1.2314238367158197e-05 train_R2 0.9046471749376218\n",
      "finished training epoch 1388\n",
      "train_loss:  1.1953472025027743e-05 train_R2 0.8251883143360665\n",
      "finished training epoch 1389\n",
      "train_loss:  1.192259853316318e-05 train_R2 0.861448942255222\n",
      "finished training epoch 1390\n",
      "train_loss:  1.2172828990326729e-05 train_R2 0.9009113004455828\n",
      "finished training epoch 1391\n",
      "train_loss:  1.234663819454498e-05 train_R2 0.9108318906379398\n",
      "finished training epoch 1392\n",
      "train_loss:  1.2392759186365533e-05 train_R2 0.9172732007795787\n",
      "finished training epoch 1393\n",
      "train_loss:  1.2082183230419302e-05 train_R2 0.8936686911314671\n",
      "finished training epoch 1394\n",
      "train_loss:  1.2149081677551685e-05 train_R2 0.8881170462915902\n",
      "finished training epoch 1395\n",
      "train_loss:  1.2066822189446054e-05 train_R2 0.890629526396567\n",
      "finished training epoch 1396\n",
      "train_loss:  1.2384332127188607e-05 train_R2 0.8843673007879564\n",
      "finished training epoch 1397\n",
      "train_loss:  1.2496289266494593e-05 train_R2 0.8967323299595205\n",
      "finished training epoch 1398\n",
      "train_loss:  1.2362626834942194e-05 train_R2 0.8602615722356062\n",
      "finished training epoch 1399\n",
      "train_loss:  1.2098394303930473e-05 train_R2 0.9007296974726198\n",
      "finished training epoch 1400\n",
      "train_loss:  1.2056427082310976e-05 train_R2 0.8918330336118994\n",
      "finished training epoch 1401\n",
      "train_loss:  1.203431673481209e-05 train_R2 0.9097460225709205\n",
      "finished training epoch 1402\n",
      "train_loss:  1.2024376676440468e-05 train_R2 0.8913220100048751\n",
      "finished training epoch 1403\n",
      "train_loss:  1.2396953031668071e-05 train_R2 0.879026782173537\n",
      "finished training epoch 1404\n",
      "train_loss:  1.2368067287658822e-05 train_R2 0.8256034567511799\n",
      "finished training epoch 1405\n",
      "train_loss:  1.2325919251938532e-05 train_R2 0.8934407431259507\n",
      "finished training epoch 1406\n",
      "train_loss:  1.2278351261474738e-05 train_R2 0.8956178550464658\n",
      "finished training epoch 1407\n",
      "train_loss:  1.2105319704180442e-05 train_R2 0.8440357753389244\n",
      "finished training epoch 1408\n",
      "train_loss:  1.2028990333323022e-05 train_R2 0.8065950546262657\n",
      "finished training epoch 1409\n",
      "train_loss:  1.2587935629915202e-05 train_R2 0.8998399085606348\n",
      "finished training epoch 1410\n",
      "train_loss:  1.2780528705730237e-05 train_R2 0.8165656480412198\n",
      "finished training epoch 1411\n",
      "train_loss:  1.2043017677084356e-05 train_R2 0.8713596868723914\n",
      "finished training epoch 1412\n",
      "train_loss:  1.1933430469758091e-05 train_R2 0.9023462404804241\n",
      "finished training epoch 1413\n",
      "train_loss:  1.2346995217821548e-05 train_R2 0.8544996951842352\n",
      "finished training epoch 1414\n",
      "train_loss:  1.2373939234274953e-05 train_R2 0.8969682213556255\n",
      "finished training epoch 1415\n",
      "train_loss:  1.2473573886773905e-05 train_R2 0.8982529573751817\n",
      "finished training epoch 1416\n",
      "train_loss:  1.223646766036399e-05 train_R2 0.8614436694122887\n",
      "finished training epoch 1417\n",
      "train_loss:  1.2445718167535981e-05 train_R2 0.8915193599654344\n",
      "finished training epoch 1418\n",
      "train_loss:  1.2519807009013387e-05 train_R2 0.8790162194951217\n",
      "finished training epoch 1419\n",
      "train_loss:  1.2581872890944203e-05 train_R2 0.890980115928474\n",
      "finished training epoch 1420\n",
      "train_loss:  1.2095464248489981e-05 train_R2 0.9280279359640295\n",
      "finished training epoch 1421\n",
      "train_loss:  1.2176369933678061e-05 train_R2 0.8388479311840229\n",
      "finished training epoch 1422\n",
      "train_loss:  1.2052187860610505e-05 train_R2 0.8816497351843354\n",
      "finished training epoch 1423\n",
      "train_loss:  1.2355789125489782e-05 train_R2 0.893507410725051\n",
      "finished training epoch 1424\n",
      "train_loss:  1.2400333457296076e-05 train_R2 0.8414868095656021\n",
      "finished training epoch 1425\n",
      "train_loss:  1.2337375934293399e-05 train_R2 0.8839943862498687\n",
      "finished training epoch 1426\n",
      "train_loss:  1.2050853803405822e-05 train_R2 0.8982851407276554\n",
      "finished training epoch 1427\n",
      "train_loss:  1.2243950623266368e-05 train_R2 0.8844830708852641\n",
      "finished training epoch 1428\n",
      "train_loss:  1.2357372688603891e-05 train_R2 0.875873501692031\n",
      "finished training epoch 1429\n",
      "train_loss:  1.2229430648557775e-05 train_R2 0.892177223562628\n",
      "finished training epoch 1430\n",
      "train_loss:  1.2859316551723023e-05 train_R2 0.8823039153737736\n",
      "finished training epoch 1431\n",
      "train_loss:  1.2267499321752298e-05 train_R2 0.8117653984439588\n",
      "finished training epoch 1432\n",
      "train_loss:  1.2235353217452246e-05 train_R2 0.8851088131080203\n",
      "finished training epoch 1433\n",
      "train_loss:  1.200818962232387e-05 train_R2 0.9047000502488086\n",
      "finished training epoch 1434\n",
      "train_loss:  1.2180994625075061e-05 train_R2 0.9029845715131216\n",
      "finished training epoch 1435\n",
      "train_loss:  1.246802683355237e-05 train_R2 0.8926262918918939\n",
      "finished training epoch 1436\n",
      "train_loss:  1.271554498435955e-05 train_R2 0.8728003883882932\n",
      "finished training epoch 1437\n",
      "train_loss:  1.2652642951089518e-05 train_R2 0.910611618408548\n",
      "finished training epoch 1438\n",
      "train_loss:  1.2150130096674843e-05 train_R2 0.9039236868002247\n",
      "finished training epoch 1439\n",
      "train_loss:  1.2079637608662883e-05 train_R2 0.8957482470372418\n",
      "finished training epoch 1440\n",
      "train_loss:  1.207044136895334e-05 train_R2 0.8475655172878265\n",
      "finished training epoch 1441\n",
      "train_loss:  1.2441185578889707e-05 train_R2 0.8698936260106638\n",
      "finished training epoch 1442\n",
      "train_loss:  1.2211561678127778e-05 train_R2 0.9206944277351995\n",
      "finished training epoch 1443\n",
      "train_loss:  1.2178677439335964e-05 train_R2 0.8924081555022989\n",
      "finished training epoch 1444\n",
      "train_loss:  1.2096791964706928e-05 train_R2 0.9315631990914086\n",
      "finished training epoch 1445\n",
      "train_loss:  1.2200546546633724e-05 train_R2 0.912257375682884\n",
      "finished training epoch 1446\n",
      "train_loss:  1.2109225475556288e-05 train_R2 0.9221003184191052\n",
      "finished training epoch 1447\n",
      "train_loss:  1.2128908192444426e-05 train_R2 0.8940186344214396\n",
      "finished training epoch 1448\n",
      "train_loss:  1.2120104629589493e-05 train_R2 0.8916187270747685\n",
      "finished training epoch 1449\n",
      "train_loss:  1.2169268161738632e-05 train_R2 0.8771792375342826\n",
      "finished training epoch 1450\n",
      "train_loss:  1.203462990693313e-05 train_R2 0.8998275548700653\n",
      "finished training epoch 1451\n",
      "train_loss:  1.1985742051396422e-05 train_R2 0.8999806560904081\n",
      "finished training epoch 1452\n",
      "train_loss:  1.2143839916042713e-05 train_R2 0.9360390598227872\n",
      "finished training epoch 1453\n",
      "train_loss:  1.1927058411484286e-05 train_R2 0.8986134997408333\n",
      "finished training epoch 1454\n",
      "train_loss:  1.2430830628441494e-05 train_R2 0.8440960990635824\n",
      "finished training epoch 1455\n",
      "train_loss:  1.1973197561973204e-05 train_R2 0.9187806930575682\n",
      "finished training epoch 1456\n",
      "train_loss:  1.203009577349487e-05 train_R2 0.8719193967289768\n",
      "finished training epoch 1457\n",
      "train_loss:  1.2290411434236455e-05 train_R2 0.860933902081067\n",
      "finished training epoch 1458\n",
      "train_loss:  1.2067384060035182e-05 train_R2 0.8714798440310344\n",
      "finished training epoch 1459\n",
      "train_loss:  1.220837046289865e-05 train_R2 0.8803702929469892\n",
      "finished training epoch 1460\n",
      "train_loss:  1.2090355504861952e-05 train_R2 0.8618527452416842\n",
      "finished training epoch 1461\n",
      "train_loss:  1.198541015379988e-05 train_R2 0.8711497615968844\n",
      "finished training epoch 1462\n",
      "train_loss:  1.1916153777073305e-05 train_R2 0.9132817469220754\n",
      "finished training epoch 1463\n",
      "train_loss:  1.188896380418394e-05 train_R2 0.8691792216416958\n",
      "finished training epoch 1464\n",
      "train_loss:  1.1978043007936902e-05 train_R2 0.905907592147253\n",
      "finished training epoch 1465\n",
      "train_loss:  1.206834319375627e-05 train_R2 0.8135468153564345\n",
      "finished training epoch 1466\n",
      "train_loss:  1.2001227786022953e-05 train_R2 0.8727740335834909\n",
      "finished training epoch 1467\n",
      "train_loss:  1.2064552062622918e-05 train_R2 0.9240793475211201\n",
      "finished training epoch 1468\n",
      "train_loss:  1.2062628781587572e-05 train_R2 0.8754875279359373\n",
      "finished training epoch 1469\n",
      "train_loss:  1.2098865474391178e-05 train_R2 0.9068805548368766\n",
      "finished training epoch 1470\n",
      "train_loss:  1.2090746371116104e-05 train_R2 0.8907384377836853\n",
      "finished training epoch 1471\n",
      "train_loss:  1.2066445614334558e-05 train_R2 0.9023250126483613\n",
      "finished training epoch 1472\n",
      "train_loss:  1.2252174045153602e-05 train_R2 0.8937131352316632\n",
      "finished training epoch 1473\n",
      "train_loss:  1.2090064120001266e-05 train_R2 0.8590449896839568\n",
      "finished training epoch 1474\n",
      "train_loss:  1.219199404063055e-05 train_R2 0.8586309545579687\n",
      "finished training epoch 1475\n",
      "train_loss:  1.1918461658801699e-05 train_R2 0.8907225502164194\n",
      "finished training epoch 1476\n",
      "train_loss:  1.209662463877128e-05 train_R2 0.8755559520748354\n",
      "finished training epoch 1477\n",
      "train_loss:  1.1702168188788669e-05 train_R2 0.8790379423530212\n",
      "finished training epoch 1478\n",
      "train_loss:  1.2570398871517052e-05 train_R2 0.8495077582271431\n",
      "finished training epoch 1479\n",
      "train_loss:  1.2762643401035934e-05 train_R2 0.90720740943911\n",
      "finished training epoch 1480\n",
      "train_loss:  1.2353863142093664e-05 train_R2 0.8834161695120031\n",
      "finished training epoch 1481\n",
      "train_loss:  1.2237089394390109e-05 train_R2 0.8925018822850426\n",
      "finished training epoch 1482\n",
      "train_loss:  1.2060717252245877e-05 train_R2 0.8985409686272002\n",
      "finished training epoch 1483\n",
      "train_loss:  1.2143701391076145e-05 train_R2 0.8268518409351601\n",
      "finished training epoch 1484\n",
      "train_loss:  1.2589065559546789e-05 train_R2 0.863434807212203\n",
      "finished training epoch 1485\n",
      "train_loss:  1.2153935162544206e-05 train_R2 0.8733503111646069\n",
      "finished training epoch 1486\n",
      "train_loss:  1.2325276567486108e-05 train_R2 0.8346560739381359\n",
      "finished training epoch 1487\n",
      "train_loss:  1.2068409740915705e-05 train_R2 0.8833165371554254\n",
      "finished training epoch 1488\n",
      "train_loss:  1.2055360155550428e-05 train_R2 0.9006623851006714\n",
      "finished training epoch 1489\n",
      "train_loss:  1.1992836435154105e-05 train_R2 0.8761840939351586\n",
      "finished training epoch 1490\n",
      "train_loss:  1.1968505452478905e-05 train_R2 0.9099331065158461\n",
      "finished training epoch 1491\n",
      "train_loss:  1.2022014382817263e-05 train_R2 0.8517932712358165\n",
      "finished training epoch 1492\n",
      "train_loss:  1.2029804907547878e-05 train_R2 0.8854400550572445\n",
      "finished training epoch 1493\n",
      "train_loss:  1.2065551554617905e-05 train_R2 0.8404158475687847\n",
      "finished training epoch 1494\n",
      "train_loss:  1.1995029219351642e-05 train_R2 0.9179754842092687\n",
      "finished training epoch 1495\n",
      "train_loss:  1.2214127023817514e-05 train_R2 0.8956731462757229\n",
      "finished training epoch 1496\n",
      "train_loss:  1.1732241415130363e-05 train_R2 0.8906651190178982\n",
      "finished training epoch 1497\n",
      "train_loss:  1.2278292587200731e-05 train_R2 0.8506403661738269\n",
      "finished training epoch 1498\n",
      "train_loss:  1.2128161315411886e-05 train_R2 0.8929938840557857\n",
      "finished training epoch 1499\n",
      "train_loss:  1.1971667971304396e-05 train_R2 0.9320764774463656\n",
      "finished training epoch 1500\n",
      "train_loss:  1.1948344455364214e-05 train_R2 0.8696064626109928\n",
      "finished training epoch 1501\n",
      "train_loss:  1.2122733719750043e-05 train_R2 0.913521925287905\n",
      "finished training epoch 1502\n",
      "train_loss:  1.227809595019034e-05 train_R2 0.8469456184653252\n",
      "finished training epoch 1503\n",
      "train_loss:  1.1922444350673895e-05 train_R2 0.924230473623102\n",
      "finished training epoch 1504\n",
      "train_loss:  1.1805365829131851e-05 train_R2 0.9161918582007454\n",
      "finished training epoch 1505\n",
      "train_loss:  1.2061439496718104e-05 train_R2 0.862964327669042\n",
      "finished training epoch 1506\n",
      "train_loss:  1.1919847094480595e-05 train_R2 0.9126290514651566\n",
      "finished training epoch 1507\n",
      "train_loss:  1.2189124145688958e-05 train_R2 0.7745575550322966\n",
      "finished training epoch 1508\n",
      "train_loss:  1.2283709341476557e-05 train_R2 0.891114135199085\n",
      "finished training epoch 1509\n",
      "train_loss:  1.2372709910216591e-05 train_R2 0.7771587984776984\n",
      "finished training epoch 1510\n",
      "train_loss:  1.2284518186059494e-05 train_R2 0.8746042536988321\n",
      "finished training epoch 1511\n",
      "train_loss:  1.1993675377840054e-05 train_R2 0.9111130258548595\n",
      "finished training epoch 1512\n",
      "train_loss:  1.1956551887140544e-05 train_R2 0.886587724356688\n",
      "finished training epoch 1513\n",
      "train_loss:  1.2099211522120068e-05 train_R2 0.8894165839379213\n",
      "finished training epoch 1514\n",
      "train_loss:  1.2073063459171684e-05 train_R2 0.9257962004034346\n",
      "finished training epoch 1515\n",
      "train_loss:  1.2144769708385578e-05 train_R2 0.8902043370773965\n",
      "finished training epoch 1516\n",
      "train_loss:  1.2064708528984881e-05 train_R2 0.8586806068742505\n",
      "finished training epoch 1517\n",
      "train_loss:  1.2057244089043706e-05 train_R2 0.8787814770841025\n",
      "finished training epoch 1518\n",
      "train_loss:  1.2108751576562128e-05 train_R2 0.8226596803650288\n",
      "finished training epoch 1519\n",
      "train_loss:  1.2107132116175184e-05 train_R2 0.8689181253978095\n",
      "finished training epoch 1520\n",
      "train_loss:  1.2396675660758823e-05 train_R2 0.9274861749512744\n",
      "finished training epoch 1521\n",
      "train_loss:  1.2120204666295299e-05 train_R2 0.8559689985225366\n",
      "finished training epoch 1522\n",
      "train_loss:  1.2233684760464368e-05 train_R2 0.902245411914793\n",
      "finished training epoch 1523\n",
      "train_loss:  1.2055877716787125e-05 train_R2 0.8874493840625166\n",
      "finished training epoch 1524\n",
      "train_loss:  1.200167603289818e-05 train_R2 0.8867892343858468\n",
      "finished training epoch 1525\n",
      "train_loss:  1.210450366692189e-05 train_R2 0.9055006958971812\n",
      "finished training epoch 1526\n",
      "train_loss:  1.2056976417871025e-05 train_R2 0.8439108043110686\n",
      "finished training epoch 1527\n",
      "train_loss:  1.21674867655187e-05 train_R2 0.8892130904744096\n",
      "finished training epoch 1528\n",
      "train_loss:  1.2204170799010416e-05 train_R2 0.8727734822605875\n",
      "finished training epoch 1529\n",
      "train_loss:  1.2091133939492023e-05 train_R2 0.8972818400327858\n",
      "finished training epoch 1530\n",
      "train_loss:  1.1971913898472193e-05 train_R2 0.8830875015910423\n",
      "finished training epoch 1531\n",
      "train_loss:  1.2066098553516094e-05 train_R2 0.9197830852381041\n",
      "finished training epoch 1532\n",
      "train_loss:  1.2250799701920952e-05 train_R2 0.883705170932301\n",
      "finished training epoch 1533\n",
      "train_loss:  1.1924446895833185e-05 train_R2 0.8873145264500943\n",
      "finished training epoch 1534\n",
      "train_loss:  1.2033543001987189e-05 train_R2 0.9157858988250771\n",
      "finished training epoch 1535\n",
      "train_loss:  1.1758989389949742e-05 train_R2 0.9138313927838363\n",
      "finished training epoch 1536\n",
      "train_loss:  1.1996191184578079e-05 train_R2 0.8914275388455086\n",
      "finished training epoch 1537\n",
      "train_loss:  1.20469445420785e-05 train_R2 0.9127867935925973\n",
      "finished training epoch 1538\n",
      "train_loss:  1.2198638956493749e-05 train_R2 0.9163628696116876\n",
      "finished training epoch 1539\n",
      "train_loss:  1.2132925511443339e-05 train_R2 0.8892195246065417\n",
      "finished training epoch 1540\n",
      "train_loss:  1.1891554420612247e-05 train_R2 0.8998819659225624\n",
      "finished training epoch 1541\n",
      "train_loss:  1.2089860721295961e-05 train_R2 0.8919367393254489\n",
      "finished training epoch 1542\n",
      "train_loss:  1.2179180924231885e-05 train_R2 0.9266629744911806\n",
      "finished training epoch 1543\n",
      "train_loss:  1.2038421862439317e-05 train_R2 0.8940090577833871\n",
      "finished training epoch 1544\n",
      "train_loss:  1.2252592062916804e-05 train_R2 0.9022780820757714\n",
      "finished training epoch 1545\n",
      "train_loss:  1.1989171971012278e-05 train_R2 0.8294814815890578\n",
      "finished training epoch 1546\n",
      "train_loss:  1.207007875676918e-05 train_R2 0.878114158552597\n",
      "finished training epoch 1547\n",
      "train_loss:  1.1778360386996361e-05 train_R2 0.913537714268284\n",
      "finished training epoch 1548\n",
      "train_loss:  1.1977951090648248e-05 train_R2 0.9150552747378613\n",
      "finished training epoch 1549\n",
      "train_loss:  1.2352593085358885e-05 train_R2 0.8955226535379679\n",
      "finished training epoch 1550\n",
      "train_loss:  1.2004050658440881e-05 train_R2 0.9136156291645912\n",
      "finished training epoch 1551\n",
      "train_loss:  1.206658654794611e-05 train_R2 0.8619227814993774\n",
      "finished training epoch 1552\n",
      "train_loss:  1.1766224333256573e-05 train_R2 0.9134209252839539\n",
      "finished training epoch 1553\n",
      "train_loss:  1.197521914580736e-05 train_R2 0.928778888959637\n",
      "finished training epoch 1554\n",
      "train_loss:  1.2166174023055154e-05 train_R2 0.905398363593484\n",
      "finished training epoch 1555\n",
      "train_loss:  1.227731234542155e-05 train_R2 0.8215876785854626\n",
      "finished training epoch 1556\n",
      "train_loss:  1.219648163949297e-05 train_R2 0.9302087241879834\n",
      "finished training epoch 1557\n",
      "train_loss:  1.1932492817760244e-05 train_R2 0.8796472419466896\n",
      "finished training epoch 1558\n",
      "train_loss:  1.1994332596193656e-05 train_R2 0.8815420474539379\n",
      "finished training epoch 1559\n",
      "train_loss:  1.203525533067391e-05 train_R2 0.9129419301767986\n",
      "finished training epoch 1560\n",
      "train_loss:  1.1833869680358167e-05 train_R2 0.8589310974695679\n",
      "finished training epoch 1561\n",
      "train_loss:  1.2230851150304386e-05 train_R2 0.897959285755481\n",
      "finished training epoch 1562\n",
      "train_loss:  1.170959787315251e-05 train_R2 0.8832973547370739\n",
      "finished training epoch 1563\n",
      "train_loss:  1.1924108821399848e-05 train_R2 0.903662310870244\n",
      "finished training epoch 1564\n",
      "train_loss:  1.2121194742268689e-05 train_R2 0.8709528480826507\n",
      "finished training epoch 1565\n",
      "train_loss:  1.1746658915305191e-05 train_R2 0.922289477989305\n",
      "finished training epoch 1566\n",
      "train_loss:  1.2089385470013077e-05 train_R2 0.8913420502113079\n",
      "finished training epoch 1567\n",
      "train_loss:  1.2048406244690112e-05 train_R2 0.9090772890911102\n",
      "finished training epoch 1568\n",
      "train_loss:  1.1955130526145866e-05 train_R2 0.9052034607006909\n",
      "finished training epoch 1569\n",
      "train_loss:  1.1949954729525025e-05 train_R2 0.9115013858792617\n",
      "finished training epoch 1570\n",
      "train_loss:  1.1831096935783293e-05 train_R2 0.9038981246004546\n",
      "finished training epoch 1571\n",
      "train_loss:  1.2194843767395807e-05 train_R2 0.8965485888368124\n",
      "finished training epoch 1572\n",
      "train_loss:  1.2155133816675392e-05 train_R2 0.8877642374345373\n",
      "finished training epoch 1573\n",
      "train_loss:  1.2057909030466696e-05 train_R2 0.8561275043788659\n",
      "finished training epoch 1574\n",
      "train_loss:  1.1656865265427321e-05 train_R2 0.9114390129521431\n",
      "finished training epoch 1575\n",
      "train_loss:  1.2005828816118502e-05 train_R2 0.8680677176911415\n",
      "finished training epoch 1576\n",
      "train_loss:  1.2034800248450402e-05 train_R2 0.87428836994726\n",
      "finished training epoch 1577\n",
      "train_loss:  1.2023548785498982e-05 train_R2 0.871967975493499\n",
      "finished training epoch 1578\n",
      "train_loss:  1.2045985690691077e-05 train_R2 0.8832572629168897\n",
      "finished training epoch 1579\n",
      "train_loss:  1.1948800292139824e-05 train_R2 0.8913632425229947\n",
      "finished training epoch 1580\n",
      "train_loss:  1.2025935853912983e-05 train_R2 0.9116848771770937\n",
      "finished training epoch 1581\n",
      "train_loss:  1.2092269609840464e-05 train_R2 0.8751000000647279\n",
      "finished training epoch 1582\n",
      "train_loss:  1.1895906973644148e-05 train_R2 0.8668046149500683\n",
      "finished training epoch 1583\n",
      "train_loss:  1.2087229383793226e-05 train_R2 0.8179036421799852\n",
      "finished training epoch 1584\n",
      "train_loss:  1.2097158536835755e-05 train_R2 0.8717402414830031\n",
      "finished training epoch 1585\n",
      "train_loss:  1.1800044889798344e-05 train_R2 0.8874433073873398\n",
      "finished training epoch 1586\n",
      "train_loss:  1.1925493847308034e-05 train_R2 0.8666089475862213\n",
      "finished training epoch 1587\n",
      "train_loss:  1.1847981850789603e-05 train_R2 0.8745714052040213\n",
      "finished training epoch 1588\n",
      "train_loss:  1.1835293910191602e-05 train_R2 0.8482234941547893\n",
      "finished training epoch 1589\n",
      "train_loss:  1.2152785946660585e-05 train_R2 0.8850577098063639\n",
      "finished training epoch 1590\n",
      "train_loss:  1.1896850930829122e-05 train_R2 0.8554964566283562\n",
      "finished training epoch 1591\n",
      "train_loss:  1.2034887115875659e-05 train_R2 0.8649969375414631\n",
      "finished training epoch 1592\n",
      "train_loss:  1.1900893711332137e-05 train_R2 0.8504937779594272\n",
      "finished training epoch 1593\n",
      "train_loss:  1.1719061671522663e-05 train_R2 0.8528191906192495\n",
      "finished training epoch 1594\n",
      "train_loss:  1.1958858439371121e-05 train_R2 0.8708473629338764\n",
      "finished training epoch 1595\n",
      "train_loss:  1.1931843581477663e-05 train_R2 0.9166778084739219\n",
      "finished training epoch 1596\n",
      "train_loss:  1.2123455453621988e-05 train_R2 0.8720473460781417\n",
      "finished training epoch 1597\n",
      "train_loss:  1.2279341060471666e-05 train_R2 0.8869767573659574\n",
      "finished training epoch 1598\n",
      "train_loss:  1.2019279105762563e-05 train_R2 0.8698484444900456\n",
      "finished training epoch 1599\n",
      "train_loss:  1.187860711671811e-05 train_R2 0.8799188210850243\n",
      "finished training epoch 1600\n",
      "train_loss:  1.1782179468852858e-05 train_R2 0.850294419660375\n",
      "finished training epoch 1601\n",
      "train_loss:  1.1813942951354567e-05 train_R2 0.882918343381321\n",
      "finished training epoch 1602\n",
      "train_loss:  1.200635736134246e-05 train_R2 0.8878123534005757\n",
      "finished training epoch 1603\n",
      "train_loss:  1.2258559708148891e-05 train_R2 0.9387665956622339\n",
      "finished training epoch 1604\n",
      "train_loss:  1.1920487216606604e-05 train_R2 0.8783587807678377\n",
      "finished training epoch 1605\n",
      "train_loss:  1.2112817479814195e-05 train_R2 0.8628090477108046\n",
      "finished training epoch 1606\n",
      "train_loss:  1.1680585438199863e-05 train_R2 0.9013235691224765\n",
      "finished training epoch 1607\n",
      "train_loss:  1.1772011834385602e-05 train_R2 0.8782316444308682\n",
      "finished training epoch 1608\n",
      "train_loss:  1.1866053000436831e-05 train_R2 0.9118344358875659\n",
      "finished training epoch 1609\n",
      "train_loss:  1.1907342355587384e-05 train_R2 0.8636033561323773\n",
      "finished training epoch 1610\n",
      "train_loss:  1.1689865574739653e-05 train_R2 0.8653520216320986\n",
      "finished training epoch 1611\n",
      "train_loss:  1.2040072239878447e-05 train_R2 0.8641051244071161\n",
      "finished training epoch 1612\n",
      "train_loss:  1.1501542944873928e-05 train_R2 0.8968859122455424\n",
      "finished training epoch 1613\n",
      "train_loss:  1.2073447207520955e-05 train_R2 0.8581714863314885\n",
      "finished training epoch 1614\n",
      "train_loss:  1.2463730055480774e-05 train_R2 0.8832803237084711\n",
      "finished training epoch 1615\n",
      "train_loss:  1.2719174307923828e-05 train_R2 0.8978360480285789\n",
      "finished training epoch 1616\n",
      "train_loss:  1.2738174128095929e-05 train_R2 0.885572217888078\n",
      "finished training epoch 1617\n",
      "train_loss:  1.2198531575697234e-05 train_R2 0.8948700795893716\n",
      "finished training epoch 1618\n",
      "train_loss:  1.1920919260053275e-05 train_R2 0.8561992940462392\n",
      "finished training epoch 1619\n",
      "train_loss:  1.2180279372801448e-05 train_R2 0.9011551223332941\n",
      "finished training epoch 1620\n",
      "train_loss:  1.244157728970866e-05 train_R2 0.9127303889656782\n",
      "finished training epoch 1621\n",
      "train_loss:  1.2534241581828637e-05 train_R2 0.8851549802972711\n",
      "finished training epoch 1622\n",
      "train_loss:  1.2240014975812895e-05 train_R2 0.9021201689706845\n",
      "finished training epoch 1623\n",
      "train_loss:  1.196209949409075e-05 train_R2 0.8616142579643987\n",
      "finished training epoch 1624\n",
      "train_loss:  1.2048100268797363e-05 train_R2 0.9122154912069212\n",
      "finished training epoch 1625\n",
      "train_loss:  1.2053367369752679e-05 train_R2 0.9041748634272707\n",
      "finished training epoch 1626\n",
      "train_loss:  1.227954015229826e-05 train_R2 0.8798870915822963\n",
      "finished training epoch 1627\n",
      "train_loss:  1.1798364353957114e-05 train_R2 0.9169390466381293\n",
      "finished training epoch 1628\n",
      "train_loss:  1.1999982444322521e-05 train_R2 0.8898104143605244\n",
      "finished training epoch 1629\n",
      "train_loss:  1.1951129847839198e-05 train_R2 0.9244443757371776\n",
      "finished training epoch 1630\n",
      "train_loss:  1.1768057362490824e-05 train_R2 0.8950113049970233\n",
      "finished training epoch 1631\n",
      "train_loss:  1.1740987864755898e-05 train_R2 0.8840161706432691\n",
      "finished training epoch 1632\n",
      "train_loss:  1.1826401924766662e-05 train_R2 0.8942273854862287\n",
      "finished training epoch 1633\n",
      "train_loss:  1.1740091443543665e-05 train_R2 0.912629311851606\n",
      "finished training epoch 1634\n",
      "train_loss:  1.1808239570293785e-05 train_R2 0.9033049939695137\n",
      "finished training epoch 1635\n",
      "train_loss:  1.1885035349747003e-05 train_R2 0.8420567757295129\n",
      "finished training epoch 1636\n",
      "train_loss:  1.1893986945748422e-05 train_R2 0.8637423223651222\n",
      "finished training epoch 1637\n",
      "train_loss:  1.1752824340374545e-05 train_R2 0.9162012010206785\n",
      "finished training epoch 1638\n",
      "train_loss:  1.217760923940138e-05 train_R2 0.9028837568366556\n",
      "finished training epoch 1639\n",
      "train_loss:  1.1912899958097262e-05 train_R2 0.8966188079808654\n",
      "finished training epoch 1640\n",
      "train_loss:  1.1823755974096108e-05 train_R2 0.9003473218437846\n",
      "finished training epoch 1641\n",
      "train_loss:  1.1930325332041694e-05 train_R2 0.8635346508940206\n",
      "finished training epoch 1642\n",
      "train_loss:  1.1886641472526137e-05 train_R2 0.9339180146584092\n",
      "finished training epoch 1643\n",
      "train_loss:  1.1837611732362362e-05 train_R2 0.8928433119100092\n",
      "finished training epoch 1644\n",
      "train_loss:  1.1825281494827735e-05 train_R2 0.9303928405298401\n",
      "finished training epoch 1645\n",
      "train_loss:  1.1934381132874333e-05 train_R2 0.8984033909657809\n",
      "finished training epoch 1646\n",
      "train_loss:  1.2009865023915734e-05 train_R2 0.9075650470852835\n",
      "finished training epoch 1647\n",
      "train_loss:  1.171565567687542e-05 train_R2 0.9132371228635368\n",
      "finished training epoch 1648\n",
      "train_loss:  1.1729254129475585e-05 train_R2 0.9031171876338216\n",
      "finished training epoch 1649\n",
      "train_loss:  1.1805366476615081e-05 train_R2 0.8727842823384039\n",
      "finished training epoch 1650\n",
      "train_loss:  1.1950852669163853e-05 train_R2 0.8479502769454736\n",
      "finished training epoch 1651\n",
      "train_loss:  1.1971932146323143e-05 train_R2 0.8948744888787739\n",
      "finished training epoch 1652\n",
      "train_loss:  1.1804443402779185e-05 train_R2 0.835927062019467\n",
      "finished training epoch 1653\n",
      "train_loss:  1.1712905631020416e-05 train_R2 0.8577478338299152\n",
      "finished training epoch 1654\n",
      "train_loss:  1.159692334984496e-05 train_R2 0.9042104966452507\n",
      "finished training epoch 1655\n",
      "train_loss:  1.1848258560610985e-05 train_R2 0.9047713810059491\n",
      "finished training epoch 1656\n",
      "train_loss:  1.213479596276331e-05 train_R2 0.8878117819585861\n",
      "finished training epoch 1657\n",
      "train_loss:  1.1774282356000291e-05 train_R2 0.8909330969469925\n",
      "finished training epoch 1658\n",
      "train_loss:  1.1586134153304487e-05 train_R2 0.9259363825797107\n",
      "finished training epoch 1659\n",
      "train_loss:  1.2076603827363537e-05 train_R2 0.8960465867777945\n",
      "finished training epoch 1660\n",
      "train_loss:  1.2201203936121566e-05 train_R2 0.8814664414519071\n",
      "finished training epoch 1661\n",
      "train_loss:  1.1905929058998552e-05 train_R2 0.9321024296023825\n",
      "finished training epoch 1662\n",
      "train_loss:  1.2063816262085038e-05 train_R2 0.8774137075469437\n",
      "finished training epoch 1663\n",
      "train_loss:  1.2076051104971513e-05 train_R2 0.9012455032632509\n",
      "finished training epoch 1664\n",
      "train_loss:  1.201156091362726e-05 train_R2 0.855794636024224\n",
      "finished training epoch 1665\n",
      "train_loss:  1.179033307068233e-05 train_R2 0.8831416349427224\n",
      "finished training epoch 1666\n",
      "train_loss:  1.1849438560481236e-05 train_R2 0.8719893851591134\n",
      "finished training epoch 1667\n",
      "train_loss:  1.1517018056111614e-05 train_R2 0.9208546257964212\n",
      "finished training epoch 1668\n",
      "train_loss:  1.1841923095139964e-05 train_R2 0.9114319103750603\n",
      "finished training epoch 1669\n",
      "train_loss:  1.1980311570647216e-05 train_R2 0.8726841187770117\n",
      "finished training epoch 1670\n",
      "train_loss:  1.1967811742684415e-05 train_R2 0.9140547968471147\n",
      "finished training epoch 1671\n",
      "train_loss:  1.2057224680708913e-05 train_R2 0.9092090236266551\n",
      "finished training epoch 1672\n",
      "train_loss:  1.201727528379986e-05 train_R2 0.8975418242924466\n",
      "finished training epoch 1673\n",
      "train_loss:  1.1955099280544292e-05 train_R2 0.8460862546554871\n",
      "finished training epoch 1674\n",
      "train_loss:  1.2022541653902155e-05 train_R2 0.8528734813339307\n",
      "finished training epoch 1675\n",
      "train_loss:  1.1661853786359817e-05 train_R2 0.9060139986296334\n",
      "finished training epoch 1676\n",
      "train_loss:  1.194270237665003e-05 train_R2 0.8852013438887241\n",
      "finished training epoch 1677\n",
      "train_loss:  1.2098303558378095e-05 train_R2 0.8924483853625568\n",
      "finished training epoch 1678\n",
      "train_loss:  1.2119615737605385e-05 train_R2 0.8843081585363817\n",
      "finished training epoch 1679\n",
      "train_loss:  1.1889581613193026e-05 train_R2 0.86307287721273\n",
      "finished training epoch 1680\n",
      "train_loss:  1.1907589500266465e-05 train_R2 0.8920121300326765\n",
      "finished training epoch 1681\n",
      "train_loss:  1.179373347818241e-05 train_R2 0.939886415721323\n",
      "finished training epoch 1682\n",
      "train_loss:  1.1727952397767379e-05 train_R2 0.9169271831226458\n",
      "finished training epoch 1683\n",
      "train_loss:  1.2071935956114834e-05 train_R2 0.8999822207396291\n",
      "finished training epoch 1684\n",
      "train_loss:  1.2501695584514457e-05 train_R2 0.8781699404595212\n",
      "finished training epoch 1685\n",
      "train_loss:  1.2168713457078673e-05 train_R2 0.8977891739279\n",
      "finished training epoch 1686\n",
      "train_loss:  1.191129237156975e-05 train_R2 0.9326084171505408\n",
      "finished training epoch 1687\n",
      "train_loss:  1.1895293885099442e-05 train_R2 0.8978224512013991\n",
      "finished training epoch 1688\n",
      "train_loss:  1.1681555312469367e-05 train_R2 0.8893481431725323\n",
      "finished training epoch 1689\n",
      "train_loss:  1.1953560621508218e-05 train_R2 0.8437995930839913\n",
      "finished training epoch 1690\n",
      "train_loss:  1.2122173488898988e-05 train_R2 0.8840661935936598\n",
      "finished training epoch 1691\n",
      "train_loss:  1.2031742141044843e-05 train_R2 0.8683907140985336\n",
      "finished training epoch 1692\n",
      "train_loss:  1.1752387265999693e-05 train_R2 0.8753547063301867\n",
      "finished training epoch 1693\n",
      "train_loss:  1.1871952685874366e-05 train_R2 0.8678615272699151\n",
      "finished training epoch 1694\n",
      "train_loss:  1.2106028528478574e-05 train_R2 0.9232263922777484\n",
      "finished training epoch 1695\n",
      "train_loss:  1.2002643162295257e-05 train_R2 0.8996436622806867\n",
      "finished training epoch 1696\n",
      "train_loss:  1.197124840468733e-05 train_R2 0.8686228158496855\n",
      "finished training epoch 1697\n",
      "train_loss:  1.1629166072816948e-05 train_R2 0.8303965043010434\n",
      "finished training epoch 1698\n",
      "train_loss:  1.1810590359342892e-05 train_R2 0.8839909395140002\n",
      "finished training epoch 1699\n",
      "train_loss:  1.1455512623004627e-05 train_R2 0.9156847786507512\n",
      "finished training epoch 1700\n",
      "train_loss:  1.1864916285329487e-05 train_R2 0.8861356288176767\n",
      "finished training epoch 1701\n",
      "train_loss:  1.180000552647202e-05 train_R2 0.9197145193805353\n",
      "finished training epoch 1702\n",
      "train_loss:  1.1798525766529697e-05 train_R2 0.8895848139548209\n",
      "finished training epoch 1703\n",
      "train_loss:  1.1681447992712285e-05 train_R2 0.9259507211258176\n",
      "finished training epoch 1704\n",
      "train_loss:  1.1481390435669603e-05 train_R2 0.8725179625731834\n",
      "finished training epoch 1705\n",
      "train_loss:  1.190463426608131e-05 train_R2 0.8989552805147841\n",
      "finished training epoch 1706\n",
      "train_loss:  1.2010101869701483e-05 train_R2 0.923353436725932\n",
      "finished training epoch 1707\n",
      "train_loss:  1.1904750554607563e-05 train_R2 0.8701302696614971\n",
      "finished training epoch 1708\n",
      "train_loss:  1.1664674952540953e-05 train_R2 0.9055414191258692\n",
      "finished training epoch 1709\n",
      "train_loss:  1.1726998604571903e-05 train_R2 0.8547079537187756\n",
      "finished training epoch 1710\n",
      "train_loss:  1.1835961741443819e-05 train_R2 0.887426179718356\n",
      "finished training epoch 1711\n",
      "train_loss:  1.2113391859757141e-05 train_R2 0.8808669258804144\n",
      "finished training epoch 1712\n",
      "train_loss:  1.1978445346504931e-05 train_R2 0.8943068706196431\n",
      "finished training epoch 1713\n",
      "train_loss:  1.1766889378977029e-05 train_R2 0.9107624402422821\n",
      "finished training epoch 1714\n",
      "train_loss:  1.1884654644225705e-05 train_R2 0.8359895834275548\n",
      "finished training epoch 1715\n",
      "train_loss:  1.1588121321453345e-05 train_R2 0.9058333810830939\n",
      "finished training epoch 1716\n",
      "train_loss:  1.1705358266049159e-05 train_R2 0.850942101227886\n",
      "finished training epoch 1717\n",
      "train_loss:  1.1750870673695596e-05 train_R2 0.9088131372335769\n",
      "finished training epoch 1718\n",
      "train_loss:  1.2168682751755051e-05 train_R2 0.8683577262865867\n",
      "finished training epoch 1719\n",
      "train_loss:  1.2133527054786896e-05 train_R2 0.9021909176293111\n",
      "finished training epoch 1720\n",
      "train_loss:  1.1878159190447615e-05 train_R2 0.8699169972530391\n",
      "finished training epoch 1721\n",
      "train_loss:  1.154608191689118e-05 train_R2 0.8444138109836277\n",
      "finished training epoch 1722\n",
      "train_loss:  1.1765807581807837e-05 train_R2 0.8754375544003694\n",
      "finished training epoch 1723\n",
      "train_loss:  1.163311268162054e-05 train_R2 0.8686029357371735\n",
      "finished training epoch 1724\n",
      "train_loss:  1.1829214384877787e-05 train_R2 0.8946638834381115\n",
      "finished training epoch 1725\n",
      "train_loss:  1.2081644509424283e-05 train_R2 0.8963574734580573\n",
      "finished training epoch 1726\n",
      "train_loss:  1.2032829136099647e-05 train_R2 0.8996738366993211\n",
      "finished training epoch 1727\n",
      "train_loss:  1.185058419723944e-05 train_R2 0.8939614224473826\n",
      "finished training epoch 1728\n",
      "train_loss:  1.1889174905913858e-05 train_R2 0.8953348610839231\n",
      "finished training epoch 1729\n",
      "train_loss:  1.1707110198769067e-05 train_R2 0.903130686652739\n",
      "finished training epoch 1730\n",
      "train_loss:  1.17119590853169e-05 train_R2 0.860092036387202\n",
      "finished training epoch 1731\n",
      "train_loss:  1.1722431509404726e-05 train_R2 0.8928777748799543\n",
      "finished training epoch 1732\n",
      "train_loss:  1.1907612205466514e-05 train_R2 0.9044640634029127\n",
      "finished training epoch 1733\n",
      "train_loss:  1.1605963038648425e-05 train_R2 0.8883460784667412\n",
      "finished training epoch 1734\n",
      "train_loss:  1.1911476828650944e-05 train_R2 0.9194138627635998\n",
      "finished training epoch 1735\n",
      "train_loss:  1.1817781915474255e-05 train_R2 0.8863878919178779\n",
      "finished training epoch 1736\n",
      "train_loss:  1.1588694035764926e-05 train_R2 0.8922442891209739\n",
      "finished training epoch 1737\n",
      "train_loss:  1.1875920921637357e-05 train_R2 0.8899741845767737\n",
      "finished training epoch 1738\n",
      "train_loss:  1.189435358256999e-05 train_R2 0.9018453306290501\n",
      "finished training epoch 1739\n",
      "train_loss:  1.184734921220474e-05 train_R2 0.8442150886963748\n",
      "finished training epoch 1740\n",
      "train_loss:  1.185626020266747e-05 train_R2 0.8723307104637242\n",
      "finished training epoch 1741\n",
      "train_loss:  1.1667666259827426e-05 train_R2 0.9035088425924183\n",
      "finished training epoch 1742\n",
      "train_loss:  1.1806523008469397e-05 train_R2 0.8746591362259375\n",
      "finished training epoch 1743\n",
      "train_loss:  1.2117920054016712e-05 train_R2 0.8922666301548855\n",
      "finished training epoch 1744\n",
      "train_loss:  1.1831402171318369e-05 train_R2 0.8857790146440268\n",
      "finished training epoch 1745\n",
      "train_loss:  1.1682309451024773e-05 train_R2 0.8459600753938409\n",
      "finished training epoch 1746\n",
      "train_loss:  1.1928589646800714e-05 train_R2 0.9117339851974748\n",
      "finished training epoch 1747\n",
      "train_loss:  1.1939669022090106e-05 train_R2 0.8753526091566647\n",
      "finished training epoch 1748\n",
      "train_loss:  1.199528152504598e-05 train_R2 0.9127133994028789\n",
      "finished training epoch 1749\n",
      "train_loss:  1.153832339250732e-05 train_R2 0.9167700053998478\n",
      "finished training epoch 1750\n",
      "train_loss:  1.1654959140530408e-05 train_R2 0.8850140264166807\n",
      "finished training epoch 1751\n",
      "train_loss:  1.1709175539875822e-05 train_R2 0.9019706604585926\n",
      "finished training epoch 1752\n",
      "train_loss:  1.1797291578485298e-05 train_R2 0.8868324649554825\n",
      "finished training epoch 1753\n",
      "train_loss:  1.1751106883230067e-05 train_R2 0.8911846627680919\n",
      "finished training epoch 1754\n",
      "train_loss:  1.1880526474678868e-05 train_R2 0.9091646945339819\n",
      "finished training epoch 1755\n",
      "train_loss:  1.1851035317680531e-05 train_R2 0.9106348809458935\n",
      "finished training epoch 1756\n",
      "train_loss:  1.2086337948861138e-05 train_R2 0.8510175832944191\n",
      "finished training epoch 1757\n",
      "train_loss:  1.2264704238614106e-05 train_R2 0.8776510094754051\n",
      "finished training epoch 1758\n",
      "train_loss:  1.2106515664082023e-05 train_R2 0.8868062877974681\n",
      "finished training epoch 1759\n",
      "train_loss:  1.2256831251556606e-05 train_R2 0.8706373880364987\n",
      "finished training epoch 1760\n",
      "train_loss:  1.1719724449180115e-05 train_R2 0.9078438588896602\n",
      "finished training epoch 1761\n",
      "train_loss:  1.1723535067243015e-05 train_R2 0.926887924347024\n",
      "finished training epoch 1762\n",
      "train_loss:  1.178245519355798e-05 train_R2 0.928361716692675\n",
      "finished training epoch 1763\n",
      "train_loss:  1.2182426643027159e-05 train_R2 0.8729281190972558\n",
      "finished training epoch 1764\n",
      "train_loss:  1.1937767414666046e-05 train_R2 0.9322280930782108\n",
      "finished training epoch 1765\n",
      "train_loss:  1.1943124484074557e-05 train_R2 0.8907793808841483\n",
      "finished training epoch 1766\n",
      "train_loss:  1.150781478346383e-05 train_R2 0.9379441916508675\n",
      "finished training epoch 1767\n",
      "train_loss:  1.147991227592113e-05 train_R2 0.8868531668941552\n",
      "finished training epoch 1768\n",
      "train_loss:  1.181611556864697e-05 train_R2 0.8746865240981181\n",
      "finished training epoch 1769\n",
      "train_loss:  1.1671300757619798e-05 train_R2 0.9216879777886479\n",
      "finished training epoch 1770\n",
      "train_loss:  1.1911829339483036e-05 train_R2 0.8538905154611249\n",
      "finished training epoch 1771\n",
      "train_loss:  1.1903374423795297e-05 train_R2 0.8852539163170957\n",
      "finished training epoch 1772\n",
      "train_loss:  1.1620747158417058e-05 train_R2 0.879505078175898\n",
      "finished training epoch 1773\n",
      "train_loss:  1.1861079946850054e-05 train_R2 0.9087342570172039\n",
      "finished training epoch 1774\n",
      "train_loss:  1.1806531055111236e-05 train_R2 0.9242228646074669\n",
      "finished training epoch 1775\n",
      "train_loss:  1.1746640865046166e-05 train_R2 0.8121869109364973\n",
      "finished training epoch 1776\n",
      "train_loss:  1.2151150423268545e-05 train_R2 0.884384204165894\n",
      "finished training epoch 1777\n",
      "train_loss:  1.1910547386508826e-05 train_R2 0.852976138671889\n",
      "finished training epoch 1778\n",
      "train_loss:  1.1799617020355002e-05 train_R2 0.9015230301510668\n",
      "finished training epoch 1779\n",
      "train_loss:  1.1640401951913535e-05 train_R2 0.885139231097535\n",
      "finished training epoch 1780\n",
      "train_loss:  1.1862972368626768e-05 train_R2 0.8703237800144792\n",
      "finished training epoch 1781\n",
      "train_loss:  1.194415675597634e-05 train_R2 0.8767322059408102\n",
      "finished training epoch 1782\n",
      "train_loss:  1.1580974121016841e-05 train_R2 0.8901085504032784\n",
      "finished training epoch 1783\n",
      "train_loss:  1.1393202170186348e-05 train_R2 0.8971997954454276\n",
      "finished training epoch 1784\n",
      "train_loss:  1.1777665646741654e-05 train_R2 0.8821210085877282\n",
      "finished training epoch 1785\n",
      "train_loss:  1.154647938021701e-05 train_R2 0.8931176658233242\n",
      "finished training epoch 1786\n",
      "train_loss:  1.2046167646824169e-05 train_R2 0.9109918973804362\n",
      "finished training epoch 1787\n",
      "train_loss:  1.177746886322947e-05 train_R2 0.9147413715828481\n",
      "finished training epoch 1788\n",
      "train_loss:  1.1829561724659139e-05 train_R2 0.9115014888944792\n",
      "finished training epoch 1789\n",
      "train_loss:  1.1754390776694093e-05 train_R2 0.8723956366073347\n",
      "finished training epoch 1790\n",
      "train_loss:  1.1744722673404933e-05 train_R2 0.8963727145488671\n",
      "finished training epoch 1791\n",
      "train_loss:  1.167535673329515e-05 train_R2 0.8915708224547981\n",
      "finished training epoch 1792\n",
      "train_loss:  1.1717435866361792e-05 train_R2 0.913395109496108\n",
      "finished training epoch 1793\n",
      "train_loss:  1.1828325756662883e-05 train_R2 0.9138527044254252\n",
      "finished training epoch 1794\n",
      "train_loss:  1.2035788455571334e-05 train_R2 0.8817224860920274\n",
      "finished training epoch 1795\n",
      "train_loss:  1.1939637821478676e-05 train_R2 0.9210435706827085\n",
      "finished training epoch 1796\n",
      "train_loss:  1.1499059460867726e-05 train_R2 0.9294829684281583\n",
      "finished training epoch 1797\n",
      "train_loss:  1.1587755561338134e-05 train_R2 0.9227136195225842\n",
      "finished training epoch 1798\n",
      "train_loss:  1.1760060786008936e-05 train_R2 0.9156586508513419\n",
      "finished training epoch 1799\n",
      "train_loss:  1.2164257276755492e-05 train_R2 0.875112005054947\n",
      "finished training epoch 1800\n",
      "train_loss:  1.2076356461812302e-05 train_R2 0.9253093088661744\n",
      "finished training epoch 1801\n",
      "train_loss:  1.1813953427313682e-05 train_R2 0.9159312053489097\n",
      "finished training epoch 1802\n",
      "train_loss:  1.1699965978534376e-05 train_R2 0.8540895481450248\n",
      "finished training epoch 1803\n",
      "train_loss:  1.1654155489607962e-05 train_R2 0.8788942044603147\n",
      "finished training epoch 1804\n",
      "train_loss:  1.1815016668604695e-05 train_R2 0.8835042417647014\n",
      "finished training epoch 1805\n",
      "train_loss:  1.1419075774936453e-05 train_R2 0.8595531921968711\n",
      "finished training epoch 1806\n",
      "train_loss:  1.1643199627670484e-05 train_R2 0.9239154768756057\n",
      "finished training epoch 1807\n",
      "train_loss:  1.1494875421425719e-05 train_R2 0.892913843603865\n",
      "finished training epoch 1808\n",
      "train_loss:  1.1775017529898318e-05 train_R2 0.8741461974717307\n",
      "finished training epoch 1809\n",
      "train_loss:  1.1521351656455393e-05 train_R2 0.8961382258703203\n",
      "finished training epoch 1810\n",
      "train_loss:  1.1605176932742512e-05 train_R2 0.9119809503987173\n",
      "finished training epoch 1811\n",
      "train_loss:  1.1732201374517805e-05 train_R2 0.9267596563526582\n",
      "finished training epoch 1812\n",
      "train_loss:  1.1594830248124365e-05 train_R2 0.8756267982080984\n",
      "finished training epoch 1813\n",
      "train_loss:  1.1604051146720175e-05 train_R2 0.8897380358358734\n",
      "finished training epoch 1814\n",
      "train_loss:  1.1729860575730623e-05 train_R2 0.8549961461092163\n",
      "finished training epoch 1815\n",
      "train_loss:  1.1448813647610456e-05 train_R2 0.8838347866120374\n",
      "finished training epoch 1816\n",
      "train_loss:  1.1656933777622721e-05 train_R2 0.860289238504776\n",
      "finished training epoch 1817\n",
      "train_loss:  1.1413935401065659e-05 train_R2 0.8963855290245416\n",
      "finished training epoch 1818\n",
      "train_loss:  1.149018142716862e-05 train_R2 0.9047959926951489\n",
      "finished training epoch 1819\n",
      "train_loss:  1.1759186406654225e-05 train_R2 0.8722994247214342\n",
      "finished training epoch 1820\n",
      "train_loss:  1.1566923894537027e-05 train_R2 0.9276801514194044\n",
      "finished training epoch 1821\n",
      "train_loss:  1.1634625540331494e-05 train_R2 0.8861942528907916\n",
      "finished training epoch 1822\n",
      "train_loss:  1.164856347297599e-05 train_R2 0.8685494338434799\n",
      "finished training epoch 1823\n",
      "train_loss:  1.150760640064875e-05 train_R2 0.9138516802683078\n",
      "finished training epoch 1824\n",
      "train_loss:  1.162332766233243e-05 train_R2 0.9153197591826872\n",
      "finished training epoch 1825\n",
      "train_loss:  1.1475450662102333e-05 train_R2 0.8708621473943943\n",
      "finished training epoch 1826\n",
      "train_loss:  1.1699219114548884e-05 train_R2 0.9093590965966828\n",
      "finished training epoch 1827\n",
      "train_loss:  1.1680159884318392e-05 train_R2 0.8784180971259214\n",
      "finished training epoch 1828\n",
      "train_loss:  1.1558210508250302e-05 train_R2 0.8779318136358368\n",
      "finished training epoch 1829\n",
      "train_loss:  1.1449217279456244e-05 train_R2 0.8869392474664387\n",
      "finished training epoch 1830\n",
      "train_loss:  1.1746459566813336e-05 train_R2 0.9199793985380487\n",
      "finished training epoch 1831\n",
      "train_loss:  1.1693645180255564e-05 train_R2 0.8918777993508997\n",
      "finished training epoch 1832\n",
      "train_loss:  1.1662465627709813e-05 train_R2 0.8966473110423865\n",
      "finished training epoch 1833\n",
      "train_loss:  1.15083715450517e-05 train_R2 0.8676122662696812\n",
      "finished training epoch 1834\n",
      "train_loss:  1.1514986360713643e-05 train_R2 0.870737582479117\n",
      "finished training epoch 1835\n",
      "train_loss:  1.1739961062026037e-05 train_R2 0.8960517576638696\n",
      "finished training epoch 1836\n",
      "train_loss:  1.1620267107604173e-05 train_R2 0.8661262872202342\n",
      "finished training epoch 1837\n",
      "train_loss:  1.1468424765334277e-05 train_R2 0.9100542826032146\n",
      "finished training epoch 1838\n",
      "train_loss:  1.1713496577941945e-05 train_R2 0.8703013673563083\n",
      "finished training epoch 1839\n",
      "train_loss:  1.1596594658387379e-05 train_R2 0.8808012732680714\n",
      "finished training epoch 1840\n",
      "train_loss:  1.1482108656849922e-05 train_R2 0.8989844862109226\n",
      "finished training epoch 1841\n",
      "train_loss:  1.142718782015255e-05 train_R2 0.912477090692589\n",
      "finished training epoch 1842\n",
      "train_loss:  1.1558005194402402e-05 train_R2 0.9189319941808803\n",
      "finished training epoch 1843\n",
      "train_loss:  1.160690755927565e-05 train_R2 0.8645745906180137\n",
      "finished training epoch 1844\n",
      "train_loss:  1.1877421665209265e-05 train_R2 0.8966050657298305\n",
      "finished training epoch 1845\n",
      "train_loss:  1.142523208531319e-05 train_R2 0.8997397589502267\n",
      "finished training epoch 1846\n",
      "train_loss:  1.1640850728672662e-05 train_R2 0.9056283185119398\n",
      "finished training epoch 1847\n",
      "train_loss:  1.1828190550778235e-05 train_R2 0.890874092155205\n",
      "finished training epoch 1848\n",
      "train_loss:  1.1840983269855062e-05 train_R2 0.8778678871626804\n",
      "finished training epoch 1849\n",
      "train_loss:  1.1701393681064079e-05 train_R2 0.8873872896404481\n",
      "finished training epoch 1850\n",
      "train_loss:  1.1613266122465595e-05 train_R2 0.9157969388814158\n",
      "finished training epoch 1851\n",
      "train_loss:  1.1487670658797898e-05 train_R2 0.8624367626940185\n",
      "finished training epoch 1852\n",
      "train_loss:  1.1749850049625188e-05 train_R2 0.8391790900448728\n",
      "finished training epoch 1853\n",
      "train_loss:  1.1368448646774193e-05 train_R2 0.867811352036624\n",
      "finished training epoch 1854\n",
      "train_loss:  1.1591698271751613e-05 train_R2 0.8976452092490803\n",
      "finished training epoch 1855\n",
      "train_loss:  1.1700518791581183e-05 train_R2 0.8815906161756635\n",
      "finished training epoch 1856\n",
      "train_loss:  1.1705458599686005e-05 train_R2 0.8902724521450214\n",
      "finished training epoch 1857\n",
      "train_loss:  1.1632200458923735e-05 train_R2 0.9302726016317272\n",
      "finished training epoch 1858\n",
      "train_loss:  1.172117594262133e-05 train_R2 0.9100012467294449\n",
      "finished training epoch 1859\n",
      "train_loss:  1.1551959162229813e-05 train_R2 0.8627271533089109\n",
      "finished training epoch 1860\n",
      "train_loss:  1.1745940076045324e-05 train_R2 0.9198379857776694\n",
      "finished training epoch 1861\n",
      "train_loss:  1.158041576943891e-05 train_R2 0.9241738404546709\n",
      "finished training epoch 1862\n",
      "train_loss:  1.1395092550223124e-05 train_R2 0.9214722256878581\n",
      "finished training epoch 1863\n",
      "train_loss:  1.1493150991297507e-05 train_R2 0.8523827235380903\n",
      "finished training epoch 1864\n",
      "train_loss:  1.1534352016412964e-05 train_R2 0.9040696954240087\n",
      "finished training epoch 1865\n",
      "train_loss:  1.1619418699287291e-05 train_R2 0.8893492406445088\n",
      "finished training epoch 1866\n",
      "train_loss:  1.1706982332738925e-05 train_R2 0.9065374676039453\n",
      "finished training epoch 1867\n",
      "train_loss:  1.1721901863787963e-05 train_R2 0.8810523362697751\n",
      "finished training epoch 1868\n",
      "train_loss:  1.1646245470388728e-05 train_R2 0.8823272091114656\n",
      "finished training epoch 1869\n",
      "train_loss:  1.1451825111860387e-05 train_R2 0.9045796713369623\n",
      "finished training epoch 1870\n",
      "train_loss:  1.1515580711922428e-05 train_R2 0.8754292961293151\n",
      "finished training epoch 1871\n",
      "train_loss:  1.1574393309381755e-05 train_R2 0.9229810174018078\n",
      "finished training epoch 1872\n",
      "train_loss:  1.1376987802277086e-05 train_R2 0.9354157376609393\n",
      "finished training epoch 1873\n",
      "train_loss:  1.1633317629668144e-05 train_R2 0.88198696639318\n",
      "finished training epoch 1874\n",
      "train_loss:  1.1672808907417377e-05 train_R2 0.9228973311820842\n",
      "finished training epoch 1875\n",
      "train_loss:  1.1599718298511323e-05 train_R2 0.8509375510712658\n",
      "finished training epoch 1876\n",
      "train_loss:  1.1376997148683838e-05 train_R2 0.8762282327243393\n",
      "finished training epoch 1877\n",
      "train_loss:  1.1402498568507429e-05 train_R2 0.9325305563844242\n",
      "finished training epoch 1878\n",
      "train_loss:  1.1542322457270455e-05 train_R2 0.890395804066806\n",
      "finished training epoch 1879\n",
      "train_loss:  1.1572772084254303e-05 train_R2 0.89917564749638\n",
      "finished training epoch 1880\n",
      "train_loss:  1.1425546758336941e-05 train_R2 0.8798461715041963\n",
      "finished training epoch 1881\n",
      "train_loss:  1.1482280005800326e-05 train_R2 0.9004323456910717\n",
      "finished training epoch 1882\n",
      "train_loss:  1.1547669213376042e-05 train_R2 0.892476982888099\n",
      "finished training epoch 1883\n",
      "train_loss:  1.177883294522591e-05 train_R2 0.90242685924935\n",
      "finished training epoch 1884\n",
      "train_loss:  1.1499989669576245e-05 train_R2 0.9035224672695622\n",
      "finished training epoch 1885\n",
      "train_loss:  1.1600032412103577e-05 train_R2 0.826617120033857\n",
      "finished training epoch 1886\n",
      "train_loss:  1.1230725579162482e-05 train_R2 0.9256240204874646\n",
      "finished training epoch 1887\n",
      "train_loss:  1.1486858134782927e-05 train_R2 0.9196617127131377\n",
      "finished training epoch 1888\n",
      "train_loss:  1.1713570553415146e-05 train_R2 0.8414288287684957\n",
      "finished training epoch 1889\n",
      "train_loss:  1.1439950179063543e-05 train_R2 0.8722881998902206\n",
      "finished training epoch 1890\n",
      "train_loss:  1.1540859617372672e-05 train_R2 0.8967594702231576\n",
      "finished training epoch 1891\n",
      "train_loss:  1.169316250348477e-05 train_R2 0.8363517879057136\n",
      "finished training epoch 1892\n",
      "train_loss:  1.1604760576023897e-05 train_R2 0.9209048110437097\n",
      "finished training epoch 1893\n",
      "train_loss:  1.1431737658633181e-05 train_R2 0.9067083605764041\n",
      "finished training epoch 1894\n",
      "train_loss:  1.1752592941046447e-05 train_R2 0.9019058362780007\n",
      "finished training epoch 1895\n",
      "train_loss:  1.1750535294177942e-05 train_R2 0.8792328192454996\n",
      "finished training epoch 1896\n",
      "train_loss:  1.1714751532937041e-05 train_R2 0.880313263442731\n",
      "finished training epoch 1897\n",
      "train_loss:  1.1708268791365896e-05 train_R2 0.8450767234210537\n",
      "finished training epoch 1898\n",
      "train_loss:  1.1721414881746332e-05 train_R2 0.8809596820222529\n",
      "finished training epoch 1899\n",
      "train_loss:  1.1444692558391175e-05 train_R2 0.9039609242403439\n",
      "finished training epoch 1900\n",
      "train_loss:  1.1626590758940066e-05 train_R2 0.8789087289823876\n",
      "finished training epoch 1901\n",
      "train_loss:  1.1533269064212379e-05 train_R2 0.808610616905693\n",
      "finished training epoch 1902\n",
      "train_loss:  1.1398566276676865e-05 train_R2 0.8995533016407602\n",
      "finished training epoch 1903\n",
      "train_loss:  1.1440344199031103e-05 train_R2 0.9082980812159802\n",
      "finished training epoch 1904\n",
      "train_loss:  1.1874646100877218e-05 train_R2 0.9155820364316511\n",
      "finished training epoch 1905\n",
      "train_loss:  1.1691458155749845e-05 train_R2 0.8928566322137129\n",
      "finished training epoch 1906\n",
      "train_loss:  1.1479851757251837e-05 train_R2 0.885398900081143\n",
      "finished training epoch 1907\n",
      "train_loss:  1.1631071539859361e-05 train_R2 0.8890758762416681\n",
      "finished training epoch 1908\n",
      "train_loss:  1.1635597981795358e-05 train_R2 0.8254238905609114\n",
      "finished training epoch 1909\n",
      "train_loss:  1.159767715510544e-05 train_R2 0.8670866357991993\n",
      "finished training epoch 1910\n",
      "train_loss:  1.1509083451950792e-05 train_R2 0.9232267040087027\n",
      "finished training epoch 1911\n",
      "train_loss:  1.1633926545997558e-05 train_R2 0.9018279243905396\n",
      "finished training epoch 1912\n",
      "train_loss:  1.1573309728094901e-05 train_R2 0.8792693369625756\n",
      "finished training epoch 1913\n",
      "train_loss:  1.1697816521538117e-05 train_R2 0.9068445646597005\n",
      "finished training epoch 1914\n",
      "train_loss:  1.1468502498911221e-05 train_R2 0.9193317612689604\n",
      "finished training epoch 1915\n",
      "train_loss:  1.1250748247689734e-05 train_R2 0.907878068267817\n",
      "finished training epoch 1916\n",
      "train_loss:  1.1515111004741243e-05 train_R2 0.9175244332609652\n",
      "finished training epoch 1917\n",
      "train_loss:  1.1615625366820402e-05 train_R2 0.9075520307510654\n",
      "finished training epoch 1918\n",
      "train_loss:  1.1753682074214951e-05 train_R2 0.8524681594407223\n",
      "finished training epoch 1919\n",
      "train_loss:  1.2117649534657508e-05 train_R2 0.8914862189198259\n",
      "finished training epoch 1920\n",
      "train_loss:  1.1396030195076197e-05 train_R2 0.9134167006420474\n",
      "finished training epoch 1921\n",
      "train_loss:  1.158796852640508e-05 train_R2 0.8933883003157365\n",
      "finished training epoch 1922\n",
      "train_loss:  1.146976233121425e-05 train_R2 0.8571883779111074\n",
      "finished training epoch 1923\n",
      "train_loss:  1.1889041375782948e-05 train_R2 0.8496514310157793\n",
      "finished training epoch 1924\n",
      "train_loss:  1.1481351245533124e-05 train_R2 0.8861266817975116\n",
      "finished training epoch 1925\n",
      "train_loss:  1.1613202499715667e-05 train_R2 0.9042421030430011\n",
      "finished training epoch 1926\n",
      "train_loss:  1.1570152034418362e-05 train_R2 0.9187736208689636\n",
      "finished training epoch 1927\n",
      "train_loss:  1.1555989020336405e-05 train_R2 0.8752965365814347\n",
      "finished training epoch 1928\n",
      "train_loss:  1.1451600474814221e-05 train_R2 0.91063778372568\n",
      "finished training epoch 1929\n",
      "train_loss:  1.1548493602239974e-05 train_R2 0.9028973793218217\n",
      "finished training epoch 1930\n",
      "train_loss:  1.134418287895922e-05 train_R2 0.9267263095125136\n",
      "finished training epoch 1931\n",
      "train_loss:  1.138984850467361e-05 train_R2 0.9050368481895442\n",
      "finished training epoch 1932\n",
      "train_loss:  1.1262251295076854e-05 train_R2 0.9154758115771141\n",
      "finished training epoch 1933\n",
      "train_loss:  1.1739025218219095e-05 train_R2 0.897990434854022\n",
      "finished training epoch 1934\n",
      "train_loss:  1.1536847068555975e-05 train_R2 0.8936562688724476\n",
      "finished training epoch 1935\n",
      "train_loss:  1.1580181172475003e-05 train_R2 0.9124592429555655\n",
      "finished training epoch 1936\n",
      "train_loss:  1.1619730478987749e-05 train_R2 0.8890804432506226\n",
      "finished training epoch 1937\n",
      "train_loss:  1.1430203276485204e-05 train_R2 0.9266807827108412\n",
      "finished training epoch 1938\n",
      "train_loss:  1.1665978426406069e-05 train_R2 0.8947263061222883\n",
      "finished training epoch 1939\n",
      "train_loss:  1.1546497256601793e-05 train_R2 0.9099292182525309\n",
      "finished training epoch 1940\n",
      "train_loss:  1.1636284942028092e-05 train_R2 0.9038847895313438\n",
      "finished training epoch 1941\n",
      "train_loss:  1.1513984155419597e-05 train_R2 0.8607617710315277\n",
      "finished training epoch 1942\n",
      "train_loss:  1.1523419404023414e-05 train_R2 0.8972832597222005\n",
      "finished training epoch 1943\n",
      "train_loss:  1.1750056276307844e-05 train_R2 0.8514675147026698\n",
      "finished training epoch 1944\n",
      "train_loss:  1.1416149495836878e-05 train_R2 0.9302089848174593\n",
      "finished training epoch 1945\n",
      "train_loss:  1.1550083294450338e-05 train_R2 0.9146203219119107\n",
      "finished training epoch 1946\n",
      "train_loss:  1.1567323179552767e-05 train_R2 0.8799502809480133\n",
      "finished training epoch 1947\n",
      "train_loss:  1.1619945701334219e-05 train_R2 0.8609876228434168\n",
      "finished training epoch 1948\n",
      "train_loss:  1.1476171348516164e-05 train_R2 0.9055154380244019\n",
      "finished training epoch 1949\n",
      "train_loss:  1.1381270894908275e-05 train_R2 0.9012163738575809\n",
      "finished training epoch 1950\n",
      "train_loss:  1.1628137491898037e-05 train_R2 0.9039855660685223\n",
      "finished training epoch 1951\n",
      "train_loss:  1.1302117517634156e-05 train_R2 0.8732814610664816\n",
      "finished training epoch 1952\n",
      "train_loss:  1.1265614473016643e-05 train_R2 0.8823542253456201\n",
      "finished training epoch 1953\n",
      "train_loss:  1.156591197746617e-05 train_R2 0.9152628646040695\n",
      "finished training epoch 1954\n",
      "train_loss:  1.1651611818249301e-05 train_R2 0.8796285657306371\n",
      "finished training epoch 1955\n",
      "train_loss:  1.1603274339684332e-05 train_R2 0.8918195271199801\n",
      "finished training epoch 1956\n",
      "train_loss:  1.1431021668181466e-05 train_R2 0.9083056969285496\n",
      "finished training epoch 1957\n",
      "train_loss:  1.161869976213423e-05 train_R2 0.9309555157165165\n",
      "finished training epoch 1958\n",
      "train_loss:  1.1507050928214767e-05 train_R2 0.8785772022859761\n",
      "finished training epoch 1959\n",
      "train_loss:  1.1477703589520966e-05 train_R2 0.884045232989097\n",
      "finished training epoch 1960\n",
      "train_loss:  1.1695006992001752e-05 train_R2 0.9199099084870528\n",
      "finished training epoch 1961\n",
      "train_loss:  1.1333923422404878e-05 train_R2 0.9365381713632055\n",
      "finished training epoch 1962\n",
      "train_loss:  1.155858849015292e-05 train_R2 0.8926643401277065\n",
      "finished training epoch 1963\n",
      "train_loss:  1.1632683300271633e-05 train_R2 0.9240702668527935\n",
      "finished training epoch 1964\n",
      "train_loss:  1.1482562654523816e-05 train_R2 0.8684094845678122\n",
      "finished training epoch 1965\n",
      "train_loss:  1.1752674326501586e-05 train_R2 0.8683627601149615\n",
      "finished training epoch 1966\n",
      "train_loss:  1.1818378992140769e-05 train_R2 0.8818886518003763\n",
      "finished training epoch 1967\n",
      "train_loss:  1.1761423702593994e-05 train_R2 0.9242793110574387\n",
      "finished training epoch 1968\n",
      "train_loss:  1.1576740188665605e-05 train_R2 0.8901822880715297\n",
      "finished training epoch 1969\n",
      "train_loss:  1.1532763078516466e-05 train_R2 0.9148518612892234\n",
      "finished training epoch 1970\n",
      "train_loss:  1.1661073603551179e-05 train_R2 0.8956934707199303\n",
      "finished training epoch 1971\n",
      "train_loss:  1.15524582657059e-05 train_R2 0.90307161985494\n",
      "finished training epoch 1972\n",
      "train_loss:  1.144367624065601e-05 train_R2 0.9270233114373319\n",
      "finished training epoch 1973\n",
      "train_loss:  1.1763592528811404e-05 train_R2 0.8972446838653922\n",
      "finished training epoch 1974\n",
      "train_loss:  1.1580383819879373e-05 train_R2 0.9080727310692607\n",
      "finished training epoch 1975\n",
      "train_loss:  1.1532711747338019e-05 train_R2 0.8991775831241671\n",
      "finished training epoch 1976\n",
      "train_loss:  1.1508859753687501e-05 train_R2 0.8573480599964971\n",
      "finished training epoch 1977\n",
      "train_loss:  1.1435713258758755e-05 train_R2 0.885162382543303\n",
      "finished training epoch 1978\n",
      "train_loss:  1.1417424488725197e-05 train_R2 0.9043701944759907\n",
      "finished training epoch 1979\n",
      "train_loss:  1.1372747236259572e-05 train_R2 0.8428276087177036\n",
      "finished training epoch 1980\n",
      "train_loss:  1.1602684979956738e-05 train_R2 0.9176094566375483\n",
      "finished training epoch 1981\n",
      "train_loss:  1.1361317317950018e-05 train_R2 0.8970667271535713\n",
      "finished training epoch 1982\n",
      "train_loss:  1.1541987095147638e-05 train_R2 0.8958132512195267\n",
      "finished training epoch 1983\n",
      "train_loss:  1.1261571371251954e-05 train_R2 0.8756782850012353\n",
      "finished training epoch 1984\n",
      "train_loss:  1.1587802667772427e-05 train_R2 0.8771189126843096\n",
      "finished training epoch 1985\n",
      "train_loss:  1.1440341199055025e-05 train_R2 0.9032387274798286\n",
      "finished training epoch 1986\n",
      "train_loss:  1.1516754935392836e-05 train_R2 0.8549446230900722\n",
      "finished training epoch 1987\n",
      "train_loss:  1.1513937471753914e-05 train_R2 0.9290562506499026\n",
      "finished training epoch 1988\n",
      "train_loss:  1.168941602830294e-05 train_R2 0.8762915905408306\n",
      "finished training epoch 1989\n",
      "train_loss:  1.1586997283160666e-05 train_R2 0.9069179882662248\n",
      "finished training epoch 1990\n",
      "train_loss:  1.1561409434517553e-05 train_R2 0.8821349392253349\n",
      "finished training epoch 1991\n",
      "train_loss:  1.1476947195223016e-05 train_R2 0.910208112704437\n",
      "finished training epoch 1992\n",
      "train_loss:  1.1476861952255963e-05 train_R2 0.9180531482123769\n",
      "finished training epoch 1993\n",
      "train_loss:  1.1445656737251407e-05 train_R2 0.9058097249457192\n",
      "finished training epoch 1994\n",
      "train_loss:  1.1399370390280172e-05 train_R2 0.9027936452224224\n",
      "finished training epoch 1995\n",
      "train_loss:  1.1312923385266594e-05 train_R2 0.9249730241115198\n",
      "finished training epoch 1996\n",
      "train_loss:  1.1632656638267435e-05 train_R2 0.9240143903313154\n",
      "finished training epoch 1997\n",
      "train_loss:  1.1649408540405053e-05 train_R2 0.9166023857766165\n",
      "finished training epoch 1998\n",
      "train_loss:  1.1498546809299438e-05 train_R2 0.9150378957015723\n",
      "finished training epoch 1999\n",
      "train_loss:  1.1345949516614426e-05 train_R2 0.9041956470425271\n",
      "finished training epoch 2000\n",
      "train_loss:  1.141087214584554e-05 train_R2 0.9331336823252296\n",
      "finished training epoch 2001\n",
      "train_loss:  1.1832017872112549e-05 train_R2 0.9412837577798561\n",
      "finished training epoch 2002\n",
      "train_loss:  1.1340299385530071e-05 train_R2 0.9003216546256374\n",
      "finished training epoch 2003\n",
      "train_loss:  1.1282606593982497e-05 train_R2 0.8836644764123517\n",
      "finished training epoch 2004\n",
      "train_loss:  1.1334226409084013e-05 train_R2 0.886138225254565\n",
      "finished training epoch 2005\n",
      "train_loss:  1.1590790853127085e-05 train_R2 0.911600045306541\n",
      "finished training epoch 2006\n",
      "train_loss:  1.1376154743263046e-05 train_R2 0.875700967805741\n",
      "finished training epoch 2007\n",
      "train_loss:  1.1447147320427735e-05 train_R2 0.8814932453377621\n",
      "finished training epoch 2008\n",
      "train_loss:  1.1411217609453988e-05 train_R2 0.8852527043204721\n",
      "finished training epoch 2009\n",
      "train_loss:  1.163667860391179e-05 train_R2 0.8620170177297308\n",
      "finished training epoch 2010\n",
      "train_loss:  1.1465558782656081e-05 train_R2 0.8993422607792807\n",
      "finished training epoch 2011\n",
      "train_loss:  1.1692490986111237e-05 train_R2 0.9182423070083108\n",
      "finished training epoch 2012\n",
      "train_loss:  1.1621098118881353e-05 train_R2 0.8914383111871034\n",
      "finished training epoch 2013\n",
      "train_loss:  1.1540211340593737e-05 train_R2 0.9143061133071708\n",
      "finished training epoch 2014\n",
      "train_loss:  1.192758588773171e-05 train_R2 0.8974561905659554\n",
      "finished training epoch 2015\n",
      "train_loss:  1.1890762832353674e-05 train_R2 0.8769661533999332\n",
      "finished training epoch 2016\n",
      "train_loss:  1.1520325884347534e-05 train_R2 0.8976480090465639\n",
      "finished training epoch 2017\n",
      "train_loss:  1.1743025758339574e-05 train_R2 0.865079298396715\n",
      "finished training epoch 2018\n",
      "train_loss:  1.1881608469747712e-05 train_R2 0.9071133662596184\n",
      "finished training epoch 2019\n",
      "train_loss:  1.1885392324225054e-05 train_R2 0.8841252325940118\n",
      "finished training epoch 2020\n",
      "train_loss:  1.2027338338546697e-05 train_R2 0.8854464449420267\n",
      "finished training epoch 2021\n",
      "train_loss:  1.1338069226902352e-05 train_R2 0.932474379555336\n",
      "finished training epoch 2022\n",
      "train_loss:  1.162229852519214e-05 train_R2 0.887149331787204\n",
      "finished training epoch 2023\n",
      "train_loss:  1.1768882545094007e-05 train_R2 0.9124622459227011\n",
      "finished training epoch 2024\n",
      "train_loss:  1.1621594749518466e-05 train_R2 0.8887228420694109\n",
      "finished training epoch 2025\n",
      "train_loss:  1.1281016116149848e-05 train_R2 0.8827494457643889\n",
      "finished training epoch 2026\n",
      "train_loss:  1.1420063543896875e-05 train_R2 0.9173233488139246\n",
      "finished training epoch 2027\n",
      "train_loss:  1.1389856931512294e-05 train_R2 0.9089147409050475\n",
      "finished training epoch 2028\n",
      "train_loss:  1.1328840647480994e-05 train_R2 0.8974875768122024\n",
      "finished training epoch 2029\n",
      "train_loss:  1.1222918264562863e-05 train_R2 0.9040167517384344\n",
      "finished training epoch 2030\n",
      "train_loss:  1.1650550028945816e-05 train_R2 0.9066409765807397\n",
      "finished training epoch 2031\n",
      "train_loss:  1.1624916076460324e-05 train_R2 0.902542389152905\n",
      "finished training epoch 2032\n",
      "train_loss:  1.1648737055119404e-05 train_R2 0.9001958414568016\n",
      "finished training epoch 2033\n",
      "train_loss:  1.1367574030191888e-05 train_R2 0.9144677775603097\n",
      "finished training epoch 2034\n",
      "train_loss:  1.1270573358202003e-05 train_R2 0.9046767168903971\n",
      "finished training epoch 2035\n",
      "train_loss:  1.1311266116454943e-05 train_R2 0.906514383865378\n",
      "finished training epoch 2036\n",
      "train_loss:  1.1310335388953738e-05 train_R2 0.9146739277118009\n",
      "finished training epoch 2037\n",
      "train_loss:  1.1470856200372483e-05 train_R2 0.8917096465950727\n",
      "finished training epoch 2038\n",
      "train_loss:  1.1645724621049983e-05 train_R2 0.9041920777556065\n",
      "finished training epoch 2039\n",
      "train_loss:  1.168616818960864e-05 train_R2 0.9220646122862358\n",
      "finished training epoch 2040\n",
      "train_loss:  1.1290627542832466e-05 train_R2 0.8954854337103835\n",
      "finished training epoch 2041\n",
      "train_loss:  1.148792185083802e-05 train_R2 0.9007273912712468\n",
      "finished training epoch 2042\n",
      "train_loss:  1.1558915319705532e-05 train_R2 0.8824703681536031\n",
      "finished training epoch 2043\n",
      "train_loss:  1.141215531124104e-05 train_R2 0.8905628417057423\n",
      "finished training epoch 2044\n",
      "train_loss:  1.1681331741982079e-05 train_R2 0.884024131697038\n",
      "finished training epoch 2045\n",
      "train_loss:  1.1348052549247613e-05 train_R2 0.9310339060836907\n",
      "finished training epoch 2046\n",
      "train_loss:  1.1352048391276882e-05 train_R2 0.8960858830860349\n",
      "finished training epoch 2047\n",
      "train_loss:  1.1463890887600492e-05 train_R2 0.898942022893345\n",
      "finished training epoch 2048\n",
      "train_loss:  1.1478316759165964e-05 train_R2 0.8748923154672187\n",
      "finished training epoch 2049\n",
      "train_loss:  1.1807628063369662e-05 train_R2 0.8892778247437919\n",
      "finished training epoch 2050\n",
      "train_loss:  1.1499502620094976e-05 train_R2 0.8899341385371282\n",
      "finished training epoch 2051\n",
      "train_loss:  1.142467518423035e-05 train_R2 0.8745224865848281\n",
      "finished training epoch 2052\n",
      "train_loss:  1.1500019406540799e-05 train_R2 0.9132189276434503\n",
      "finished training epoch 2053\n",
      "train_loss:  1.1463087665290947e-05 train_R2 0.9082307603276412\n",
      "finished training epoch 2054\n",
      "train_loss:  1.1402928744417371e-05 train_R2 0.8883818959347209\n",
      "finished training epoch 2055\n",
      "train_loss:  1.1503580557844847e-05 train_R2 0.9145702758941862\n",
      "finished training epoch 2056\n",
      "train_loss:  1.1220867783260148e-05 train_R2 0.8980645471860748\n",
      "finished training epoch 2057\n",
      "train_loss:  1.140790497938053e-05 train_R2 0.9078343704564705\n",
      "finished training epoch 2058\n",
      "train_loss:  1.1628212542406802e-05 train_R2 0.8908004641084974\n",
      "finished training epoch 2059\n",
      "train_loss:  1.1254754861415301e-05 train_R2 0.911705248359314\n",
      "finished training epoch 2060\n",
      "train_loss:  1.15174919966204e-05 train_R2 0.9089692767770824\n",
      "finished training epoch 2061\n",
      "train_loss:  1.1200630300699916e-05 train_R2 0.9043352775179994\n",
      "finished training epoch 2062\n",
      "train_loss:  1.1436286782161017e-05 train_R2 0.906514275432548\n",
      "finished training epoch 2063\n",
      "train_loss:  1.1338424482829253e-05 train_R2 0.8709781864721975\n",
      "finished training epoch 2064\n",
      "train_loss:  1.1623757385162796e-05 train_R2 0.9164352702714789\n",
      "finished training epoch 2065\n",
      "train_loss:  1.1277704805470124e-05 train_R2 0.8958106911486502\n",
      "finished training epoch 2066\n",
      "train_loss:  1.1685896072963345e-05 train_R2 0.8624841131921269\n",
      "finished training epoch 2067\n",
      "train_loss:  1.149684983419038e-05 train_R2 0.8816703806084947\n",
      "finished training epoch 2068\n",
      "train_loss:  1.1440627270946306e-05 train_R2 0.9039497621247204\n",
      "finished training epoch 2069\n",
      "train_loss:  1.1540149578318525e-05 train_R2 0.912930667315236\n",
      "finished training epoch 2070\n",
      "train_loss:  1.1792124291865269e-05 train_R2 0.875904814128742\n",
      "finished training epoch 2071\n",
      "train_loss:  1.1580299013785223e-05 train_R2 0.8995098451715476\n",
      "finished training epoch 2072\n",
      "train_loss:  1.1418477081243646e-05 train_R2 0.9059378895944237\n",
      "finished training epoch 2073\n",
      "train_loss:  1.132586910545873e-05 train_R2 0.9213936450269637\n",
      "finished training epoch 2074\n",
      "train_loss:  1.1240068953078975e-05 train_R2 0.9137265827153005\n",
      "finished training epoch 2075\n",
      "train_loss:  1.123852352727882e-05 train_R2 0.8623969898051891\n",
      "finished training epoch 2076\n",
      "train_loss:  1.1189559085647232e-05 train_R2 0.9149152399885356\n",
      "finished training epoch 2077\n",
      "train_loss:  1.1589241321794157e-05 train_R2 0.9101167209530202\n",
      "finished training epoch 2078\n",
      "train_loss:  1.1497056410758594e-05 train_R2 0.894529107206429\n",
      "finished training epoch 2079\n",
      "train_loss:  1.1434178034867765e-05 train_R2 0.8632492142835938\n",
      "finished training epoch 2080\n",
      "train_loss:  1.1520040937034556e-05 train_R2 0.9050226991067226\n",
      "finished training epoch 2081\n",
      "train_loss:  1.160653432449522e-05 train_R2 0.913738185731276\n",
      "finished training epoch 2082\n",
      "train_loss:  1.1451835092275722e-05 train_R2 0.8984594763035663\n",
      "finished training epoch 2083\n",
      "train_loss:  1.1459941294964781e-05 train_R2 0.9084697462177282\n",
      "finished training epoch 2084\n",
      "train_loss:  1.1578003870149708e-05 train_R2 0.9118591943061313\n",
      "finished training epoch 2085\n",
      "train_loss:  1.1768002334217704e-05 train_R2 0.9102835648077341\n",
      "finished training epoch 2086\n",
      "train_loss:  1.1644913976603584e-05 train_R2 0.9030007909639567\n",
      "finished training epoch 2087\n",
      "train_loss:  1.1541659677749792e-05 train_R2 0.9105060598407682\n",
      "finished training epoch 2088\n",
      "train_loss:  1.1373940661106689e-05 train_R2 0.8926187811006411\n",
      "finished training epoch 2089\n",
      "train_loss:  1.1823543892486677e-05 train_R2 0.9101641113973529\n",
      "finished training epoch 2090\n",
      "train_loss:  1.1768237406594397e-05 train_R2 0.8968074166464864\n",
      "finished training epoch 2091\n",
      "train_loss:  1.1420925332343683e-05 train_R2 0.918440260910296\n",
      "finished training epoch 2092\n",
      "train_loss:  1.1264558016837743e-05 train_R2 0.8989989812003897\n",
      "finished training epoch 2093\n",
      "train_loss:  1.1523864889465828e-05 train_R2 0.8474277766520246\n",
      "finished training epoch 2094\n",
      "train_loss:  1.1526675567547353e-05 train_R2 0.8419412439971837\n",
      "finished training epoch 2095\n",
      "train_loss:  1.1601323892277513e-05 train_R2 0.9036689876546833\n",
      "finished training epoch 2096\n",
      "train_loss:  1.1343489318251345e-05 train_R2 0.9551718550472272\n",
      "finished training epoch 2097\n",
      "train_loss:  1.1403336825402702e-05 train_R2 0.8582708613575832\n",
      "finished training epoch 2098\n",
      "train_loss:  1.1617264203580396e-05 train_R2 0.9246417984866453\n",
      "finished training epoch 2099\n",
      "train_loss:  1.1407113489963557e-05 train_R2 0.8430273580687547\n",
      "finished training epoch 2100\n",
      "train_loss:  1.1382929137333025e-05 train_R2 0.8964151730460246\n",
      "finished training epoch 2101\n",
      "train_loss:  1.178183080429422e-05 train_R2 0.8916111433115835\n",
      "finished training epoch 2102\n",
      "train_loss:  1.1362647238223021e-05 train_R2 0.8999318722957785\n",
      "finished training epoch 2103\n",
      "train_loss:  1.1164591215486515e-05 train_R2 0.8926403300636502\n",
      "finished training epoch 2104\n",
      "train_loss:  1.1419536132578281e-05 train_R2 0.8982768278838926\n",
      "finished training epoch 2105\n",
      "train_loss:  1.1430072854798787e-05 train_R2 0.8906614916775171\n",
      "finished training epoch 2106\n",
      "train_loss:  1.1276090420252965e-05 train_R2 0.9226059840437919\n",
      "finished training epoch 2107\n",
      "train_loss:  1.1316690495638662e-05 train_R2 0.8825757516694239\n",
      "finished training epoch 2108\n",
      "train_loss:  1.165867213640294e-05 train_R2 0.89984669385096\n",
      "finished training epoch 2109\n",
      "train_loss:  1.1331614091887388e-05 train_R2 0.8829988599006934\n",
      "finished training epoch 2110\n",
      "train_loss:  1.1446090570138522e-05 train_R2 0.9265120840500469\n",
      "finished training epoch 2111\n",
      "train_loss:  1.1471124711572824e-05 train_R2 0.9103349478633171\n",
      "finished training epoch 2112\n",
      "train_loss:  1.1723066665777063e-05 train_R2 0.9044126429953063\n",
      "finished training epoch 2113\n",
      "train_loss:  1.157571207641425e-05 train_R2 0.9181475285517378\n",
      "finished training epoch 2114\n",
      "train_loss:  1.1405473270889635e-05 train_R2 0.8900360426294807\n",
      "finished training epoch 2115\n",
      "train_loss:  1.1315193092403836e-05 train_R2 0.9112208523279592\n",
      "finished training epoch 2116\n",
      "train_loss:  1.146791270919427e-05 train_R2 0.9112406928059791\n",
      "finished training epoch 2117\n",
      "train_loss:  1.1624368941633011e-05 train_R2 0.9036085134146292\n",
      "finished training epoch 2118\n",
      "train_loss:  1.1494822263744138e-05 train_R2 0.8860703934617045\n",
      "finished training epoch 2119\n",
      "train_loss:  1.1249659105036318e-05 train_R2 0.8810477556100441\n",
      "finished training epoch 2120\n",
      "train_loss:  1.1580710129813762e-05 train_R2 0.9120406872522877\n",
      "finished training epoch 2121\n",
      "train_loss:  1.1644013244022894e-05 train_R2 0.929596995587423\n",
      "finished training epoch 2122\n",
      "train_loss:  1.1675360797729066e-05 train_R2 0.8790895611062055\n",
      "finished training epoch 2123\n",
      "train_loss:  1.1413096807424147e-05 train_R2 0.9174348193233509\n",
      "finished training epoch 2124\n",
      "train_loss:  1.1461017948638189e-05 train_R2 0.8674161323654267\n",
      "finished training epoch 2125\n",
      "train_loss:  1.1254640262278802e-05 train_R2 0.9209603087559215\n",
      "finished training epoch 2126\n",
      "train_loss:  1.1388028247170216e-05 train_R2 0.8932160301182825\n",
      "finished training epoch 2127\n",
      "train_loss:  1.1654108383288398e-05 train_R2 0.9305456162872604\n",
      "finished training epoch 2128\n",
      "train_loss:  1.1190456526894624e-05 train_R2 0.8876219009627044\n",
      "finished training epoch 2129\n",
      "train_loss:  1.1513783569068359e-05 train_R2 0.942439984448915\n",
      "finished training epoch 2130\n",
      "train_loss:  1.1437880827840363e-05 train_R2 0.8770164332415962\n",
      "finished training epoch 2131\n",
      "train_loss:  1.1307242400558061e-05 train_R2 0.9127209896352826\n",
      "finished training epoch 2132\n",
      "train_loss:  1.152078417185912e-05 train_R2 0.8878906635269552\n",
      "finished training epoch 2133\n",
      "train_loss:  1.1587503310799486e-05 train_R2 0.8870246313950839\n",
      "finished training epoch 2134\n",
      "train_loss:  1.1367680584018968e-05 train_R2 0.902149073887094\n",
      "finished training epoch 2135\n",
      "train_loss:  1.127656306174821e-05 train_R2 0.9280352856028476\n",
      "finished training epoch 2136\n",
      "train_loss:  1.1325966970726663e-05 train_R2 0.9190842014677488\n",
      "finished training epoch 2137\n",
      "train_loss:  1.128536394701743e-05 train_R2 0.8999809503770031\n",
      "finished training epoch 2138\n",
      "train_loss:  1.1316280753077644e-05 train_R2 0.914247482380603\n",
      "finished training epoch 2139\n",
      "train_loss:  1.1749279357208948e-05 train_R2 0.9248373704729288\n",
      "finished training epoch 2140\n",
      "train_loss:  1.1226795916614653e-05 train_R2 0.8865895738646615\n",
      "finished training epoch 2141\n",
      "train_loss:  1.1576698622387912e-05 train_R2 0.9052495520651219\n",
      "finished training epoch 2142\n",
      "train_loss:  1.1417857209963462e-05 train_R2 0.8694366289031912\n",
      "finished training epoch 2143\n",
      "train_loss:  1.1192946682446709e-05 train_R2 0.9134555556080799\n",
      "finished training epoch 2144\n",
      "train_loss:  1.1052391570797527e-05 train_R2 0.8985248823491215\n",
      "finished training epoch 2145\n",
      "train_loss:  1.1453254365636688e-05 train_R2 0.9185431567006991\n",
      "finished training epoch 2146\n",
      "train_loss:  1.132999320599088e-05 train_R2 0.8684852671764521\n",
      "finished training epoch 2147\n",
      "train_loss:  1.155484113010296e-05 train_R2 0.8673094060903317\n",
      "finished training epoch 2148\n",
      "train_loss:  1.1560497259523093e-05 train_R2 0.9176039432079045\n",
      "finished training epoch 2149\n",
      "train_loss:  1.1437236647270589e-05 train_R2 0.9277668640241236\n",
      "finished training epoch 2150\n",
      "train_loss:  1.1697396055735888e-05 train_R2 0.8859061165091403\n",
      "finished training epoch 2151\n",
      "train_loss:  1.1046899170550531e-05 train_R2 0.9125656033167485\n",
      "finished training epoch 2152\n",
      "train_loss:  1.1568781643268953e-05 train_R2 0.8867733025764822\n",
      "finished training epoch 2153\n",
      "train_loss:  1.1246749978162647e-05 train_R2 0.923501940054957\n",
      "finished training epoch 2154\n",
      "train_loss:  1.1349830940959993e-05 train_R2 0.903438208730055\n",
      "finished training epoch 2155\n",
      "train_loss:  1.1525401825060839e-05 train_R2 0.8981247044960088\n",
      "finished training epoch 2156\n",
      "train_loss:  1.1259531763755186e-05 train_R2 0.9246649378101749\n",
      "finished training epoch 2157\n",
      "train_loss:  1.1576451149538833e-05 train_R2 0.8957450652438179\n",
      "finished training epoch 2158\n",
      "train_loss:  1.1541119621354123e-05 train_R2 0.8948317885199418\n",
      "finished training epoch 2159\n",
      "train_loss:  1.1305023919977636e-05 train_R2 0.906974286109429\n",
      "finished training epoch 2160\n",
      "train_loss:  1.1275892638392772e-05 train_R2 0.9109189000638148\n",
      "finished training epoch 2161\n",
      "train_loss:  1.112770116779432e-05 train_R2 0.9353948229921071\n",
      "finished training epoch 2162\n",
      "train_loss:  1.1388424786804722e-05 train_R2 0.8929251727129813\n",
      "finished training epoch 2163\n",
      "train_loss:  1.1421090213710549e-05 train_R2 0.9213718357097969\n",
      "finished training epoch 2164\n",
      "train_loss:  1.1785878227079152e-05 train_R2 0.9071093756357752\n",
      "finished training epoch 2165\n",
      "train_loss:  1.164036947761021e-05 train_R2 0.8871058825409613\n",
      "finished training epoch 2166\n",
      "train_loss:  1.1637136715230061e-05 train_R2 0.8989071519157589\n",
      "finished training epoch 2167\n",
      "train_loss:  1.1335471851457154e-05 train_R2 0.9127767994093974\n",
      "finished training epoch 2168\n",
      "train_loss:  1.1209163831954853e-05 train_R2 0.9259559694957852\n",
      "finished training epoch 2169\n",
      "train_loss:  1.1312379150728195e-05 train_R2 0.8695265660868556\n",
      "finished training epoch 2170\n",
      "train_loss:  1.124196609166068e-05 train_R2 0.9017558079232726\n",
      "finished training epoch 2171\n",
      "train_loss:  1.1450192151408727e-05 train_R2 0.8794924227384665\n",
      "finished training epoch 2172\n",
      "train_loss:  1.1298429207066656e-05 train_R2 0.9253432389718119\n",
      "finished training epoch 2173\n",
      "train_loss:  1.125389412900649e-05 train_R2 0.9029288985909194\n",
      "finished training epoch 2174\n",
      "train_loss:  1.1605560704455493e-05 train_R2 0.8669407391044002\n",
      "finished training epoch 2175\n",
      "train_loss:  1.1543088851707184e-05 train_R2 0.8768005390822639\n",
      "finished training epoch 2176\n",
      "train_loss:  1.1646446469542304e-05 train_R2 0.8711247505594182\n",
      "finished training epoch 2177\n",
      "train_loss:  1.1241780232864126e-05 train_R2 0.8780797240124011\n",
      "finished training epoch 2178\n",
      "train_loss:  1.1628426793309923e-05 train_R2 0.8880649413254151\n",
      "finished training epoch 2179\n",
      "train_loss:  1.159681978960288e-05 train_R2 0.8923721231292282\n",
      "finished training epoch 2180\n",
      "train_loss:  1.138030212903892e-05 train_R2 0.903451709931383\n",
      "finished training epoch 2181\n",
      "train_loss:  1.1441322401769972e-05 train_R2 0.8659468495099825\n",
      "finished training epoch 2182\n",
      "train_loss:  1.1235741306312173e-05 train_R2 0.8973312003928895\n",
      "finished training epoch 2183\n",
      "train_loss:  1.1548455979023598e-05 train_R2 0.8816149372685159\n",
      "finished training epoch 2184\n",
      "train_loss:  1.1302853284074454e-05 train_R2 0.9049032449557106\n",
      "finished training epoch 2185\n",
      "train_loss:  1.120199966000937e-05 train_R2 0.8663769097130746\n",
      "finished training epoch 2186\n",
      "train_loss:  1.1475519853316208e-05 train_R2 0.8955364463565437\n",
      "finished training epoch 2187\n",
      "train_loss:  1.142568599552169e-05 train_R2 0.9111239573338955\n",
      "finished training epoch 2188\n",
      "train_loss:  1.160674991537406e-05 train_R2 0.8530711243032393\n",
      "finished training epoch 2189\n",
      "train_loss:  1.1241614457964735e-05 train_R2 0.9285262309474029\n",
      "finished training epoch 2190\n",
      "train_loss:  1.1340831948328055e-05 train_R2 0.9045922435435714\n",
      "finished training epoch 2191\n",
      "train_loss:  1.1469015033326602e-05 train_R2 0.930800641952472\n",
      "finished training epoch 2192\n",
      "train_loss:  1.1365650719818348e-05 train_R2 0.9151771580189099\n",
      "finished training epoch 2193\n",
      "train_loss:  1.1270907879610492e-05 train_R2 0.8745505266115046\n",
      "finished training epoch 2194\n",
      "train_loss:  1.1605884297633317e-05 train_R2 0.9217846783254237\n",
      "finished training epoch 2195\n",
      "train_loss:  1.1433226432206219e-05 train_R2 0.9323517578526196\n",
      "finished training epoch 2196\n",
      "train_loss:  1.1389397507443449e-05 train_R2 0.8442095391433424\n",
      "finished training epoch 2197\n",
      "train_loss:  1.148801696706099e-05 train_R2 0.9055410840506413\n",
      "finished training epoch 2198\n",
      "train_loss:  1.1346511956080114e-05 train_R2 0.8991919342142617\n",
      "finished training epoch 2199\n",
      "train_loss:  1.1226211003929008e-05 train_R2 0.9045568499532723\n",
      "finished training epoch 2200\n",
      "train_loss:  1.1611974934409646e-05 train_R2 0.90237017669163\n",
      "finished training epoch 2201\n",
      "train_loss:  1.1156858570377787e-05 train_R2 0.885607433743705\n",
      "finished training epoch 2202\n",
      "train_loss:  1.1587369565485639e-05 train_R2 0.8529857997855708\n",
      "finished training epoch 2203\n",
      "train_loss:  1.1397943447583172e-05 train_R2 0.8866336786572776\n",
      "finished training epoch 2204\n",
      "train_loss:  1.14261531700594e-05 train_R2 0.8985945690773969\n",
      "finished training epoch 2205\n",
      "train_loss:  1.151874637500835e-05 train_R2 0.864435299325649\n",
      "finished training epoch 2206\n",
      "train_loss:  1.1184130113301196e-05 train_R2 0.9168843773424691\n",
      "finished training epoch 2207\n",
      "train_loss:  1.1455680181601722e-05 train_R2 0.8969763387654157\n",
      "finished training epoch 2208\n",
      "train_loss:  1.1343674925628359e-05 train_R2 0.863870871613369\n",
      "finished training epoch 2209\n",
      "train_loss:  1.1485175464415674e-05 train_R2 0.929761855008573\n",
      "finished training epoch 2210\n",
      "train_loss:  1.1168680205387501e-05 train_R2 0.903586625477174\n",
      "finished training epoch 2211\n",
      "train_loss:  1.1092415786832534e-05 train_R2 0.8934206375967486\n",
      "finished training epoch 2212\n",
      "train_loss:  1.1184386306000284e-05 train_R2 0.8982601240929535\n",
      "finished training epoch 2213\n",
      "train_loss:  1.1153396134153612e-05 train_R2 0.9083885284978748\n",
      "finished training epoch 2214\n",
      "train_loss:  1.1496262248912022e-05 train_R2 0.8769227229537628\n",
      "finished training epoch 2215\n",
      "train_loss:  1.123989779748938e-05 train_R2 0.8932638447540961\n",
      "finished training epoch 2216\n",
      "train_loss:  1.1224409552500931e-05 train_R2 0.8761212861894032\n",
      "finished training epoch 2217\n",
      "train_loss:  1.1334993200788269e-05 train_R2 0.9161516984003597\n",
      "finished training epoch 2218\n",
      "train_loss:  1.148754336594826e-05 train_R2 0.9116805421339595\n",
      "finished training epoch 2219\n",
      "train_loss:  1.1170538666260393e-05 train_R2 0.9305357732565778\n",
      "finished training epoch 2220\n",
      "train_loss:  1.1465108276473614e-05 train_R2 0.9285377675789421\n",
      "finished training epoch 2221\n",
      "train_loss:  1.148370738613847e-05 train_R2 0.8965705439143152\n",
      "finished training epoch 2222\n",
      "train_loss:  1.1730991313698663e-05 train_R2 0.9072661653364423\n",
      "finished training epoch 2223\n",
      "train_loss:  1.1312471192349798e-05 train_R2 0.8825508452501469\n",
      "finished training epoch 2224\n",
      "train_loss:  1.1630902198682177e-05 train_R2 0.8960697551056791\n",
      "finished training epoch 2225\n",
      "train_loss:  1.1503648736903611e-05 train_R2 0.8768495426060849\n",
      "finished training epoch 2226\n",
      "train_loss:  1.1488938457864068e-05 train_R2 0.9114481753513406\n",
      "finished training epoch 2227\n",
      "train_loss:  1.1479652167376548e-05 train_R2 0.8696356489659236\n",
      "finished training epoch 2228\n",
      "train_loss:  1.1491495007805054e-05 train_R2 0.9007533943806113\n",
      "finished training epoch 2229\n",
      "train_loss:  1.1516537599555499e-05 train_R2 0.8964284120793523\n",
      "finished training epoch 2230\n",
      "train_loss:  1.1434900488308542e-05 train_R2 0.9061446020716099\n",
      "finished training epoch 2231\n",
      "train_loss:  1.1199477894866679e-05 train_R2 0.9014800001119653\n",
      "finished training epoch 2232\n",
      "train_loss:  1.1340365401647035e-05 train_R2 0.8946791835990826\n",
      "finished training epoch 2233\n",
      "train_loss:  1.1351065082286955e-05 train_R2 0.9332204010816175\n",
      "finished training epoch 2234\n",
      "train_loss:  1.1414585302857123e-05 train_R2 0.9018411547538183\n",
      "finished training epoch 2235\n",
      "train_loss:  1.1474829443613152e-05 train_R2 0.907941353704743\n",
      "finished training epoch 2236\n",
      "train_loss:  1.1355898018645928e-05 train_R2 0.8883327806782655\n",
      "finished training epoch 2237\n",
      "train_loss:  1.1356746136998731e-05 train_R2 0.8937334587307574\n",
      "finished training epoch 2238\n",
      "train_loss:  1.1200505790899385e-05 train_R2 0.8773109402074507\n",
      "finished training epoch 2239\n",
      "train_loss:  1.1659782741114744e-05 train_R2 0.8737650239591349\n",
      "finished training epoch 2240\n",
      "train_loss:  1.1392329321006133e-05 train_R2 0.8950099314007545\n",
      "finished training epoch 2241\n",
      "train_loss:  1.139697085110696e-05 train_R2 0.8685762377357942\n",
      "finished training epoch 2242\n",
      "train_loss:  1.1338824593105537e-05 train_R2 0.8931984099723271\n",
      "finished training epoch 2243\n",
      "train_loss:  1.1367252989255479e-05 train_R2 0.893150276046229\n",
      "finished training epoch 2244\n",
      "train_loss:  1.1272906073043684e-05 train_R2 0.8623439862786211\n",
      "finished training epoch 2245\n",
      "train_loss:  1.1295746635655977e-05 train_R2 0.9281186455739563\n",
      "finished training epoch 2246\n",
      "train_loss:  1.1423914811716602e-05 train_R2 0.885710551460965\n",
      "finished training epoch 2247\n",
      "train_loss:  1.1560914036412284e-05 train_R2 0.9098830938500332\n",
      "finished training epoch 2248\n",
      "train_loss:  1.1511803259117555e-05 train_R2 0.902940457619647\n",
      "finished training epoch 2249\n",
      "train_loss:  1.1386823983461182e-05 train_R2 0.896098385992067\n",
      "finished training epoch 2250\n",
      "train_loss:  1.1493739546174398e-05 train_R2 0.9115218587025651\n",
      "finished training epoch 2251\n",
      "train_loss:  1.1352942460631757e-05 train_R2 0.891714697128915\n",
      "finished training epoch 2252\n",
      "train_loss:  1.1514851876803353e-05 train_R2 0.9054783945178801\n",
      "finished training epoch 2253\n",
      "train_loss:  1.108387913082323e-05 train_R2 0.8822025379648366\n",
      "finished training epoch 2254\n",
      "train_loss:  1.1362149329210361e-05 train_R2 0.8959489978102109\n",
      "finished training epoch 2255\n",
      "train_loss:  1.1371419121214785e-05 train_R2 0.8764632794420352\n",
      "finished training epoch 2256\n",
      "train_loss:  1.1124242534572724e-05 train_R2 0.9194941499541249\n",
      "finished training epoch 2257\n",
      "train_loss:  1.1210234933539651e-05 train_R2 0.904255644072282\n",
      "finished training epoch 2258\n",
      "train_loss:  1.1210823475965356e-05 train_R2 0.8706118831444374\n",
      "finished training epoch 2259\n",
      "train_loss:  1.1538888121892521e-05 train_R2 0.918807023970711\n",
      "finished training epoch 2260\n",
      "train_loss:  1.1282271396175459e-05 train_R2 0.9329878062933552\n",
      "finished training epoch 2261\n",
      "train_loss:  1.1478714309392632e-05 train_R2 0.9115061620091068\n",
      "finished training epoch 2262\n",
      "train_loss:  1.1585185448468832e-05 train_R2 0.9135201676565174\n",
      "finished training epoch 2263\n",
      "train_loss:  1.1737377579221418e-05 train_R2 0.8930701684796039\n",
      "finished training epoch 2264\n",
      "train_loss:  1.1461923830778518e-05 train_R2 0.8987231550423852\n",
      "finished training epoch 2265\n",
      "train_loss:  1.1269168412182705e-05 train_R2 0.9155143008144621\n",
      "finished training epoch 2266\n",
      "train_loss:  1.161858530774131e-05 train_R2 0.8685330166580266\n",
      "finished training epoch 2267\n",
      "train_loss:  1.1116054031405943e-05 train_R2 0.9032401882108638\n",
      "finished training epoch 2268\n",
      "train_loss:  1.1346448004847608e-05 train_R2 0.8889178497398753\n",
      "finished training epoch 2269\n",
      "train_loss:  1.1191786144742237e-05 train_R2 0.9295389236606495\n",
      "finished training epoch 2270\n",
      "train_loss:  1.1299219688981845e-05 train_R2 0.9114829927666912\n",
      "finished training epoch 2271\n",
      "train_loss:  1.1401944186641998e-05 train_R2 0.884437723842357\n",
      "finished training epoch 2272\n",
      "train_loss:  1.1023973445193755e-05 train_R2 0.9057564646737072\n",
      "finished training epoch 2273\n",
      "train_loss:  1.1357109501441473e-05 train_R2 0.9051954839144654\n",
      "finished training epoch 2274\n",
      "train_loss:  1.1387710040426314e-05 train_R2 0.9150844350092149\n",
      "finished training epoch 2275\n",
      "train_loss:  1.1627914036766449e-05 train_R2 0.8879450174501489\n",
      "finished training epoch 2276\n",
      "train_loss:  1.1198822462917875e-05 train_R2 0.8940550292519716\n",
      "finished training epoch 2277\n",
      "train_loss:  1.147296014772451e-05 train_R2 0.9092692700069593\n",
      "finished training epoch 2278\n",
      "train_loss:  1.1360711334419898e-05 train_R2 0.9094311109163304\n",
      "finished training epoch 2279\n",
      "train_loss:  1.1509432041403343e-05 train_R2 0.9005314406384024\n",
      "finished training epoch 2280\n",
      "train_loss:  1.1353423354579672e-05 train_R2 0.8688900110187879\n",
      "finished training epoch 2281\n",
      "train_loss:  1.1211665394893815e-05 train_R2 0.8770698830539159\n",
      "finished training epoch 2282\n",
      "train_loss:  1.133104931008384e-05 train_R2 0.88687118837354\n",
      "finished training epoch 2283\n",
      "train_loss:  1.137387459574878e-05 train_R2 0.9044126521997861\n",
      "finished training epoch 2284\n",
      "train_loss:  1.1350480865768172e-05 train_R2 0.9207381303276254\n",
      "finished training epoch 2285\n",
      "train_loss:  1.1241817794394249e-05 train_R2 0.9100388980392673\n",
      "finished training epoch 2286\n",
      "train_loss:  1.1246390726905429e-05 train_R2 0.8946687812659572\n",
      "finished training epoch 2287\n",
      "train_loss:  1.1209013029825747e-05 train_R2 0.8821424198939001\n",
      "finished training epoch 2288\n",
      "train_loss:  1.1285734654740984e-05 train_R2 0.8961230313922828\n",
      "finished training epoch 2289\n",
      "train_loss:  1.1290161476802741e-05 train_R2 0.9000931465519892\n",
      "finished training epoch 2290\n",
      "train_loss:  1.140210708698055e-05 train_R2 0.8925794271552329\n",
      "finished training epoch 2291\n",
      "train_loss:  1.1243286601444616e-05 train_R2 0.8914928042356107\n",
      "finished training epoch 2292\n",
      "train_loss:  1.1092945753718658e-05 train_R2 0.8899681170173244\n",
      "finished training epoch 2293\n",
      "train_loss:  1.1301067787300239e-05 train_R2 0.9021770586684504\n",
      "finished training epoch 2294\n",
      "train_loss:  1.1338705810655705e-05 train_R2 0.9300199903127783\n",
      "finished training epoch 2295\n",
      "train_loss:  1.1125690564231052e-05 train_R2 0.8708621415445544\n",
      "finished training epoch 2296\n",
      "train_loss:  1.1280160797414858e-05 train_R2 0.8566618432084062\n",
      "finished training epoch 2297\n",
      "train_loss:  1.1236685378489452e-05 train_R2 0.8951313678952668\n",
      "finished training epoch 2298\n",
      "train_loss:  1.142697023438712e-05 train_R2 0.9056087944638986\n",
      "finished training epoch 2299\n",
      "train_loss:  1.1295811526353993e-05 train_R2 0.918561439309511\n",
      "finished training epoch 2300\n",
      "train_loss:  1.1215634914034083e-05 train_R2 0.8803849437524808\n",
      "finished training epoch 2301\n",
      "train_loss:  1.142214393625731e-05 train_R2 0.8725523088263537\n",
      "finished training epoch 2302\n",
      "train_loss:  1.1186935322036226e-05 train_R2 0.8671503699154757\n",
      "finished training epoch 2303\n",
      "train_loss:  1.1342602556281911e-05 train_R2 0.9035217633291137\n",
      "finished training epoch 2304\n",
      "train_loss:  1.1160884702997549e-05 train_R2 0.8987463977760494\n",
      "finished training epoch 2305\n",
      "train_loss:  1.1233324995142027e-05 train_R2 0.8973760556157215\n",
      "finished training epoch 2306\n",
      "train_loss:  1.1362383367340574e-05 train_R2 0.9062926242532925\n",
      "finished training epoch 2307\n",
      "train_loss:  1.1523011145035986e-05 train_R2 0.9069267264293422\n",
      "finished training epoch 2308\n",
      "train_loss:  1.1227776648426495e-05 train_R2 0.9225439649639903\n",
      "finished training epoch 2309\n",
      "train_loss:  1.1426046613200047e-05 train_R2 0.9228414806944555\n",
      "finished training epoch 2310\n",
      "train_loss:  1.144170325897937e-05 train_R2 0.9155318625523605\n",
      "finished training epoch 2311\n",
      "train_loss:  1.0878159476433247e-05 train_R2 0.9163415254134122\n",
      "finished training epoch 2312\n",
      "train_loss:  1.1297060491355006e-05 train_R2 0.8953363867874539\n",
      "finished training epoch 2313\n",
      "train_loss:  1.1053910375693437e-05 train_R2 0.912665103425106\n",
      "finished training epoch 2314\n",
      "train_loss:  1.1340520927643042e-05 train_R2 0.8877475742880349\n",
      "finished training epoch 2315\n",
      "train_loss:  1.130035295743385e-05 train_R2 0.889604900433103\n",
      "finished training epoch 2316\n",
      "train_loss:  1.1406998854413002e-05 train_R2 0.9033355991348456\n",
      "finished training epoch 2317\n",
      "train_loss:  1.1334627148284927e-05 train_R2 0.9167166038889285\n",
      "finished training epoch 2318\n",
      "train_loss:  1.1250669285020418e-05 train_R2 0.9196000814910232\n",
      "finished training epoch 2319\n",
      "train_loss:  1.1433156841585106e-05 train_R2 0.8799498434222036\n",
      "finished training epoch 2320\n",
      "train_loss:  1.139409207358018e-05 train_R2 0.8866359686676912\n",
      "finished training epoch 2321\n",
      "train_loss:  1.1321963927621491e-05 train_R2 0.8689669344328851\n",
      "finished training epoch 2322\n",
      "train_loss:  1.1734663739877428e-05 train_R2 0.9192740097603443\n",
      "finished training epoch 2323\n",
      "train_loss:  1.1276331690064251e-05 train_R2 0.9171781550966766\n",
      "finished training epoch 2324\n",
      "train_loss:  1.1168596492433977e-05 train_R2 0.8764863475055499\n",
      "finished training epoch 2325\n",
      "train_loss:  1.1586894089388196e-05 train_R2 0.9152025533294844\n",
      "finished training epoch 2326\n",
      "train_loss:  1.1459350003184387e-05 train_R2 0.9023465890037825\n",
      "finished training epoch 2327\n",
      "train_loss:  1.1274512101542115e-05 train_R2 0.8683163921415668\n",
      "finished training epoch 2328\n",
      "train_loss:  1.1408372736225973e-05 train_R2 0.8919904422008841\n",
      "finished training epoch 2329\n",
      "train_loss:  1.119639534036377e-05 train_R2 0.9039581798586342\n",
      "finished training epoch 2330\n",
      "train_loss:  1.1349612319986022e-05 train_R2 0.9207214272000513\n",
      "finished training epoch 2331\n",
      "train_loss:  1.1253607440677469e-05 train_R2 0.9068535991984006\n",
      "finished training epoch 2332\n",
      "train_loss:  1.1522264121068043e-05 train_R2 0.8688418975383198\n",
      "finished training epoch 2333\n",
      "train_loss:  1.1410991998928715e-05 train_R2 0.8833249720318682\n",
      "finished training epoch 2334\n",
      "train_loss:  1.1281583279102175e-05 train_R2 0.9134478315958461\n",
      "finished training epoch 2335\n",
      "train_loss:  1.1159095071510735e-05 train_R2 0.9356895946103608\n",
      "finished training epoch 2336\n",
      "train_loss:  1.1417775897842221e-05 train_R2 0.8829139661291127\n",
      "finished training epoch 2337\n",
      "train_loss:  1.1266161470743155e-05 train_R2 0.9076895213412186\n",
      "finished training epoch 2338\n",
      "train_loss:  1.1275741524860916e-05 train_R2 0.9107019806318658\n",
      "finished training epoch 2339\n",
      "train_loss:  1.1364059017419634e-05 train_R2 0.8924822345642373\n",
      "finished training epoch 2340\n",
      "train_loss:  1.1489371422236183e-05 train_R2 0.931058718065427\n",
      "finished training epoch 2341\n",
      "train_loss:  1.1372106449199511e-05 train_R2 0.8844192532467752\n",
      "finished training epoch 2342\n",
      "train_loss:  1.1149559831369584e-05 train_R2 0.8871942503609916\n",
      "finished training epoch 2343\n",
      "train_loss:  1.1240037764986717e-05 train_R2 0.9242669222926371\n",
      "finished training epoch 2344\n",
      "train_loss:  1.1300574454845451e-05 train_R2 0.8890150498520479\n",
      "finished training epoch 2345\n",
      "train_loss:  1.0969424718660777e-05 train_R2 0.9119614120771912\n",
      "finished training epoch 2346\n",
      "train_loss:  1.1371448315019799e-05 train_R2 0.8725786699235115\n",
      "finished training epoch 2347\n",
      "train_loss:  1.1268976784984068e-05 train_R2 0.9136647158058215\n",
      "finished training epoch 2348\n",
      "train_loss:  1.1246854075000136e-05 train_R2 0.9093982772620025\n",
      "finished training epoch 2349\n",
      "train_loss:  1.1513240742411735e-05 train_R2 0.9150165655815115\n",
      "finished training epoch 2350\n",
      "train_loss:  1.1437147474462122e-05 train_R2 0.9352786592927319\n",
      "finished training epoch 2351\n",
      "train_loss:  1.1338497620335704e-05 train_R2 0.912524957558545\n",
      "finished training epoch 2352\n",
      "train_loss:  1.1281868462586399e-05 train_R2 0.8460605807019939\n",
      "finished training epoch 2353\n",
      "train_loss:  1.1075944961332282e-05 train_R2 0.8823424511343256\n",
      "finished training epoch 2354\n",
      "train_loss:  1.1303742597693752e-05 train_R2 0.9045064147931123\n",
      "finished training epoch 2355\n",
      "train_loss:  1.1410668007817282e-05 train_R2 0.896108017416181\n",
      "finished training epoch 2356\n",
      "train_loss:  1.1439178975949243e-05 train_R2 0.9030117807599733\n",
      "finished training epoch 2357\n",
      "train_loss:  1.1282215558320137e-05 train_R2 0.9025120870951343\n",
      "finished training epoch 2358\n",
      "train_loss:  1.1312958613710983e-05 train_R2 0.9060427512335322\n",
      "finished training epoch 2359\n",
      "train_loss:  1.1058732894241042e-05 train_R2 0.8943627185518681\n",
      "finished training epoch 2360\n",
      "train_loss:  1.1465730072377224e-05 train_R2 0.8921181026599909\n",
      "finished training epoch 2361\n",
      "train_loss:  1.1444424053183717e-05 train_R2 0.9109098635060081\n",
      "finished training epoch 2362\n",
      "train_loss:  1.1444475837847302e-05 train_R2 0.8997763677251943\n",
      "finished training epoch 2363\n",
      "train_loss:  1.1169435591029512e-05 train_R2 0.885162632038252\n",
      "finished training epoch 2364\n",
      "train_loss:  1.14677828941584e-05 train_R2 0.9146580037683896\n",
      "finished training epoch 2365\n",
      "train_loss:  1.1434222757577122e-05 train_R2 0.9097649556353034\n",
      "finished training epoch 2366\n",
      "train_loss:  1.1101972851768336e-05 train_R2 0.8598969180587388\n",
      "finished training epoch 2367\n",
      "train_loss:  1.1062683004265524e-05 train_R2 0.8661139785242223\n",
      "finished training epoch 2368\n",
      "train_loss:  1.1345412117794173e-05 train_R2 0.8737070633847477\n",
      "finished training epoch 2369\n",
      "train_loss:  1.1249470151376581e-05 train_R2 0.915329622268625\n",
      "finished training epoch 2370\n",
      "train_loss:  1.1541289719707001e-05 train_R2 0.8863111683644377\n",
      "finished training epoch 2371\n",
      "train_loss:  1.1484169176493232e-05 train_R2 0.8991985301706371\n",
      "finished training epoch 2372\n",
      "train_loss:  1.1578959538846211e-05 train_R2 0.8633270998505668\n",
      "finished training epoch 2373\n",
      "train_loss:  1.1134039042707917e-05 train_R2 0.9147380250921056\n",
      "finished training epoch 2374\n",
      "train_loss:  1.1448166838476785e-05 train_R2 0.9157516913160454\n",
      "finished training epoch 2375\n",
      "train_loss:  1.1433362323250035e-05 train_R2 0.898622905621531\n",
      "finished training epoch 2376\n",
      "train_loss:  1.1378153699483625e-05 train_R2 0.9066437056867317\n",
      "finished training epoch 2377\n",
      "train_loss:  1.1405674911068393e-05 train_R2 0.8723829499016458\n",
      "finished training epoch 2378\n",
      "train_loss:  1.1419199067848655e-05 train_R2 0.8856454062408946\n",
      "finished training epoch 2379\n",
      "train_loss:  1.1432858893534934e-05 train_R2 0.8884315306563032\n",
      "finished training epoch 2380\n",
      "train_loss:  1.1292254814834809e-05 train_R2 0.91409933777421\n",
      "finished training epoch 2381\n",
      "train_loss:  1.1332257450960347e-05 train_R2 0.9020338691938364\n",
      "finished training epoch 2382\n",
      "train_loss:  1.155612116645408e-05 train_R2 0.9023548976028736\n",
      "finished training epoch 2383\n",
      "train_loss:  1.1390014052055436e-05 train_R2 0.908303882677291\n",
      "finished training epoch 2384\n",
      "train_loss:  1.1200066103085661e-05 train_R2 0.897301930093785\n",
      "finished training epoch 2385\n",
      "train_loss:  1.1388383743661552e-05 train_R2 0.8755697545228811\n",
      "finished training epoch 2386\n",
      "train_loss:  1.1183508812242676e-05 train_R2 0.8627818458146533\n",
      "finished training epoch 2387\n",
      "train_loss:  1.1322190672436432e-05 train_R2 0.9299016217969667\n",
      "finished training epoch 2388\n",
      "train_loss:  1.1572561887615575e-05 train_R2 0.9212261592428509\n",
      "finished training epoch 2389\n",
      "train_loss:  1.1338639411699255e-05 train_R2 0.9029087150713808\n",
      "finished training epoch 2390\n",
      "train_loss:  1.123601810734379e-05 train_R2 0.8720286283789473\n",
      "finished training epoch 2391\n",
      "train_loss:  1.1092733441145997e-05 train_R2 0.9043875194910856\n",
      "finished training epoch 2392\n",
      "train_loss:  1.1287434012618534e-05 train_R2 0.9086646981450126\n",
      "finished training epoch 2393\n",
      "train_loss:  1.1367934549608535e-05 train_R2 0.8715946582503189\n",
      "finished training epoch 2394\n",
      "train_loss:  1.1107034278680287e-05 train_R2 0.8874457013992516\n",
      "finished training epoch 2395\n",
      "train_loss:  1.1252287388055927e-05 train_R2 0.9111206545248896\n",
      "finished training epoch 2396\n",
      "train_loss:  1.1401999312346744e-05 train_R2 0.9137891084888239\n",
      "finished training epoch 2397\n",
      "train_loss:  1.1175075980147906e-05 train_R2 0.8738198385231439\n",
      "finished training epoch 2398\n",
      "train_loss:  1.1368863792458417e-05 train_R2 0.9198927563848744\n",
      "finished training epoch 2399\n",
      "train_loss:  1.1337130153568526e-05 train_R2 0.9079704077859208\n",
      "finished training epoch 2400\n",
      "train_loss:  1.1258510645152385e-05 train_R2 0.9268274426212498\n",
      "finished training epoch 2401\n",
      "train_loss:  1.1377483305981238e-05 train_R2 0.9029382600801628\n",
      "finished training epoch 2402\n",
      "train_loss:  1.1222007412697535e-05 train_R2 0.8966330436907735\n",
      "finished training epoch 2403\n",
      "train_loss:  1.1184040466581568e-05 train_R2 0.8526469523114624\n",
      "finished training epoch 2404\n",
      "train_loss:  1.1241560125675628e-05 train_R2 0.9162980978192967\n",
      "finished training epoch 2405\n",
      "train_loss:  1.1263970165232744e-05 train_R2 0.9124002578063964\n",
      "finished training epoch 2406\n",
      "train_loss:  1.1462386983051394e-05 train_R2 0.9121865590795035\n",
      "finished training epoch 2407\n",
      "train_loss:  1.13524116107239e-05 train_R2 0.9204102009979831\n",
      "finished training epoch 2408\n",
      "train_loss:  1.1111385199759741e-05 train_R2 0.920183987969992\n",
      "finished training epoch 2409\n",
      "train_loss:  1.109470747292888e-05 train_R2 0.8909080761517894\n",
      "finished training epoch 2410\n",
      "train_loss:  1.126614409883494e-05 train_R2 0.9137417933959305\n",
      "finished training epoch 2411\n",
      "train_loss:  1.0946366447809634e-05 train_R2 0.9139992791807848\n",
      "finished training epoch 2412\n",
      "train_loss:  1.114286761782768e-05 train_R2 0.9289437211955208\n",
      "finished training epoch 2413\n",
      "train_loss:  1.1302605098821346e-05 train_R2 0.9007358161982725\n",
      "finished training epoch 2414\n",
      "train_loss:  1.1176003722127921e-05 train_R2 0.869115806991713\n",
      "finished training epoch 2415\n",
      "train_loss:  1.119635000034876e-05 train_R2 0.8803038172546347\n",
      "finished training epoch 2416\n",
      "train_loss:  1.113580313210599e-05 train_R2 0.897683797560786\n",
      "finished training epoch 2417\n",
      "train_loss:  1.1270240344406856e-05 train_R2 0.8954021817351678\n",
      "finished training epoch 2418\n",
      "train_loss:  1.113120467140898e-05 train_R2 0.8893904522125292\n",
      "finished training epoch 2419\n",
      "train_loss:  1.1100946814198206e-05 train_R2 0.895428505883619\n",
      "finished training epoch 2420\n",
      "train_loss:  1.1277345492244911e-05 train_R2 0.8993258685748226\n",
      "finished training epoch 2421\n",
      "train_loss:  1.1161639166750035e-05 train_R2 0.9325701429367198\n",
      "finished training epoch 2422\n",
      "train_loss:  1.0987958558403634e-05 train_R2 0.8870707819433719\n",
      "finished training epoch 2423\n",
      "train_loss:  1.1260336242362648e-05 train_R2 0.8796947689012595\n",
      "finished training epoch 2424\n",
      "train_loss:  1.119432356563985e-05 train_R2 0.9118883003470835\n",
      "finished training epoch 2425\n",
      "train_loss:  1.13938747249587e-05 train_R2 0.8711578978035182\n",
      "finished training epoch 2426\n",
      "train_loss:  1.0980448469511017e-05 train_R2 0.9082281984798285\n",
      "finished training epoch 2427\n",
      "train_loss:  1.1014424872569083e-05 train_R2 0.917819998763708\n",
      "finished training epoch 2428\n",
      "train_loss:  1.1135314308547606e-05 train_R2 0.8831704379241916\n",
      "finished training epoch 2429\n",
      "train_loss:  1.1166306115465019e-05 train_R2 0.8792614141208169\n",
      "finished training epoch 2430\n",
      "train_loss:  1.1157423810123651e-05 train_R2 0.9165435301987631\n",
      "finished training epoch 2431\n",
      "train_loss:  1.1512678480860957e-05 train_R2 0.877295909988153\n",
      "finished training epoch 2432\n",
      "train_loss:  1.12088218887147e-05 train_R2 0.9161997224489266\n",
      "finished training epoch 2433\n",
      "train_loss:  1.1143200369364243e-05 train_R2 0.9200113485936832\n",
      "finished training epoch 2434\n",
      "train_loss:  1.1386876746312668e-05 train_R2 0.9098251729441366\n",
      "finished training epoch 2435\n",
      "train_loss:  1.1171167292244722e-05 train_R2 0.9084260522626826\n",
      "finished training epoch 2436\n",
      "train_loss:  1.1330352798445465e-05 train_R2 0.9340741988089417\n",
      "finished training epoch 2437\n",
      "train_loss:  1.1222438549222604e-05 train_R2 0.9033316980275758\n",
      "finished training epoch 2438\n",
      "train_loss:  1.1189540295727506e-05 train_R2 0.8852458628948328\n",
      "finished training epoch 2439\n",
      "train_loss:  1.1328552336348805e-05 train_R2 0.8467546689543849\n",
      "finished training epoch 2440\n",
      "train_loss:  1.1379432590856446e-05 train_R2 0.9098889426585439\n",
      "finished training epoch 2441\n",
      "train_loss:  1.0996754467368288e-05 train_R2 0.887767324041771\n",
      "finished training epoch 2442\n",
      "train_loss:  1.1297014343008615e-05 train_R2 0.8803499254085081\n",
      "finished training epoch 2443\n",
      "train_loss:  1.0925861766230788e-05 train_R2 0.9032375641439652\n",
      "finished training epoch 2444\n",
      "train_loss:  1.1536986736865487e-05 train_R2 0.8690950147362004\n",
      "finished training epoch 2445\n",
      "train_loss:  1.1370071671373173e-05 train_R2 0.8776439037878596\n",
      "finished training epoch 2446\n",
      "train_loss:  1.1559108794359833e-05 train_R2 0.8765268454949897\n",
      "finished training epoch 2447\n",
      "train_loss:  1.1244315968191457e-05 train_R2 0.9208113911421745\n",
      "finished training epoch 2448\n",
      "train_loss:  1.1342720268023314e-05 train_R2 0.9181212331199895\n",
      "finished training epoch 2449\n",
      "train_loss:  1.0970535361986366e-05 train_R2 0.9176527919646272\n",
      "finished training epoch 2450\n",
      "train_loss:  1.1148809162532651e-05 train_R2 0.9144377150613526\n",
      "finished training epoch 2451\n",
      "train_loss:  1.1324458304187536e-05 train_R2 0.905749257219933\n",
      "finished training epoch 2452\n",
      "train_loss:  1.099221123092126e-05 train_R2 0.9090523196331753\n",
      "finished training epoch 2453\n",
      "train_loss:  1.1420982179702199e-05 train_R2 0.9266508430477299\n",
      "finished training epoch 2454\n",
      "train_loss:  1.125769301465322e-05 train_R2 0.9009498093577532\n",
      "finished training epoch 2455\n",
      "train_loss:  1.1317758101094365e-05 train_R2 0.9018237218743594\n",
      "finished training epoch 2456\n",
      "train_loss:  1.1150324214427344e-05 train_R2 0.8716741826932802\n",
      "finished training epoch 2457\n",
      "train_loss:  1.118138730300973e-05 train_R2 0.9045308225006428\n",
      "finished training epoch 2458\n",
      "train_loss:  1.1218450990106374e-05 train_R2 0.8939643164880775\n",
      "finished training epoch 2459\n",
      "train_loss:  1.0943681216873026e-05 train_R2 0.8837530915921786\n",
      "finished training epoch 2460\n",
      "train_loss:  1.1095538321755141e-05 train_R2 0.9035599840204712\n",
      "finished training epoch 2461\n",
      "train_loss:  1.1212192703467402e-05 train_R2 0.878314848571108\n",
      "finished training epoch 2462\n",
      "train_loss:  1.1475817859166035e-05 train_R2 0.918402943376081\n",
      "finished training epoch 2463\n",
      "train_loss:  1.1347617144283454e-05 train_R2 0.9228419746476727\n",
      "finished training epoch 2464\n",
      "train_loss:  1.1130990256160388e-05 train_R2 0.8723016077128518\n",
      "finished training epoch 2465\n",
      "train_loss:  1.1329380987823364e-05 train_R2 0.850368445269112\n",
      "finished training epoch 2466\n",
      "train_loss:  1.1181346049215103e-05 train_R2 0.8666173792033874\n",
      "finished training epoch 2467\n",
      "train_loss:  1.1270627232270467e-05 train_R2 0.8780497380471187\n",
      "finished training epoch 2468\n",
      "train_loss:  1.1340810328245076e-05 train_R2 0.8784356748153193\n",
      "finished training epoch 2469\n",
      "train_loss:  1.1298813784275305e-05 train_R2 0.8919217990405418\n",
      "finished training epoch 2470\n",
      "train_loss:  1.1155486935531463e-05 train_R2 0.8992621574564448\n",
      "finished training epoch 2471\n",
      "train_loss:  1.1278177109530634e-05 train_R2 0.8934914186193863\n",
      "finished training epoch 2472\n",
      "train_loss:  1.1369619443461329e-05 train_R2 0.8889172849074188\n",
      "finished training epoch 2473\n",
      "train_loss:  1.1357292930788543e-05 train_R2 0.9331563606442413\n",
      "finished training epoch 2474\n",
      "train_loss:  1.1241933294095054e-05 train_R2 0.8999853165010487\n",
      "finished training epoch 2475\n",
      "train_loss:  1.118108835687647e-05 train_R2 0.8860187971023626\n",
      "finished training epoch 2476\n",
      "train_loss:  1.1193314747697866e-05 train_R2 0.9107221138254585\n",
      "finished training epoch 2477\n",
      "train_loss:  1.1410760537906808e-05 train_R2 0.9188167684758142\n",
      "finished training epoch 2478\n",
      "train_loss:  1.1288086303976634e-05 train_R2 0.8969364269277339\n",
      "finished training epoch 2479\n",
      "train_loss:  1.0997389415428919e-05 train_R2 0.869602074848524\n",
      "finished training epoch 2480\n",
      "train_loss:  1.1672750766487613e-05 train_R2 0.890580618756142\n",
      "finished training epoch 2481\n",
      "train_loss:  1.1346920337007043e-05 train_R2 0.8842082546360701\n",
      "finished training epoch 2482\n",
      "train_loss:  1.125032192537328e-05 train_R2 0.9245741806277771\n",
      "finished training epoch 2483\n",
      "train_loss:  1.1206164603173765e-05 train_R2 0.8939927832200703\n",
      "finished training epoch 2484\n",
      "train_loss:  1.1228914581935838e-05 train_R2 0.919649037984818\n",
      "finished training epoch 2485\n",
      "train_loss:  1.1230839018296223e-05 train_R2 0.9231347636993065\n",
      "finished training epoch 2486\n",
      "train_loss:  1.1267313421655609e-05 train_R2 0.883464417715006\n",
      "finished training epoch 2487\n",
      "train_loss:  1.1076616020490432e-05 train_R2 0.9033160592440226\n",
      "finished training epoch 2488\n",
      "train_loss:  1.1060492321317124e-05 train_R2 0.9251939865164581\n",
      "finished training epoch 2489\n",
      "train_loss:  1.1347891735210448e-05 train_R2 0.903604744975474\n",
      "finished training epoch 2490\n",
      "train_loss:  1.1365036202827456e-05 train_R2 0.8943550535097614\n",
      "finished training epoch 2491\n",
      "train_loss:  1.1264692199248274e-05 train_R2 0.8661659394948135\n",
      "finished training epoch 2492\n",
      "train_loss:  1.1232036657698602e-05 train_R2 0.9074585774532692\n",
      "finished training epoch 2493\n",
      "train_loss:  1.1351349240903472e-05 train_R2 0.901659683072305\n",
      "finished training epoch 2494\n",
      "train_loss:  1.1282984109393822e-05 train_R2 0.8878301265965485\n",
      "finished training epoch 2495\n",
      "train_loss:  1.1223159328631547e-05 train_R2 0.9082051182966775\n",
      "finished training epoch 2496\n",
      "train_loss:  1.1193598903797253e-05 train_R2 0.8627570953687639\n",
      "finished training epoch 2497\n",
      "train_loss:  1.1540298842198395e-05 train_R2 0.8560993846592696\n",
      "finished training epoch 2498\n",
      "train_loss:  1.122782490950173e-05 train_R2 0.9179324861307133\n",
      "finished training epoch 2499\n",
      "train_loss:  1.0844263142119026e-05 train_R2 0.8998326838291221\n",
      "finished training epoch 2500\n",
      "train_loss:  1.1298828044583651e-05 train_R2 0.9398557184851719\n",
      "finished training epoch 2501\n",
      "train_loss:  1.133562110208681e-05 train_R2 0.8760109903515713\n",
      "finished training epoch 2502\n",
      "train_loss:  1.1496232332340373e-05 train_R2 0.9284816601450493\n",
      "finished training epoch 2503\n",
      "train_loss:  1.099422965679393e-05 train_R2 0.9239639924672828\n",
      "finished training epoch 2504\n",
      "train_loss:  1.1566147231509718e-05 train_R2 0.9226098585273377\n",
      "finished training epoch 2505\n",
      "train_loss:  1.113848274351488e-05 train_R2 0.9111847989057679\n",
      "finished training epoch 2506\n",
      "train_loss:  1.0998632794689988e-05 train_R2 0.9196368286764257\n",
      "finished training epoch 2507\n",
      "train_loss:  1.0994041260223831e-05 train_R2 0.9171493621514606\n",
      "finished training epoch 2508\n",
      "train_loss:  1.1201171674147762e-05 train_R2 0.8940053328878773\n",
      "finished training epoch 2509\n",
      "train_loss:  1.0850886379105006e-05 train_R2 0.9284095274256903\n",
      "finished training epoch 2510\n",
      "train_loss:  1.1404223380373233e-05 train_R2 0.8743604867320115\n",
      "finished training epoch 2511\n",
      "train_loss:  1.1190892175499367e-05 train_R2 0.8929891897876551\n",
      "finished training epoch 2512\n",
      "train_loss:  1.1154946684946194e-05 train_R2 0.8499278319263639\n",
      "finished training epoch 2513\n",
      "train_loss:  1.1129381983483755e-05 train_R2 0.9114155742055033\n",
      "finished training epoch 2514\n",
      "train_loss:  1.1153758974053208e-05 train_R2 0.8835580471687577\n",
      "finished training epoch 2515\n",
      "train_loss:  1.1276146874880805e-05 train_R2 0.9252816439101342\n",
      "finished training epoch 2516\n",
      "train_loss:  1.1444167032847978e-05 train_R2 0.918662580901276\n",
      "finished training epoch 2517\n",
      "train_loss:  1.126335358676763e-05 train_R2 0.9063042647313263\n",
      "finished training epoch 2518\n",
      "train_loss:  1.1269905529736723e-05 train_R2 0.927973607655042\n",
      "finished training epoch 2519\n",
      "train_loss:  1.150460978668398e-05 train_R2 0.9154385039290867\n",
      "finished training epoch 2520\n",
      "train_loss:  1.1307266769965134e-05 train_R2 0.8485235756960707\n",
      "finished training epoch 2521\n",
      "train_loss:  1.1273662946303241e-05 train_R2 0.9104262413266566\n",
      "finished training epoch 2522\n",
      "train_loss:  1.137106301720919e-05 train_R2 0.905917903703888\n",
      "finished training epoch 2523\n",
      "train_loss:  1.1120973010955573e-05 train_R2 0.9169297487917097\n",
      "finished training epoch 2524\n",
      "train_loss:  1.1139580813805816e-05 train_R2 0.8955896226479345\n",
      "finished training epoch 2525\n",
      "train_loss:  1.1168545575471883e-05 train_R2 0.9059825123156751\n",
      "finished training epoch 2526\n",
      "train_loss:  1.120553106085401e-05 train_R2 0.8962887683324018\n",
      "finished training epoch 2527\n",
      "train_loss:  1.1146207294178262e-05 train_R2 0.9195796177255847\n",
      "finished training epoch 2528\n",
      "train_loss:  1.1304971520293618e-05 train_R2 0.8618716377007931\n",
      "finished training epoch 2529\n",
      "train_loss:  1.144797207000212e-05 train_R2 0.8907190780337703\n",
      "finished training epoch 2530\n",
      "train_loss:  1.1147751871608757e-05 train_R2 0.9378078434437853\n",
      "finished training epoch 2531\n",
      "train_loss:  1.1221802564811138e-05 train_R2 0.9119810525970795\n",
      "finished training epoch 2532\n",
      "train_loss:  1.1268640939428853e-05 train_R2 0.9314018384943752\n",
      "finished training epoch 2533\n",
      "train_loss:  1.115651919138007e-05 train_R2 0.9029253471239055\n",
      "finished training epoch 2534\n",
      "train_loss:  1.1004439429931523e-05 train_R2 0.881934904033848\n",
      "finished training epoch 2535\n",
      "train_loss:  1.1259583844530004e-05 train_R2 0.9318028300896523\n",
      "finished training epoch 2536\n",
      "train_loss:  1.1338789968689637e-05 train_R2 0.9210043963440876\n",
      "finished training epoch 2537\n",
      "train_loss:  1.1268924379081419e-05 train_R2 0.9056326406712358\n",
      "finished training epoch 2538\n",
      "train_loss:  1.121387916576672e-05 train_R2 0.9105789079394868\n",
      "finished training epoch 2539\n",
      "train_loss:  1.1053293408863858e-05 train_R2 0.9145664998254699\n",
      "finished training epoch 2540\n",
      "train_loss:  1.1078794187385001e-05 train_R2 0.9282468031051\n",
      "finished training epoch 2541\n",
      "train_loss:  1.1159462381020156e-05 train_R2 0.9162072052467083\n",
      "finished training epoch 2542\n",
      "train_loss:  1.1195214319041677e-05 train_R2 0.8889434719790595\n",
      "finished training epoch 2543\n",
      "train_loss:  1.1282000152003438e-05 train_R2 0.9166091773819371\n",
      "finished training epoch 2544\n",
      "train_loss:  1.0870657220697107e-05 train_R2 0.8869234042943364\n",
      "finished training epoch 2545\n",
      "train_loss:  1.1188271513361556e-05 train_R2 0.9179516500968704\n",
      "finished training epoch 2546\n",
      "train_loss:  1.1233793824098305e-05 train_R2 0.8717695192830012\n",
      "finished training epoch 2547\n",
      "train_loss:  1.1133706797227408e-05 train_R2 0.9143213511609268\n",
      "finished training epoch 2548\n",
      "train_loss:  1.1065967805969219e-05 train_R2 0.9138687802350329\n",
      "finished training epoch 2549\n",
      "train_loss:  1.1268085001775468e-05 train_R2 0.8878727938720907\n",
      "finished training epoch 2550\n",
      "train_loss:  1.1079443482853195e-05 train_R2 0.9160202926171126\n",
      "finished training epoch 2551\n",
      "train_loss:  1.1005497708795734e-05 train_R2 0.9321918864696144\n",
      "finished training epoch 2552\n",
      "train_loss:  1.1268684241498457e-05 train_R2 0.9132344538085698\n",
      "finished training epoch 2553\n",
      "train_loss:  1.1291934951189901e-05 train_R2 0.8731225309587617\n",
      "finished training epoch 2554\n",
      "train_loss:  1.1196962228850488e-05 train_R2 0.9068747734477188\n",
      "finished training epoch 2555\n",
      "train_loss:  1.1422844755351994e-05 train_R2 0.9029147604971601\n",
      "finished training epoch 2556\n",
      "train_loss:  1.100923464591259e-05 train_R2 0.9208504264199868\n",
      "finished training epoch 2557\n",
      "train_loss:  1.1351872938320784e-05 train_R2 0.9171171999130653\n",
      "finished training epoch 2558\n",
      "train_loss:  1.1005050879581012e-05 train_R2 0.9209905252180967\n",
      "finished training epoch 2559\n",
      "train_loss:  1.1187421600969112e-05 train_R2 0.8963420214981067\n",
      "finished training epoch 2560\n",
      "train_loss:  1.098097969562871e-05 train_R2 0.880857329284724\n",
      "finished training epoch 2561\n",
      "train_loss:  1.1186199543243146e-05 train_R2 0.9068371616613796\n",
      "finished training epoch 2562\n",
      "train_loss:  1.116037180786075e-05 train_R2 0.9235841673390947\n",
      "finished training epoch 2563\n",
      "train_loss:  1.0951730092570336e-05 train_R2 0.9158523334138643\n",
      "finished training epoch 2564\n",
      "train_loss:  1.0986262935580097e-05 train_R2 0.8849726681132206\n",
      "finished training epoch 2565\n",
      "train_loss:  1.1141822065858186e-05 train_R2 0.8642725463302285\n",
      "finished training epoch 2566\n",
      "train_loss:  1.1149617344554215e-05 train_R2 0.8934652270421704\n",
      "finished training epoch 2567\n",
      "train_loss:  1.1056435228062525e-05 train_R2 0.9012035834408535\n",
      "finished training epoch 2568\n",
      "train_loss:  1.1174695710513641e-05 train_R2 0.8859516667544967\n",
      "finished training epoch 2569\n",
      "train_loss:  1.1077894641195962e-05 train_R2 0.9273564452048276\n",
      "finished training epoch 2570\n",
      "train_loss:  1.1170527143406728e-05 train_R2 0.9086681979394096\n",
      "finished training epoch 2571\n",
      "train_loss:  1.1141884332037456e-05 train_R2 0.9137964533032943\n",
      "finished training epoch 2572\n",
      "train_loss:  1.1268021574248293e-05 train_R2 0.9105238019003148\n",
      "finished training epoch 2573\n",
      "train_loss:  1.1148197875149328e-05 train_R2 0.9208128699360748\n",
      "finished training epoch 2574\n",
      "train_loss:  1.1130665801528443e-05 train_R2 0.8651931297256688\n",
      "finished training epoch 2575\n",
      "train_loss:  1.1152442319231747e-05 train_R2 0.9133084653239875\n",
      "finished training epoch 2576\n",
      "train_loss:  1.1319832206335902e-05 train_R2 0.8765102885628656\n",
      "finished training epoch 2577\n",
      "train_loss:  1.1061876250112615e-05 train_R2 0.8677590246933108\n",
      "finished training epoch 2578\n",
      "train_loss:  1.1236979526640596e-05 train_R2 0.9250862906214361\n",
      "finished training epoch 2579\n",
      "train_loss:  1.1294276040565545e-05 train_R2 0.9085721763900705\n",
      "finished training epoch 2580\n",
      "train_loss:  1.1336265180050666e-05 train_R2 0.8826933407500324\n",
      "finished training epoch 2581\n",
      "train_loss:  1.1188945061698114e-05 train_R2 0.8920801653296896\n",
      "finished training epoch 2582\n",
      "train_loss:  1.1376552102060119e-05 train_R2 0.8974043478503259\n",
      "finished training epoch 2583\n",
      "train_loss:  1.132356401592675e-05 train_R2 0.8844570143978538\n",
      "finished training epoch 2584\n",
      "train_loss:  1.1451329116428364e-05 train_R2 0.870335219007821\n",
      "finished training epoch 2585\n",
      "train_loss:  1.1387178934207604e-05 train_R2 0.919995452373667\n",
      "finished training epoch 2586\n",
      "train_loss:  1.1173643405896073e-05 train_R2 0.901061956738646\n",
      "finished training epoch 2587\n",
      "train_loss:  1.1338880086448606e-05 train_R2 0.9140298994050081\n",
      "finished training epoch 2588\n",
      "train_loss:  1.1005594813370166e-05 train_R2 0.8946529171671838\n",
      "finished training epoch 2589\n",
      "train_loss:  1.1133232282134746e-05 train_R2 0.9121000700191985\n",
      "finished training epoch 2590\n",
      "train_loss:  1.1122852840454456e-05 train_R2 0.8809663966678829\n",
      "finished training epoch 2591\n",
      "train_loss:  1.1233844470703244e-05 train_R2 0.9341360677195802\n",
      "finished training epoch 2592\n",
      "train_loss:  1.1152930282670399e-05 train_R2 0.93040817640898\n",
      "finished training epoch 2593\n",
      "train_loss:  1.1427302228877158e-05 train_R2 0.9123138109528316\n",
      "finished training epoch 2594\n",
      "train_loss:  1.1154211703911012e-05 train_R2 0.9081749444133885\n",
      "finished training epoch 2595\n",
      "train_loss:  1.0810937623051035e-05 train_R2 0.9166981813222465\n",
      "finished training epoch 2596\n",
      "train_loss:  1.129192079740205e-05 train_R2 0.9063243710845165\n",
      "finished training epoch 2597\n",
      "train_loss:  1.1210679366264666e-05 train_R2 0.8908872193385238\n",
      "finished training epoch 2598\n",
      "train_loss:  1.1221180273508525e-05 train_R2 0.9149855433118906\n",
      "finished training epoch 2599\n",
      "train_loss:  1.1331021461584492e-05 train_R2 0.9178259696751845\n",
      "finished training epoch 2600\n",
      "train_loss:  1.115827945532703e-05 train_R2 0.8920020861123688\n",
      "finished training epoch 2601\n",
      "train_loss:  1.1167803997220183e-05 train_R2 0.895175932700026\n",
      "finished training epoch 2602\n",
      "train_loss:  1.1428782649622516e-05 train_R2 0.9220807874131289\n",
      "finished training epoch 2603\n",
      "train_loss:  1.0955441090692711e-05 train_R2 0.8907443984704249\n",
      "finished training epoch 2604\n",
      "train_loss:  1.1286086969548715e-05 train_R2 0.9116760965886844\n",
      "finished training epoch 2605\n",
      "train_loss:  1.1160397462109154e-05 train_R2 0.9180306754193868\n",
      "finished training epoch 2606\n",
      "train_loss:  1.1397158136783453e-05 train_R2 0.8636111134107279\n",
      "finished training epoch 2607\n",
      "train_loss:  1.1215940317886634e-05 train_R2 0.9030479242434887\n",
      "finished training epoch 2608\n",
      "train_loss:  1.1137640111040757e-05 train_R2 0.8969673497586065\n",
      "finished training epoch 2609\n",
      "train_loss:  1.1308264334479238e-05 train_R2 0.8979397480786381\n",
      "finished training epoch 2610\n",
      "train_loss:  1.1342034075972163e-05 train_R2 0.889419130372983\n",
      "finished training epoch 2611\n",
      "train_loss:  1.124032091065706e-05 train_R2 0.9186414127067001\n",
      "finished training epoch 2612\n",
      "train_loss:  1.1289522922972202e-05 train_R2 0.9208626931437415\n",
      "finished training epoch 2613\n",
      "train_loss:  1.1269002317733679e-05 train_R2 0.9058941190226701\n",
      "finished training epoch 2614\n",
      "train_loss:  1.1258717458915218e-05 train_R2 0.9204431390400402\n",
      "finished training epoch 2615\n",
      "train_loss:  1.138260923632158e-05 train_R2 0.8996626752687628\n",
      "finished training epoch 2616\n",
      "train_loss:  1.1289036714051793e-05 train_R2 0.9166830305200065\n",
      "finished training epoch 2617\n",
      "train_loss:  1.1363099677354394e-05 train_R2 0.9035516804529291\n",
      "finished training epoch 2618\n",
      "train_loss:  1.0991959790224398e-05 train_R2 0.8958179998554138\n",
      "finished training epoch 2619\n",
      "train_loss:  1.1303498310687046e-05 train_R2 0.9028218815951505\n",
      "finished training epoch 2620\n",
      "train_loss:  1.1176952819241114e-05 train_R2 0.9265366324021153\n",
      "finished training epoch 2621\n",
      "train_loss:  1.1229599696033685e-05 train_R2 0.85835103915914\n",
      "finished training epoch 2622\n",
      "train_loss:  1.1221294707249659e-05 train_R2 0.9175409112772753\n",
      "finished training epoch 2623\n",
      "train_loss:  1.1065994083478003e-05 train_R2 0.8876996815916801\n",
      "finished training epoch 2624\n",
      "train_loss:  1.1262578762346777e-05 train_R2 0.905381836791898\n",
      "finished training epoch 2625\n",
      "train_loss:  1.1341463272596594e-05 train_R2 0.9283728175421555\n",
      "finished training epoch 2626\n",
      "train_loss:  1.120100156902127e-05 train_R2 0.8902521328331373\n",
      "finished training epoch 2627\n",
      "train_loss:  1.1193106091303917e-05 train_R2 0.8905447325807108\n",
      "finished training epoch 2628\n",
      "train_loss:  1.1116005218906379e-05 train_R2 0.8911430828221389\n",
      "finished training epoch 2629\n",
      "train_loss:  1.1278507250178675e-05 train_R2 0.9327306593593588\n",
      "finished training epoch 2630\n",
      "train_loss:  1.1071670245853348e-05 train_R2 0.9046980721712358\n",
      "finished training epoch 2631\n",
      "train_loss:  1.0905224288204196e-05 train_R2 0.9322103146847361\n",
      "finished training epoch 2632\n",
      "train_loss:  1.115637630460096e-05 train_R2 0.9255448866838308\n",
      "finished training epoch 2633\n",
      "train_loss:  1.1150703424281486e-05 train_R2 0.8780908665906149\n",
      "finished training epoch 2634\n",
      "train_loss:  1.1275076646714687e-05 train_R2 0.8843581644253513\n",
      "finished training epoch 2635\n",
      "train_loss:  1.1006992801906414e-05 train_R2 0.8866858924902129\n",
      "finished training epoch 2636\n",
      "train_loss:  1.1134463437361644e-05 train_R2 0.8977938641347571\n",
      "finished training epoch 2637\n",
      "train_loss:  1.140903607719497e-05 train_R2 0.9017828849536312\n",
      "finished training epoch 2638\n",
      "train_loss:  1.122505982282845e-05 train_R2 0.8841921568941337\n",
      "finished training epoch 2639\n",
      "train_loss:  1.1148111953159598e-05 train_R2 0.9121652757835423\n",
      "finished training epoch 2640\n",
      "train_loss:  1.1378452578399767e-05 train_R2 0.9055209686684151\n",
      "finished training epoch 2641\n",
      "train_loss:  1.1206374876119478e-05 train_R2 0.9249130726540445\n",
      "finished training epoch 2642\n",
      "train_loss:  1.1382814254519134e-05 train_R2 0.9085906561233071\n",
      "finished training epoch 2643\n",
      "train_loss:  1.1293157799535634e-05 train_R2 0.9182095597788119\n",
      "finished training epoch 2644\n",
      "train_loss:  1.1370604117776818e-05 train_R2 0.9150511862946833\n",
      "finished training epoch 2645\n",
      "train_loss:  1.1109936474915443e-05 train_R2 0.9029764615161253\n",
      "finished training epoch 2646\n",
      "train_loss:  1.1123141826851577e-05 train_R2 0.88638829043533\n",
      "finished training epoch 2647\n",
      "train_loss:  1.1178024280246816e-05 train_R2 0.9097782305951585\n",
      "finished training epoch 2648\n",
      "train_loss:  1.104302642612933e-05 train_R2 0.918853046091056\n",
      "finished training epoch 2649\n",
      "train_loss:  1.1354029127648666e-05 train_R2 0.9089617090146114\n",
      "finished training epoch 2650\n",
      "train_loss:  1.12572584165506e-05 train_R2 0.8882881948818823\n",
      "finished training epoch 2651\n",
      "train_loss:  1.110343983132731e-05 train_R2 0.9211025915754997\n",
      "finished training epoch 2652\n",
      "train_loss:  1.1051255193239612e-05 train_R2 0.8844739778294035\n",
      "finished training epoch 2653\n",
      "train_loss:  1.1135045642481257e-05 train_R2 0.9058410459431581\n",
      "finished training epoch 2654\n",
      "train_loss:  1.1199589576461601e-05 train_R2 0.9053086621636651\n",
      "finished training epoch 2655\n",
      "train_loss:  1.1079357885336602e-05 train_R2 0.9026194713723679\n",
      "finished training epoch 2656\n",
      "train_loss:  1.1195281474907786e-05 train_R2 0.9082336470922728\n",
      "finished training epoch 2657\n",
      "train_loss:  1.1182171414185384e-05 train_R2 0.8699555953840745\n",
      "finished training epoch 2658\n",
      "train_loss:  1.1418415591902593e-05 train_R2 0.9019561101685662\n",
      "finished training epoch 2659\n",
      "train_loss:  1.0948960473761582e-05 train_R2 0.9228633453340973\n",
      "finished training epoch 2660\n",
      "train_loss:  1.1356425674277722e-05 train_R2 0.902961737110351\n",
      "finished training epoch 2661\n",
      "train_loss:  1.11670083479019e-05 train_R2 0.8753563007633121\n",
      "finished training epoch 2662\n",
      "train_loss:  1.119804082069886e-05 train_R2 0.914326411162224\n",
      "finished training epoch 2663\n",
      "train_loss:  1.1158706471208723e-05 train_R2 0.9055904356454487\n",
      "finished training epoch 2664\n",
      "train_loss:  1.1187437700671622e-05 train_R2 0.878484378742279\n",
      "finished training epoch 2665\n",
      "train_loss:  1.1160064880699117e-05 train_R2 0.8664286972470815\n",
      "finished training epoch 2666\n",
      "train_loss:  1.1075810263493494e-05 train_R2 0.90233679191402\n",
      "finished training epoch 2667\n",
      "train_loss:  1.1201372191044081e-05 train_R2 0.8994861030700096\n",
      "finished training epoch 2668\n",
      "train_loss:  1.1368045161445112e-05 train_R2 0.8852985258675815\n",
      "finished training epoch 2669\n",
      "train_loss:  1.1350098294335383e-05 train_R2 0.8848000462148959\n",
      "finished training epoch 2670\n",
      "train_loss:  1.0943272455589297e-05 train_R2 0.8535395029134336\n",
      "finished training epoch 2671\n",
      "train_loss:  1.1324277819518427e-05 train_R2 0.9077583516843393\n",
      "finished training epoch 2672\n",
      "train_loss:  1.1035385781681355e-05 train_R2 0.9010012819233149\n",
      "finished training epoch 2673\n",
      "train_loss:  1.1016092828886221e-05 train_R2 0.8657193056970532\n",
      "finished training epoch 2674\n",
      "train_loss:  1.1097894178885784e-05 train_R2 0.9069568619095785\n",
      "finished training epoch 2675\n",
      "train_loss:  1.1491345094841369e-05 train_R2 0.9162033608204616\n",
      "finished training epoch 2676\n",
      "train_loss:  1.1170121386535458e-05 train_R2 0.9282275382306032\n",
      "finished training epoch 2677\n",
      "train_loss:  1.1083852810070187e-05 train_R2 0.8994772033890355\n",
      "finished training epoch 2678\n",
      "train_loss:  1.0687969509376268e-05 train_R2 0.9041465503191328\n",
      "finished training epoch 2679\n",
      "train_loss:  1.1379031651502903e-05 train_R2 0.9024159562645256\n",
      "finished training epoch 2680\n",
      "train_loss:  1.1240064968513638e-05 train_R2 0.9263673853608364\n",
      "finished training epoch 2681\n",
      "train_loss:  1.1261199722658655e-05 train_R2 0.8815820751002466\n",
      "finished training epoch 2682\n",
      "train_loss:  1.1330443995103324e-05 train_R2 0.9170944813717083\n",
      "finished training epoch 2683\n",
      "train_loss:  1.0892505450393666e-05 train_R2 0.9115993045429893\n",
      "finished training epoch 2684\n",
      "train_loss:  1.0993607335916174e-05 train_R2 0.9138723418620036\n",
      "finished training epoch 2685\n",
      "train_loss:  1.1184803586464096e-05 train_R2 0.9047009009826853\n",
      "finished training epoch 2686\n",
      "train_loss:  1.1076014403264714e-05 train_R2 0.8889762396839965\n",
      "finished training epoch 2687\n",
      "train_loss:  1.1012807856100177e-05 train_R2 0.8928567482043896\n",
      "finished training epoch 2688\n",
      "train_loss:  1.128693512560291e-05 train_R2 0.8839728306654551\n",
      "finished training epoch 2689\n",
      "train_loss:  1.1348469572626885e-05 train_R2 0.8981469314374402\n",
      "finished training epoch 2690\n",
      "train_loss:  1.1529209563042874e-05 train_R2 0.8845947753454642\n",
      "finished training epoch 2691\n",
      "train_loss:  1.1118094938596522e-05 train_R2 0.9085659515028616\n",
      "finished training epoch 2692\n",
      "train_loss:  1.1207657653740617e-05 train_R2 0.877982877884371\n",
      "finished training epoch 2693\n",
      "train_loss:  1.0865876718055164e-05 train_R2 0.9112370439126599\n",
      "finished training epoch 2694\n",
      "train_loss:  1.1088969669130048e-05 train_R2 0.8770832162496488\n",
      "finished training epoch 2695\n",
      "train_loss:  1.1280122051281764e-05 train_R2 0.8994675650917698\n",
      "finished training epoch 2696\n",
      "train_loss:  1.1115155097278066e-05 train_R2 0.9010158385698699\n",
      "finished training epoch 2697\n",
      "train_loss:  1.0977530174385015e-05 train_R2 0.9053957203724734\n",
      "finished training epoch 2698\n",
      "train_loss:  1.1138018177673443e-05 train_R2 0.9259238968484722\n",
      "finished training epoch 2699\n",
      "train_loss:  1.1166400259788292e-05 train_R2 0.8925171855148951\n",
      "finished training epoch 2700\n",
      "train_loss:  1.1293204298433509e-05 train_R2 0.9083292933638146\n",
      "finished training epoch 2701\n",
      "train_loss:  1.1193662869384585e-05 train_R2 0.9122276599002326\n",
      "finished training epoch 2702\n",
      "train_loss:  1.1258977280958518e-05 train_R2 0.9113165461826881\n",
      "finished training epoch 2703\n",
      "train_loss:  1.1067848212400166e-05 train_R2 0.9033819074759949\n",
      "finished training epoch 2704\n",
      "train_loss:  1.1339864436352527e-05 train_R2 0.9180716616717508\n",
      "finished training epoch 2705\n",
      "train_loss:  1.1330505420228562e-05 train_R2 0.8953776253459318\n",
      "finished training epoch 2706\n",
      "train_loss:  1.1043853348103674e-05 train_R2 0.9127381407175846\n",
      "finished training epoch 2707\n",
      "train_loss:  1.1013672027694206e-05 train_R2 0.9024238366777142\n",
      "finished training epoch 2708\n",
      "train_loss:  1.1229867456678424e-05 train_R2 0.9154369636264262\n",
      "finished training epoch 2709\n",
      "train_loss:  1.0930853332642946e-05 train_R2 0.8895492750096632\n",
      "finished training epoch 2710\n",
      "train_loss:  1.131898235408886e-05 train_R2 0.9268378659667317\n",
      "finished training epoch 2711\n",
      "train_loss:  1.1016165788138778e-05 train_R2 0.901057273107184\n",
      "finished training epoch 2712\n",
      "train_loss:  1.1118270283030374e-05 train_R2 0.9232179921326089\n",
      "finished training epoch 2713\n",
      "train_loss:  1.0904704738694987e-05 train_R2 0.8975486512728589\n",
      "finished training epoch 2714\n",
      "train_loss:  1.129013487944678e-05 train_R2 0.8833208870932424\n",
      "finished training epoch 2715\n",
      "train_loss:  1.1094014510147806e-05 train_R2 0.8726688859850984\n",
      "finished training epoch 2716\n",
      "train_loss:  1.1213129216932607e-05 train_R2 0.8840171114202414\n",
      "finished training epoch 2717\n",
      "train_loss:  1.0946274202985862e-05 train_R2 0.8860695482826799\n",
      "finished training epoch 2718\n",
      "train_loss:  1.1333562338058348e-05 train_R2 0.8922333285556431\n",
      "finished training epoch 2719\n",
      "train_loss:  1.1019218077071862e-05 train_R2 0.8714788755750527\n",
      "finished training epoch 2720\n",
      "train_loss:  1.1259616342056882e-05 train_R2 0.8893147840916745\n",
      "finished training epoch 2721\n",
      "train_loss:  1.1084809163443974e-05 train_R2 0.9095561472075057\n",
      "finished training epoch 2722\n",
      "train_loss:  1.1135491759392367e-05 train_R2 0.9160511047882223\n",
      "finished training epoch 2723\n",
      "train_loss:  1.1348557956017735e-05 train_R2 0.8979661119242299\n",
      "finished training epoch 2724\n",
      "train_loss:  1.1352765454910938e-05 train_R2 0.916471460413129\n",
      "finished training epoch 2725\n",
      "train_loss:  1.1312994815845562e-05 train_R2 0.8743578183881898\n",
      "finished training epoch 2726\n",
      "train_loss:  1.0878558636477885e-05 train_R2 0.9222532768102505\n",
      "finished training epoch 2727\n",
      "train_loss:  1.1105229091363575e-05 train_R2 0.9173779053627366\n",
      "finished training epoch 2728\n",
      "train_loss:  1.09279475295445e-05 train_R2 0.9142646229814816\n",
      "finished training epoch 2729\n",
      "train_loss:  1.1236678009517508e-05 train_R2 0.8882529236228414\n",
      "finished training epoch 2730\n",
      "train_loss:  1.1226906327375804e-05 train_R2 0.8850885500866373\n",
      "finished training epoch 2731\n",
      "train_loss:  1.1195774707844398e-05 train_R2 0.8878157845063039\n",
      "finished training epoch 2732\n",
      "train_loss:  1.12248652006262e-05 train_R2 0.8623968094426963\n",
      "finished training epoch 2733\n",
      "train_loss:  1.0894144740563408e-05 train_R2 0.9051785250192165\n",
      "finished training epoch 2734\n",
      "train_loss:  1.1053101238753716e-05 train_R2 0.920022506741169\n",
      "finished training epoch 2735\n",
      "train_loss:  1.1290618736680745e-05 train_R2 0.8710776416663989\n",
      "finished training epoch 2736\n",
      "train_loss:  1.0793668825875942e-05 train_R2 0.9001881502890253\n",
      "finished training epoch 2737\n",
      "train_loss:  1.0797608954901297e-05 train_R2 0.9131763961280257\n",
      "finished training epoch 2738\n",
      "train_loss:  1.103743349115044e-05 train_R2 0.908602996437126\n",
      "finished training epoch 2739\n",
      "train_loss:  1.0974605202674964e-05 train_R2 0.8755317181245302\n",
      "finished training epoch 2740\n",
      "train_loss:  1.1317048239751581e-05 train_R2 0.9215690885375264\n",
      "finished training epoch 2741\n",
      "train_loss:  1.1168580115814871e-05 train_R2 0.9090079593547558\n",
      "finished training epoch 2742\n",
      "train_loss:  1.1055010401645642e-05 train_R2 0.8833245168301407\n",
      "finished training epoch 2743\n",
      "train_loss:  1.093710393130566e-05 train_R2 0.9002426674601117\n",
      "finished training epoch 2744\n",
      "train_loss:  1.1072081622553519e-05 train_R2 0.9213809412574787\n",
      "finished training epoch 2745\n",
      "train_loss:  1.111558570332084e-05 train_R2 0.9192811880851994\n",
      "finished training epoch 2746\n",
      "train_loss:  1.120534016041242e-05 train_R2 0.8929699750323731\n",
      "finished training epoch 2747\n",
      "train_loss:  1.0990206699844452e-05 train_R2 0.8971015420238259\n",
      "finished training epoch 2748\n",
      "train_loss:  1.101442120372197e-05 train_R2 0.8845207164036093\n",
      "finished training epoch 2749\n",
      "train_loss:  1.1230180322218362e-05 train_R2 0.8976926711109794\n",
      "finished training epoch 2750\n",
      "train_loss:  1.0973199910811424e-05 train_R2 0.9162793325472587\n",
      "finished training epoch 2751\n",
      "train_loss:  1.1069691238766887e-05 train_R2 0.9105500301664764\n",
      "finished training epoch 2752\n",
      "train_loss:  1.140222937584891e-05 train_R2 0.8862482192010616\n",
      "finished training epoch 2753\n",
      "train_loss:  1.1175547816986514e-05 train_R2 0.8912085437693715\n",
      "finished training epoch 2754\n",
      "train_loss:  1.1138460295632582e-05 train_R2 0.9015769448546299\n",
      "finished training epoch 2755\n",
      "train_loss:  1.0959302209310153e-05 train_R2 0.9300385583396488\n",
      "finished training epoch 2756\n",
      "train_loss:  1.1284955776264244e-05 train_R2 0.9101666319196873\n",
      "finished training epoch 2757\n",
      "train_loss:  1.1159815107072092e-05 train_R2 0.8939011024435134\n",
      "finished training epoch 2758\n",
      "train_loss:  1.1229033657371812e-05 train_R2 0.88897133883355\n",
      "finished training epoch 2759\n",
      "train_loss:  1.1179958850302308e-05 train_R2 0.8814222571016124\n",
      "finished training epoch 2760\n",
      "train_loss:  1.1277677061594568e-05 train_R2 0.8626213144230972\n",
      "finished training epoch 2761\n",
      "train_loss:  1.1296534413598855e-05 train_R2 0.8974332390034878\n",
      "finished training epoch 2762\n",
      "train_loss:  1.0940557680237974e-05 train_R2 0.9040031776238437\n",
      "finished training epoch 2763\n",
      "train_loss:  1.117817601669579e-05 train_R2 0.8931965798763656\n",
      "finished training epoch 2764\n",
      "train_loss:  1.1033688002707817e-05 train_R2 0.9046366257759614\n",
      "finished training epoch 2765\n",
      "train_loss:  1.1032390301887447e-05 train_R2 0.8986752688067853\n",
      "finished training epoch 2766\n",
      "train_loss:  1.1289360493868755e-05 train_R2 0.8877510306525319\n",
      "finished training epoch 2767\n",
      "train_loss:  1.1097894491919766e-05 train_R2 0.8863540803087233\n",
      "finished training epoch 2768\n",
      "train_loss:  1.1030361893709491e-05 train_R2 0.8960414038215994\n",
      "finished training epoch 2769\n",
      "train_loss:  1.0826392630538926e-05 train_R2 0.9211416878159077\n",
      "finished training epoch 2770\n",
      "train_loss:  1.1219073453202605e-05 train_R2 0.8567312010236955\n",
      "finished training epoch 2771\n",
      "train_loss:  1.1307309634060564e-05 train_R2 0.8988594261705728\n",
      "finished training epoch 2772\n",
      "train_loss:  1.0965122069332606e-05 train_R2 0.9046991661705605\n",
      "finished training epoch 2773\n",
      "train_loss:  1.105145935275348e-05 train_R2 0.9252208636903333\n",
      "finished training epoch 2774\n",
      "train_loss:  1.1083730435992187e-05 train_R2 0.8983771511132349\n",
      "finished training epoch 2775\n",
      "train_loss:  1.1193259492221414e-05 train_R2 0.8857746681052769\n",
      "finished training epoch 2776\n",
      "train_loss:  1.0876525982878697e-05 train_R2 0.8829008910769494\n",
      "finished training epoch 2777\n",
      "train_loss:  1.1001213491680784e-05 train_R2 0.9285053631609823\n",
      "finished training epoch 2778\n",
      "train_loss:  1.1044464821564825e-05 train_R2 0.9060965167902851\n",
      "finished training epoch 2779\n",
      "train_loss:  1.0960200886743545e-05 train_R2 0.9261904202009075\n",
      "finished training epoch 2780\n",
      "train_loss:  1.1186829915934804e-05 train_R2 0.9108235398604346\n",
      "finished training epoch 2781\n",
      "train_loss:  1.1059410682558661e-05 train_R2 0.9052483854162413\n",
      "finished training epoch 2782\n",
      "train_loss:  1.1058558636459077e-05 train_R2 0.9207580914537458\n",
      "finished training epoch 2783\n",
      "train_loss:  1.0969917133977249e-05 train_R2 0.8876146957220414\n",
      "finished training epoch 2784\n",
      "train_loss:  1.1144749780591404e-05 train_R2 0.8990807783192442\n",
      "finished training epoch 2785\n",
      "train_loss:  1.1336866086268236e-05 train_R2 0.8914871987454658\n",
      "finished training epoch 2786\n",
      "train_loss:  1.1085914490006112e-05 train_R2 0.9145419925274901\n",
      "finished training epoch 2787\n",
      "train_loss:  1.1182957798618906e-05 train_R2 0.90600894232655\n",
      "finished training epoch 2788\n",
      "train_loss:  1.1387566353286752e-05 train_R2 0.8980427346608165\n",
      "finished training epoch 2789\n",
      "train_loss:  1.0974720109936433e-05 train_R2 0.9070383543391031\n",
      "finished training epoch 2790\n",
      "train_loss:  1.1073725638432118e-05 train_R2 0.9280539970076133\n",
      "finished training epoch 2791\n",
      "train_loss:  1.127184479433385e-05 train_R2 0.8578461571795437\n",
      "finished training epoch 2792\n",
      "train_loss:  1.115745099474836e-05 train_R2 0.8999945807712612\n",
      "finished training epoch 2793\n",
      "train_loss:  1.0882657625762685e-05 train_R2 0.8872923275081558\n",
      "finished training epoch 2794\n",
      "train_loss:  1.0931342511062694e-05 train_R2 0.9004596351202157\n",
      "finished training epoch 2795\n",
      "train_loss:  1.117985739548313e-05 train_R2 0.8910562991878704\n",
      "finished training epoch 2796\n",
      "train_loss:  1.096105975914859e-05 train_R2 0.9365649490246437\n",
      "finished training epoch 2797\n",
      "train_loss:  1.0928617870866376e-05 train_R2 0.9162322252867444\n",
      "finished training epoch 2798\n",
      "train_loss:  1.1163840671256092e-05 train_R2 0.8936526664048837\n",
      "finished training epoch 2799\n",
      "train_loss:  1.1267156420721167e-05 train_R2 0.9172553615633225\n",
      "finished training epoch 2800\n",
      "train_loss:  1.1077021238171817e-05 train_R2 0.9237810131002763\n",
      "finished training epoch 2801\n",
      "train_loss:  1.1337449625644593e-05 train_R2 0.9302561907073141\n",
      "finished training epoch 2802\n",
      "train_loss:  1.0965631193118911e-05 train_R2 0.9238007728988995\n",
      "finished training epoch 2803\n",
      "train_loss:  1.1067971990457283e-05 train_R2 0.8924711994506181\n",
      "finished training epoch 2804\n",
      "train_loss:  1.1107660428965622e-05 train_R2 0.9284473352522371\n",
      "finished training epoch 2805\n",
      "train_loss:  1.1121537938546739e-05 train_R2 0.8983667995470502\n",
      "finished training epoch 2806\n",
      "train_loss:  1.1157473268609517e-05 train_R2 0.907320673551328\n",
      "finished training epoch 2807\n",
      "train_loss:  1.1110884702733392e-05 train_R2 0.8944781264941079\n",
      "finished training epoch 2808\n",
      "train_loss:  1.0953369407829662e-05 train_R2 0.8934709396046223\n",
      "finished training epoch 2809\n",
      "train_loss:  1.106317148970557e-05 train_R2 0.8784832409239433\n",
      "finished training epoch 2810\n",
      "train_loss:  1.1131977605727584e-05 train_R2 0.8708858928214552\n",
      "finished training epoch 2811\n",
      "train_loss:  1.0994446545709969e-05 train_R2 0.9009803108791354\n",
      "finished training epoch 2812\n",
      "train_loss:  1.1305348508956992e-05 train_R2 0.8812072900296911\n",
      "finished training epoch 2813\n",
      "train_loss:  1.11723147704101e-05 train_R2 0.9297952068868608\n",
      "finished training epoch 2814\n",
      "train_loss:  1.1089835013542079e-05 train_R2 0.9178098928006663\n",
      "finished training epoch 2815\n",
      "train_loss:  1.1036944931625982e-05 train_R2 0.9088534632154583\n",
      "finished training epoch 2816\n",
      "train_loss:  1.1114689141871143e-05 train_R2 0.8993536289934884\n",
      "finished training epoch 2817\n",
      "train_loss:  1.0892526219077649e-05 train_R2 0.8889591825868448\n",
      "finished training epoch 2818\n",
      "train_loss:  1.116974065616703e-05 train_R2 0.9220225902936172\n",
      "finished training epoch 2819\n",
      "train_loss:  1.108288451240588e-05 train_R2 0.8841877777378838\n",
      "finished training epoch 2820\n",
      "train_loss:  1.1286709938973511e-05 train_R2 0.8922393165359199\n",
      "finished training epoch 2821\n",
      "train_loss:  1.1261768111672773e-05 train_R2 0.8803608211672893\n",
      "finished training epoch 2822\n",
      "train_loss:  1.1037961422826401e-05 train_R2 0.895710984171457\n",
      "finished training epoch 2823\n",
      "train_loss:  1.1060663983584527e-05 train_R2 0.9112963608861082\n",
      "finished training epoch 2824\n",
      "train_loss:  1.1256220543874708e-05 train_R2 0.8937900244271083\n",
      "finished training epoch 2825\n",
      "train_loss:  1.0992972423514403e-05 train_R2 0.8906963886256676\n",
      "finished training epoch 2826\n",
      "train_loss:  1.109447489934148e-05 train_R2 0.9087129892938641\n",
      "finished training epoch 2827\n",
      "train_loss:  1.113931684928356e-05 train_R2 0.9122500562788207\n",
      "finished training epoch 2828\n",
      "train_loss:  1.1181779427364173e-05 train_R2 0.8994302938973734\n",
      "finished training epoch 2829\n",
      "train_loss:  1.1416535061166872e-05 train_R2 0.8846962484335394\n",
      "finished training epoch 2830\n",
      "train_loss:  1.0994852451560056e-05 train_R2 0.9131668654143218\n",
      "finished training epoch 2831\n",
      "train_loss:  1.1209618275931468e-05 train_R2 0.8876187015827771\n",
      "finished training epoch 2832\n",
      "train_loss:  1.1058919135805476e-05 train_R2 0.8885202045671978\n",
      "finished training epoch 2833\n",
      "train_loss:  1.0928059223866054e-05 train_R2 0.8990550606173807\n",
      "finished training epoch 2834\n",
      "train_loss:  1.1243073724295742e-05 train_R2 0.8960204510547068\n",
      "finished training epoch 2835\n",
      "train_loss:  1.1167269602019219e-05 train_R2 0.9130968714252461\n",
      "finished training epoch 2836\n",
      "train_loss:  1.1020369260422195e-05 train_R2 0.9223462577945343\n",
      "finished training epoch 2837\n",
      "train_loss:  1.11419074391932e-05 train_R2 0.8780264094216466\n",
      "finished training epoch 2838\n",
      "train_loss:  1.0917712446482608e-05 train_R2 0.9025958662056214\n",
      "finished training epoch 2839\n",
      "train_loss:  1.105590216650456e-05 train_R2 0.9072421029495514\n",
      "finished training epoch 2840\n",
      "train_loss:  1.1040321706896448e-05 train_R2 0.8868844172332675\n",
      "finished training epoch 2841\n",
      "train_loss:  1.0981381629391346e-05 train_R2 0.8940396343550976\n",
      "finished training epoch 2842\n",
      "train_loss:  1.1183330407753477e-05 train_R2 0.8708742535589057\n",
      "finished training epoch 2843\n",
      "train_loss:  1.0868257209893663e-05 train_R2 0.9103975173689866\n",
      "finished training epoch 2844\n",
      "train_loss:  1.1280537546494025e-05 train_R2 0.8724738098135243\n",
      "finished training epoch 2845\n",
      "train_loss:  1.1206616047789403e-05 train_R2 0.9302532104137762\n",
      "finished training epoch 2846\n",
      "train_loss:  1.1079296210539106e-05 train_R2 0.8976108904841803\n",
      "finished training epoch 2847\n",
      "train_loss:  1.0905126462567331e-05 train_R2 0.9238661192376112\n",
      "finished training epoch 2848\n",
      "train_loss:  1.1016294626095186e-05 train_R2 0.9275706830986842\n",
      "finished training epoch 2849\n",
      "train_loss:  1.1174209368314391e-05 train_R2 0.8690361789815371\n",
      "finished training epoch 2850\n",
      "train_loss:  1.1023096001389295e-05 train_R2 0.8992683355303198\n",
      "finished training epoch 2851\n",
      "train_loss:  1.1036513208736715e-05 train_R2 0.8948746149893813\n",
      "finished training epoch 2852\n",
      "train_loss:  1.1194850372367039e-05 train_R2 0.9140227712282424\n",
      "finished training epoch 2853\n",
      "train_loss:  1.1282017479932964e-05 train_R2 0.8620921949112134\n",
      "finished training epoch 2854\n",
      "train_loss:  1.1036388815077925e-05 train_R2 0.9072862685326993\n",
      "finished training epoch 2855\n",
      "train_loss:  1.1037786439829562e-05 train_R2 0.8967028947590383\n",
      "finished training epoch 2856\n",
      "train_loss:  1.1235254148261498e-05 train_R2 0.8952421482809241\n",
      "finished training epoch 2857\n",
      "train_loss:  1.1092551621610477e-05 train_R2 0.9175910043134112\n",
      "finished training epoch 2858\n",
      "train_loss:  1.1146705609041109e-05 train_R2 0.9104171448050964\n",
      "finished training epoch 2859\n",
      "train_loss:  1.11170632532765e-05 train_R2 0.9226683750995575\n",
      "finished training epoch 2860\n",
      "train_loss:  1.1199224216502667e-05 train_R2 0.8969349016018429\n",
      "finished training epoch 2861\n",
      "train_loss:  1.1111198409581602e-05 train_R2 0.8845028533378855\n",
      "finished training epoch 2862\n",
      "train_loss:  1.1057149817317617e-05 train_R2 0.9102595044469906\n",
      "finished training epoch 2863\n",
      "train_loss:  1.1168944742307323e-05 train_R2 0.8983494552143179\n",
      "finished training epoch 2864\n",
      "train_loss:  1.1161153607328578e-05 train_R2 0.9142064365367178\n",
      "finished training epoch 2865\n",
      "train_loss:  1.1089306687522283e-05 train_R2 0.8724578026467401\n",
      "finished training epoch 2866\n",
      "train_loss:  1.0956835348783369e-05 train_R2 0.8799528614249269\n",
      "finished training epoch 2867\n",
      "train_loss:  1.1243963062680604e-05 train_R2 0.906116156889124\n",
      "finished training epoch 2868\n",
      "train_loss:  1.0856533080432177e-05 train_R2 0.91342015797259\n",
      "finished training epoch 2869\n",
      "train_loss:  1.1120090236601413e-05 train_R2 0.8960275023115273\n",
      "finished training epoch 2870\n",
      "train_loss:  1.0878487881013728e-05 train_R2 0.9197628360405169\n",
      "finished training epoch 2871\n",
      "train_loss:  1.1023248804602337e-05 train_R2 0.897569225730014\n",
      "finished training epoch 2872\n",
      "train_loss:  1.1229408378275263e-05 train_R2 0.9373682982280975\n",
      "finished training epoch 2873\n",
      "train_loss:  1.1160678543743354e-05 train_R2 0.8793797275685954\n",
      "finished training epoch 2874\n",
      "train_loss:  1.1328013736068898e-05 train_R2 0.9167583207239082\n",
      "finished training epoch 2875\n",
      "train_loss:  1.1331139966074369e-05 train_R2 0.8456752922469485\n",
      "finished training epoch 2876\n",
      "train_loss:  1.1154354300252257e-05 train_R2 0.9238840933748382\n",
      "finished training epoch 2877\n",
      "train_loss:  1.0745383758491286e-05 train_R2 0.9103033064622924\n",
      "finished training epoch 2878\n",
      "train_loss:  1.1147373991236007e-05 train_R2 0.8924557794808742\n",
      "finished training epoch 2879\n",
      "train_loss:  1.1193497759927534e-05 train_R2 0.930504894702682\n",
      "finished training epoch 2880\n",
      "train_loss:  1.1112929217626609e-05 train_R2 0.9046004329335726\n",
      "finished training epoch 2881\n",
      "train_loss:  1.0922494924550268e-05 train_R2 0.8919814354153287\n",
      "finished training epoch 2882\n",
      "train_loss:  1.0884580530239053e-05 train_R2 0.8838911043181846\n",
      "finished training epoch 2883\n",
      "train_loss:  1.1110998286597921e-05 train_R2 0.8942730816315839\n",
      "finished training epoch 2884\n",
      "train_loss:  1.0977378883530695e-05 train_R2 0.8962621055602629\n",
      "finished training epoch 2885\n",
      "train_loss:  1.102945675927701e-05 train_R2 0.8920266192308964\n",
      "finished training epoch 2886\n",
      "train_loss:  1.094663312943404e-05 train_R2 0.9171533916381006\n",
      "finished training epoch 2887\n",
      "train_loss:  1.119001181413229e-05 train_R2 0.9180876364653184\n",
      "finished training epoch 2888\n",
      "train_loss:  1.111730351548744e-05 train_R2 0.9157824440918881\n",
      "finished training epoch 2889\n",
      "train_loss:  1.1253616041765674e-05 train_R2 0.8945131239541593\n",
      "finished training epoch 2890\n",
      "train_loss:  1.0998990900261013e-05 train_R2 0.8802932560543002\n",
      "finished training epoch 2891\n",
      "train_loss:  1.1169576207817304e-05 train_R2 0.9187815667530659\n",
      "finished training epoch 2892\n",
      "train_loss:  1.1214919030413159e-05 train_R2 0.8958888485169558\n",
      "finished training epoch 2893\n",
      "train_loss:  1.095767349067204e-05 train_R2 0.9152755240238533\n",
      "finished training epoch 2894\n",
      "train_loss:  1.1075042172167913e-05 train_R2 0.8571158769922139\n",
      "finished training epoch 2895\n",
      "train_loss:  1.0993588515603978e-05 train_R2 0.8833659921474813\n",
      "finished training epoch 2896\n",
      "train_loss:  1.0974750073525531e-05 train_R2 0.9145063776035568\n",
      "finished training epoch 2897\n",
      "train_loss:  1.1134509150850789e-05 train_R2 0.9100284081955705\n",
      "finished training epoch 2898\n",
      "train_loss:  1.1251925712547829e-05 train_R2 0.9469830465338362\n",
      "finished training epoch 2899\n",
      "train_loss:  1.1033503406653517e-05 train_R2 0.9265680661701186\n",
      "finished training epoch 2900\n",
      "train_loss:  1.1073687833669357e-05 train_R2 0.9247661922434769\n",
      "finished training epoch 2901\n",
      "train_loss:  1.1133520911353684e-05 train_R2 0.9201130605492014\n",
      "finished training epoch 2902\n",
      "train_loss:  1.1121142133390153e-05 train_R2 0.8694895332272154\n",
      "finished training epoch 2903\n",
      "train_loss:  1.1117865864975765e-05 train_R2 0.8927129255899726\n",
      "finished training epoch 2904\n",
      "train_loss:  1.0922521926622279e-05 train_R2 0.9087993640330719\n",
      "finished training epoch 2905\n",
      "train_loss:  1.085780004339917e-05 train_R2 0.9096082926085826\n",
      "finished training epoch 2906\n",
      "train_loss:  1.1139893736670133e-05 train_R2 0.8681048096901056\n",
      "finished training epoch 2907\n",
      "train_loss:  1.0959702957216079e-05 train_R2 0.9098874879943988\n",
      "finished training epoch 2908\n",
      "train_loss:  1.1223915955943204e-05 train_R2 0.8846825648320591\n",
      "finished training epoch 2909\n",
      "train_loss:  1.1241657881314727e-05 train_R2 0.9137710807002328\n",
      "finished training epoch 2910\n",
      "train_loss:  1.1042220000799352e-05 train_R2 0.8909969098052402\n",
      "finished training epoch 2911\n",
      "train_loss:  1.1061690320794808e-05 train_R2 0.895380169680027\n",
      "finished training epoch 2912\n",
      "train_loss:  1.1138980612879268e-05 train_R2 0.9149297638364007\n",
      "finished training epoch 2913\n",
      "train_loss:  1.0803772603702492e-05 train_R2 0.9215339010124951\n",
      "finished training epoch 2914\n",
      "train_loss:  1.0955033956931779e-05 train_R2 0.9017082669557767\n",
      "finished training epoch 2915\n",
      "train_loss:  1.0795792871332644e-05 train_R2 0.910908194031169\n",
      "finished training epoch 2916\n",
      "train_loss:  1.1271266393423496e-05 train_R2 0.8750986692237345\n",
      "finished training epoch 2917\n",
      "train_loss:  1.1149395168516913e-05 train_R2 0.9120224074862175\n",
      "finished training epoch 2918\n",
      "train_loss:  1.115369075576251e-05 train_R2 0.8941362323104215\n",
      "finished training epoch 2919\n",
      "train_loss:  1.1134489522861405e-05 train_R2 0.9192480849710208\n",
      "finished training epoch 2920\n",
      "train_loss:  1.1148274412493234e-05 train_R2 0.9071534559965273\n",
      "finished training epoch 2921\n",
      "train_loss:  1.1206320598455152e-05 train_R2 0.9055616167194069\n",
      "finished training epoch 2922\n",
      "train_loss:  1.1175929194897533e-05 train_R2 0.8935368301758163\n",
      "finished training epoch 2923\n",
      "train_loss:  1.092519764198558e-05 train_R2 0.8669725733271421\n",
      "finished training epoch 2924\n",
      "train_loss:  1.125916828605399e-05 train_R2 0.8675230446609032\n",
      "finished training epoch 2925\n",
      "train_loss:  1.1140086865750827e-05 train_R2 0.917526287464012\n",
      "finished training epoch 2926\n",
      "train_loss:  1.1513841206592707e-05 train_R2 0.8610358331239523\n",
      "finished training epoch 2927\n",
      "train_loss:  1.1170850235636324e-05 train_R2 0.9294493793605232\n",
      "finished training epoch 2928\n",
      "train_loss:  1.1154476963569382e-05 train_R2 0.8684817632918512\n",
      "finished training epoch 2929\n",
      "train_loss:  1.1239586445883713e-05 train_R2 0.9097548574273673\n",
      "finished training epoch 2930\n",
      "train_loss:  1.1088345826536324e-05 train_R2 0.8974708470818172\n",
      "finished training epoch 2931\n",
      "train_loss:  1.0936331701176847e-05 train_R2 0.9272643422558369\n",
      "finished training epoch 2932\n",
      "train_loss:  1.0968613330423408e-05 train_R2 0.9185412527056307\n",
      "finished training epoch 2933\n",
      "train_loss:  1.0930007865957453e-05 train_R2 0.9176983594038359\n",
      "finished training epoch 2934\n",
      "train_loss:  1.0962940588400874e-05 train_R2 0.8937079976815414\n",
      "finished training epoch 2935\n",
      "train_loss:  1.069953977672065e-05 train_R2 0.8761372759099357\n",
      "finished training epoch 2936\n",
      "train_loss:  1.1297383404696403e-05 train_R2 0.8839248077445905\n",
      "finished training epoch 2937\n",
      "train_loss:  1.1017286577099018e-05 train_R2 0.9066149577862435\n",
      "finished training epoch 2938\n",
      "train_loss:  1.152674419910313e-05 train_R2 0.9166146040593459\n",
      "finished training epoch 2939\n",
      "train_loss:  1.1087618786273249e-05 train_R2 0.9177952880627005\n",
      "finished training epoch 2940\n",
      "train_loss:  1.0956944345259175e-05 train_R2 0.8983205240509613\n",
      "finished training epoch 2941\n",
      "train_loss:  1.1012586063074163e-05 train_R2 0.9129381166568579\n",
      "finished training epoch 2942\n",
      "train_loss:  1.0938734003966629e-05 train_R2 0.8833435379436562\n",
      "finished training epoch 2943\n",
      "train_loss:  1.127108938214959e-05 train_R2 0.9133805356243955\n",
      "finished training epoch 2944\n",
      "train_loss:  1.1314519594048574e-05 train_R2 0.9306937476102037\n",
      "finished training epoch 2945\n",
      "train_loss:  1.0915191472632362e-05 train_R2 0.8941823597501565\n",
      "finished training epoch 2946\n",
      "train_loss:  1.1068180982300313e-05 train_R2 0.9096013471738521\n",
      "finished training epoch 2947\n",
      "train_loss:  1.1018698710797638e-05 train_R2 0.8901252144712011\n",
      "finished training epoch 2948\n",
      "train_loss:  1.1182326565846214e-05 train_R2 0.8900423493765767\n",
      "finished training epoch 2949\n",
      "train_loss:  1.1080894731281554e-05 train_R2 0.8876613097766213\n",
      "finished training epoch 2950\n",
      "train_loss:  1.1187019293050001e-05 train_R2 0.9323317570207885\n",
      "finished training epoch 2951\n",
      "train_loss:  1.1244001575225443e-05 train_R2 0.8910387518915771\n",
      "finished training epoch 2952\n",
      "train_loss:  1.0898136848896145e-05 train_R2 0.9069577024460869\n",
      "finished training epoch 2953\n",
      "train_loss:  1.1012706116718665e-05 train_R2 0.9128345393775172\n",
      "finished training epoch 2954\n",
      "train_loss:  1.0974444596064295e-05 train_R2 0.9016232668367203\n",
      "finished training epoch 2955\n",
      "train_loss:  1.1266973397221225e-05 train_R2 0.8819661512961904\n",
      "finished training epoch 2956\n",
      "train_loss:  1.1311220494025365e-05 train_R2 0.9063360684997154\n",
      "finished training epoch 2957\n",
      "train_loss:  1.1152189582469004e-05 train_R2 0.9108064014024381\n",
      "finished training epoch 2958\n",
      "train_loss:  1.108836195005601e-05 train_R2 0.9159244131484521\n",
      "finished training epoch 2959\n",
      "train_loss:  1.0946126532341594e-05 train_R2 0.9075315141145102\n",
      "finished training epoch 2960\n",
      "train_loss:  1.103705530379966e-05 train_R2 0.9275054550821085\n",
      "finished training epoch 2961\n",
      "train_loss:  1.0829481530840395e-05 train_R2 0.8853518929354178\n",
      "finished training epoch 2962\n",
      "train_loss:  1.1030677310730772e-05 train_R2 0.8785819341160443\n",
      "finished training epoch 2963\n",
      "train_loss:  1.1180549697262038e-05 train_R2 0.9179466952628198\n",
      "finished training epoch 2964\n",
      "train_loss:  1.1147009773267e-05 train_R2 0.8906609213875516\n",
      "finished training epoch 2965\n",
      "train_loss:  1.1060915493011424e-05 train_R2 0.91798459186539\n",
      "finished training epoch 2966\n",
      "train_loss:  1.0953763939736055e-05 train_R2 0.8955543612777168\n",
      "finished training epoch 2967\n",
      "train_loss:  1.1293576107239371e-05 train_R2 0.8889004695031779\n",
      "finished training epoch 2968\n",
      "train_loss:  1.1054741899223528e-05 train_R2 0.8952225388857927\n",
      "finished training epoch 2969\n",
      "train_loss:  1.1064747876845522e-05 train_R2 0.8835421641377302\n",
      "finished training epoch 2970\n",
      "train_loss:  1.1158742094815566e-05 train_R2 0.9073082283391127\n",
      "finished training epoch 2971\n",
      "train_loss:  1.0918771708419809e-05 train_R2 0.8863915386036284\n",
      "finished training epoch 2972\n",
      "train_loss:  1.1029775518880724e-05 train_R2 0.9149423128938561\n",
      "finished training epoch 2973\n",
      "train_loss:  1.1051201424043011e-05 train_R2 0.9178973306290582\n",
      "finished training epoch 2974\n",
      "train_loss:  1.1054750660952271e-05 train_R2 0.8999493889497472\n",
      "finished training epoch 2975\n",
      "train_loss:  1.0874188076105957e-05 train_R2 0.9033452689364285\n",
      "finished training epoch 2976\n",
      "train_loss:  1.1059798620478205e-05 train_R2 0.916956644596703\n",
      "finished training epoch 2977\n",
      "train_loss:  1.1206004911129796e-05 train_R2 0.8670515771085151\n",
      "finished training epoch 2978\n",
      "train_loss:  1.1118809926813789e-05 train_R2 0.9217972471422874\n",
      "finished training epoch 2979\n",
      "train_loss:  1.0897446669915787e-05 train_R2 0.906034097528969\n",
      "finished training epoch 2980\n",
      "train_loss:  1.0907223809118884e-05 train_R2 0.8939155565267932\n",
      "finished training epoch 2981\n",
      "train_loss:  1.102387044637498e-05 train_R2 0.8826719491836766\n",
      "finished training epoch 2982\n",
      "train_loss:  1.1110069610840045e-05 train_R2 0.914782487111373\n",
      "finished training epoch 2983\n",
      "train_loss:  1.103909733426957e-05 train_R2 0.8961445780577189\n",
      "finished training epoch 2984\n",
      "train_loss:  1.097770257193716e-05 train_R2 0.9219146997395833\n",
      "finished training epoch 2985\n",
      "train_loss:  1.1115980802350362e-05 train_R2 0.9108625810636839\n",
      "finished training epoch 2986\n",
      "train_loss:  1.1135321574203624e-05 train_R2 0.9255994471139033\n",
      "finished training epoch 2987\n",
      "train_loss:  1.0850789117786658e-05 train_R2 0.898620301945563\n",
      "finished training epoch 2988\n",
      "train_loss:  1.0992650269074794e-05 train_R2 0.8926664705968353\n",
      "finished training epoch 2989\n",
      "train_loss:  1.115956823693805e-05 train_R2 0.9223400858626603\n",
      "finished training epoch 2990\n",
      "train_loss:  1.1235603472331565e-05 train_R2 0.8878059854064422\n",
      "finished training epoch 2991\n",
      "train_loss:  1.1203125783115629e-05 train_R2 0.8594428715087987\n",
      "finished training epoch 2992\n",
      "train_loss:  1.1045012435637857e-05 train_R2 0.8925807538973658\n",
      "finished training epoch 2993\n",
      "train_loss:  1.1093887797890293e-05 train_R2 0.9078450124522353\n",
      "finished training epoch 2994\n",
      "train_loss:  1.1492898618471814e-05 train_R2 0.9106909663050047\n",
      "finished training epoch 2995\n",
      "train_loss:  1.1189995977877145e-05 train_R2 0.9307382636759185\n",
      "finished training epoch 2996\n",
      "train_loss:  1.0990421287557077e-05 train_R2 0.9097355729660502\n",
      "finished training epoch 2997\n",
      "train_loss:  1.1150366610459216e-05 train_R2 0.8887217246418514\n",
      "finished training epoch 2998\n",
      "train_loss:  1.1242089229106964e-05 train_R2 0.8690350234106448\n",
      "finished training epoch 2999\n",
      "train_loss:  1.1234497170807649e-05 train_R2 0.9214970334784515\n",
      "finished training epoch 3000\n",
      "train_loss:  1.0764286819543558e-05 train_R2 0.8943366940818307\n",
      "final train_loss: 1.0764286819543558e-05 final train_R2: 0.8943366940818307 val_loss: 0.00019619958655957493 loss validation best: 0.00010358920105973142\n",
      "total Training time: 528.6568908691406s\n"
     ]
    }
   ],
   "source": [
    "starttime=time.time()\n",
    "loss_weights=[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0] \n",
    "fln=15 #20 for full 0-300, 15 for 80-240\n",
    "lr=0.1 #sgd\n",
    "loss_val_best = 500000\n",
    "lr_adam=0.0001\n",
    "optimizer = optim.Adam(model1.parameters(), lr=lr_adam) #add weight decay normally 1-9e-4\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=600, gamma=0.5)\n",
    "batch_total=X_train.shape[0]\n",
    "batch_size=178  # this is the batch size for training\n",
    "#during validation\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "R2_best=-2\n",
    "\n",
    "\n",
    "batches = int(batch_total/batch_size)\n",
    "\n",
    "#turn pd df to pytorch tensors\n",
    "X_train_torch = torch.tensor(X_train.values)\n",
    "Y_train_torch = torch.tensor(Y_train.values)\n",
    "X_train_torch = X_train_torch.view(batches, batch_size, 11)\n",
    "Y_train_torch = Y_train_torch.view(batches, batch_size, 1)\n",
    "\n",
    "X_val_torch = torch.tensor(X_val.values)\n",
    "Y_val_torch = torch.tensor(Y_val.values)\n",
    "\n",
    "X_val_torch = X_val_torch.view(1, X_val_torch.size(0), X_val_torch.size(1))\n",
    "Y_val_torch = Y_val_torch.view(Y_val_torch.size(0), 1, 1)\n",
    "\n",
    "maxepoch=3000\n",
    "model1.train()\n",
    "for epoch in range(maxepoch):\n",
    "    train_loss=0.0\n",
    "    val_loss=0.0\n",
    "    model1.zero_grad()\n",
    "    \n",
    "    \n",
    "    Y_pred_all= torch.zeros(Y_train_torch.shape)\n",
    "    \n",
    "    for bb in range(int(batch_total/batch_size)):\n",
    "        \n",
    "        hidden = model1.init_hidden(batch_size)\n",
    "        \n",
    "        hidden = hidden.float()\n",
    "    \n",
    "        Y_pred,hidden = model1(X_train_torch[bb:bb+1, :].float(),\\\n",
    "                                hidden)\n",
    "        \n",
    "        loss = myloss_mul_sum(Y_pred, Y_train_torch[bb:(bb+1),:],\\\n",
    "                                 loss_weights)\n",
    "        for nh in range(len(hidden[0])):\n",
    "            hidden[0][nh].detach()\n",
    "        hidden[1].detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            train_loss=train_loss+loss.item()\n",
    "            Y_pred_all[bb:(bb+1),:]=Y_pred[:,:]\n",
    "    scheduler.step()\n",
    "    \n",
    "    #validation\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss=train_loss/(batch_total/batch_size)\n",
    "        train_losses.append(train_loss)\n",
    "        train_R2=compute_r2(Y_pred_all[:,0].contiguous().view(-1),Y_train_torch[:,0].contiguous().view(-1)).item()\n",
    "        Y_val_pred=torch.zeros(Y_train_torch.size())\n",
    "        \n",
    "        hidden = model1.init_hidden(X_val_torch.size(1))   \n",
    "        Y_val_pred, hidden = model1(X_val_torch.float(), hidden)\n",
    "        loss = myloss_mul_sum(Y_val_pred, Y_val_torch, loss_weights)\n",
    "        val_loss=loss.item()\n",
    "        val_losses.append(val_loss)\n",
    "        #r2 only for n2o\n",
    "        val_R2=compute_r2(Y_val_pred[:,:,0].contiguous().view(-1),Y_val_torch[:,:,0].contiguous().view(-1)).item()\n",
    "        if val_loss < loss_val_best and val_R2 > R2_best:\n",
    "            loss_val_best=val_loss\n",
    "            R2_best = val_R2\n",
    "            \n",
    "            f0=open(model_save,'w')\n",
    "            f0.close()\n",
    "            #os.remove(path_save)\n",
    "            torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model1.state_dict(),\n",
    "                    'R2': train_R2,\n",
    "                    'loss': train_loss,\n",
    "                    'los_val': val_loss,\n",
    "                    'R2_val': val_R2,\n",
    "                    }, model_save)    \n",
    "        print(\"finished training epoch\", epoch+1)\n",
    "    mtime=time.time()\n",
    "    print(\"train_loss: \", train_loss, \"train_R2\", train_R2)\n",
    "\n",
    "    if train_R2 > 0.99:\n",
    "        break\n",
    "    model1.train()\n",
    "endtime=time.time()\n",
    "torch.save({'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'model_state_dict_fs': model1.state_dict(),\n",
    "            }, stats_save)  \n",
    "print(\"final train_loss:\",train_loss,\"final train_R2:\",train_R2,\"val_loss:\",val_loss,\"loss validation best:\",loss_val_best)\n",
    "print(f\"total Training time: {endtime - starttime}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be08f3c6-2c3b-43c4-912b-bfc1199437c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa673d8cac0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint=torch.load('kgml-results/stats-fine_tuned')\n",
    "train_losses=checkpoint['train_losses']\n",
    "val_losses=checkpoint['val_losses']\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.rcParams['xtick.labelsize']=20\n",
    "plt.rcParams['ytick.labelsize']=20\n",
    "fig= plt.plot(figsize=(6, 10)) \n",
    "train_line, = plt.plot(train_losses, label=\"Training loss\") \n",
    "val_line, = plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.title(\"GRU fine-tuned on ameriFLUX data\")\n",
    "plt.text(0.35, 0.1, \"Final R2 = %0.2f\\n Final RMSE = %0.8f\" % (train_R2, train_loss), ha=\"left\", va=\"bottom\", color=train_line.get_color(), fontsize=16, transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.text(0.35, 0.5, \"Final R2 = %0.2f\\n Final RMSE = %0.8f\" % (val_R2, val_loss), ha=\"left\", va=\"top\", color=val_line.get_color(), fontsize=16, transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b266d96-c96e-4e80-9943-7860b6fdd3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
