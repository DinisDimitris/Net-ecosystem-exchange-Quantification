{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd828e47-3802-4984-b7b2-632597ce60b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xg\n",
    "from xgboost import cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n",
    "from sklearn.metrics import r2_score as R2\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5421815f-66ec-4069-936e-90e220006b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = 'NEE'\n",
    "\n",
    "model = ['rcef_RandomForestRegressor', 'rcef_RidgeCV', 'rcef_XGBRegressor', 'xgboost'] \n",
    "\n",
    "extracted_features = model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1c71bc-6b46-4cfe-b8a7-5cae2c582062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loads all data sets into a dict\n",
    "def load_datasets(dirs: list, load_path: str) -> dict:\n",
    "    files = ['soil_c','surf_water','flux_soc','soil_water','n_flux','p_flux','temp', \n",
    "         'plant_c','plant_n','plant_p','canopcy_c','plant_stress','photosynthesis','plant_growth']\n",
    "    \n",
    "    #files.append('soil_temp', 'canopy_temp') missing \n",
    "    datasets = {}\n",
    "    \n",
    "    for dr in dirs:\n",
    "        csv_list = []\n",
    "        path = 'datasets/' + dr + load_path\n",
    "        for f in files:\n",
    "            df = pd.read_csv(os.path.join(path,f + '.csv'))\n",
    "            df.drop(df.columns[0], axis=1)\n",
    "\n",
    "            csv_list.append(df)\n",
    "\n",
    "\n",
    "        data_dict = {}\n",
    "        for i in range (len(csv_list)):\n",
    "            data_dict[files[i]] = csv_list[i]\n",
    "\n",
    "        datasets[dr] = data_dict\n",
    "\n",
    "    return datasets\n",
    "\n",
    "dirs = ['warm_temp_maize_soybean_irrigated', 'warm_temp_maize-soybean_dryland', 'cool_temp_maize_soybean']\n",
    "\n",
    "datasets = load_datasets(dirs, '/csv_outs/with_plant_soil_details/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b535aafa-b830-4751-8754-14c548a2a0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_dupes(suffix: str, df: pd.DataFrame, dupes: list) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if col in dupes:\n",
    "            df.rename(columns={col: col + suffix}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def average_numbered_columns(df):\n",
    "    numbered_cols = [col for col in df.columns if '_' in col and col.split('_')[-1].isdigit()]\n",
    "\n",
    "    col_groups = {}\n",
    "    for col in numbered_cols:\n",
    "        prefix = '_'.join(col.split('_')[:-1])\n",
    "        if prefix not in col_groups:\n",
    "            col_groups[prefix] = []\n",
    "        col_groups[prefix].append(col)\n",
    "\n",
    "    # calculate averages and add new columns\n",
    "    for prefix, cols in col_groups.items():\n",
    "        avg_col_name = prefix\n",
    "        avg_col_values = df[cols].mean(axis=1)\n",
    "        df[avg_col_name] = avg_col_values\n",
    "\n",
    "    # drop numbered columns\n",
    "    df = df.drop(columns=numbered_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "# turn all csv's to one dataframe\n",
    "def to_pd(df: dict, handle_dupes: bool, flatten_num_cols: bool) -> pd.DataFrame:\n",
    "    x = pd.DataFrame()\n",
    "    for file_name in df:\n",
    "        cur = df[file_name]\n",
    "            \n",
    "        x = pd.concat([x, df[file_name]], axis = 1)\n",
    "        \n",
    "    cheeky_col = 'unnamed.1'\n",
    "    cheeky_col2 = 'Unnamed: 0'\n",
    "    if cheeky_col in x.columns:\n",
    "        x = x.drop([cheeky_col], axis=1)\n",
    "    elif cheeky_col2 in x.columns:\n",
    "         x = x.drop([cheeky_col2], axis=1)\n",
    "    x = x.drop(['DATE'], axis=1)\n",
    "\n",
    "    if flatten_num_cols:\n",
    "        x = average_numbered_columns(x)\n",
    "        \n",
    "    x = x.loc[:,~x.columns.duplicated()].copy()\n",
    "    \n",
    "    one_hot = pd.get_dummies(x['GROWTH_STG'])\n",
    "    x= x.drop('GROWTH_STG',axis = 1)\n",
    "    # Join the encoded df\n",
    "    x = x.join(one_hot)\n",
    "\n",
    "    x.columns = x.columns.str.translate(\"\".maketrans({\"[\":\"{\", \"]\":\"}\",\"<\":\"^\"}))\n",
    "    \n",
    "    return x\n",
    "\n",
    "df_dry = to_pd(datasets['warm_temp_maize-soybean_dryland'], True, True)\n",
    "df_irr = to_pd(datasets['warm_temp_maize_soybean_irrigated'], True, True)\n",
    "df_cool = to_pd(datasets['cool_temp_maize_soybean'], True, True)\n",
    "\n",
    "# NEE = GPP - ER:\n",
    "#GPP = GROSS PRIMARY PRODUCTION (TOTAL C INTAKE) \n",
    "#ER = total C uptake =  ECO_RH + ECO_RA =  autotrophic + heterotrophic respiration \n",
    "#NPP = GPP + ECO_RA\n",
    "df_dry['NEE'] = df_dry['ECO_NPP'] - df_dry['ECO_RH']\n",
    "df_irr['NEE'] = df_irr['ECO_NPP'] - df_irr['ECO_RH']\n",
    "df_cool['NEE'] = df_cool['ECO_NPP'] - df_cool['ECO_RH']\n",
    "\n",
    "df= pd.concat([df_dry, df_irr, df_cool])\n",
    "y = df[target].copy()\n",
    "#y = df[target].copy()\n",
    "#df = df.drop(target, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b80e21e-2fb4-4a66-80b1-fcef203c6c97",
   "metadata": {},
   "source": [
    "### Read simulated data, extracted features, l2 normalize data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73510359-5207-41de-8d09-c3db173d8c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgbFeatImp = pd.read_csv('feature_analysis/xgboost/FeaturesImportance'  + target  + 'weather_soil_data' + '.csv')\n",
    "feat_cols = []\n",
    "for i in range(len(xgbFeatImp.values)):\n",
    "    feat_cols.append(xgbFeatImp.values[i][0])\n",
    "\n",
    "y_simulated = df[target].copy()\n",
    "x_simulated = df[feat_cols]\n",
    "x_simulated['WIND'] = x_simulated['WIND'] / 100\n",
    "\n",
    "for entr in x_simulated.columns:\n",
    "    x_simulated[entr] = preprocessing.normalize([x_simulated[entr]])[0]\n",
    "y_simulated = pd.Series(preprocessing.normalize([y_simulated])[0], name='NEE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a25ef-8fc9-4577-88e8-b4fac3262c3a",
   "metadata": {},
   "source": [
    "### Read observed data, and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a138ec-42ca-4271-ba37-55a66d8553cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_df = pd.read_csv('datasets/extractedNEE_CUT_REF_NIGHT.csv')\n",
    "\n",
    "observed_df['initial planting density (m-2)1'] = 8.2\n",
    "\n",
    "x_observed = observed_df[feat_cols]\n",
    "y_observed = observed_df['NEE']\n",
    "\n",
    "for entr in x_observed.columns:\n",
    "    x_observed[entr] = preprocessing.normalize([x_observed[entr]])[0]\n",
    "y_observed = pd.Series(preprocessing.normalize([y_observed])[0], name='NEE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae558e45-c0b1-42ae-a345-ded17e825f0e",
   "metadata": {},
   "source": [
    "### Aggregate data and turn into xgb matrix for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adc8e955-b31e-43ec-a93f-c1d18a271ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = pd.concat([x_simulated, x_observed])\n",
    "y = pd.concat([y_simulated, y_observed])\n",
    "\n",
    "data_dmatrix = xg.DMatrix(data=x,label=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027542-dae4-44d4-b35d-8085598c9de5",
   "metadata": {},
   "source": [
    "### Load optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "393db39f-b814-4a90-8aab-2a5febf6c713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg = xg.XGBRegressor()\n",
    "reg.load_model(\"models/bayesian_pretrain_gridsearch_fine_tune_xgb.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d40c6-248f-4411-8161-7caf82a34c5b",
   "metadata": {},
   "source": [
    "### Kfold CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d8f46ea-a900-4d9f-b837-69f6e3ff6aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_cv = cv(dtrain=data_dmatrix, params=reg.get_xgb_params(), nfold=7\n",
    "            , early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82773f07-0e0e-49eb-a634-e58233dcfcf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486303</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.486303</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481512</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.481512</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476769</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.476769</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.472072</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.472072</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467421</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.467421</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.462816</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.462816</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.458256</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.458256</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.453742</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.453742</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.449271</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.449271</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.444846</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.444846</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0         0.486303        0.000036        0.486303       0.000216\n",
       "1         0.481512        0.000035        0.481512       0.000217\n",
       "2         0.476769        0.000035        0.476769       0.000216\n",
       "3         0.472072        0.000035        0.472072       0.000217\n",
       "4         0.467421        0.000035        0.467421       0.000217\n",
       "5         0.462816        0.000034        0.462816       0.000217\n",
       "6         0.458256        0.000034        0.458256       0.000217\n",
       "7         0.453742        0.000034        0.453742       0.000217\n",
       "8         0.449271        0.000033        0.449271       0.000218\n",
       "9         0.444846        0.000033        0.444846       0.000218"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
